{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import math \n",
    "from torch.optim import Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_samples = 30\n",
    "p = 10\n",
    "d = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(N_samples, d)\n",
    "true_beta = torch.randn(d,p)\n",
    "Y = X@true_beta + torch.randn(N_samples, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(X,Y,batch_size): \n",
    "    '''\n",
    "    get the batches required to do a  minibatch gradient ascent.  \n",
    "\n",
    "    args : \n",
    "            'batch_size' int.  the batch size you want. \n",
    "\n",
    "    returns : a generator. Will generate n/batch_size samples of size batch_size (except the last one \n",
    "                since the rest of the division is not always 0)\n",
    "    '''\n",
    "    #np.random.seed(2)\n",
    "    n = Y.shape[0]\n",
    "    indices = np.arange(n)\n",
    "    np.random.shuffle(indices)\n",
    "    # get the number of batches and the size of the last one. \n",
    "    nb_full_batch, last_batch_size  = n//batch_size, n % batch_size  \n",
    "    for i in range(nb_full_batch): \n",
    "        yield   (X[indices[i*batch_size: (i+1)*batch_size]],\n",
    "                 Y[indices[i*batch_size: (i+1)*batch_size]], \n",
    "                 indices[i*batch_size: (i+1)*batch_size]\n",
    "                ) \n",
    "    if last_batch_size != 0 :\n",
    "        yield   (X[indices[-last_batch_size:]], Y[indices[-last_batch_size:]], \n",
    "                 indices[-last_batch_size:],\n",
    "                )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0084, -0.3115, -1.2462, -2.4635, -1.0466,  2.0231, -0.2599,  3.8577,\n",
       "         1.9691, -0.0273])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res : tensor([[ 0.6336, -0.2571,  0.4531,  0.7773,  0.0067, -0.6726,  0.6879, -2.3523,\n",
      "         -0.1955, -0.0462],\n",
      "        [ 0.4223,  1.1227, -0.2600, -1.0814,  0.4451, -1.4642,  0.4540, -0.9706,\n",
      "          1.7317, -1.1076],\n",
      "        [-1.8058,  0.9489,  0.8655,  0.3208, -0.8030,  0.1810,  1.3851,  0.3318,\n",
      "         -0.8078, -0.9673],\n",
      "        [-0.2844, -1.1583, -1.1680,  0.3981, -1.1801, -1.0732,  0.5986, -0.2830,\n",
      "          0.7018, -0.8330]], requires_grad=True)\n",
      "grad : tensor([[-1.5895e-08, -3.1789e-08,  1.5895e-08,  3.9736e-09, -3.9736e-09,\n",
      "          9.9341e-09, -6.3578e-08,  9.9341e-08,  3.1789e-08,  3.1789e-08],\n",
      "        [-1.9868e-08,  1.0331e-07,  1.5895e-08, -5.5631e-08, -1.1921e-08,\n",
      "         -9.9341e-08,  7.9473e-09, -4.7684e-08,  7.9473e-08, -3.9736e-08],\n",
      "        [-1.2716e-07,  2.7816e-08,  6.3578e-08,  0.0000e+00,  3.9736e-08,\n",
      "          1.1921e-08,  1.5895e-08, -3.1789e-08,  1.5895e-08, -5.5631e-08],\n",
      "        [-3.1789e-08, -6.5565e-08, -8.3447e-08,  0.0000e+00, -8.3447e-08,\n",
      "          1.0331e-07, -3.1789e-08,  2.7816e-08, -5.5631e-08,  4.3710e-08]],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "grad : tensor([[[-6.0840e-01,  7.7744e-01, -4.5783e-01,  1.7780e+00,  4.0282e-02,\n",
      "           7.6556e-01, -4.6198e-01,  5.9777e-01, -8.5713e-01,  8.1047e-01],\n",
      "         [ 8.1633e-02, -1.0432e-01,  6.1430e-02, -2.3856e-01, -5.4049e-03,\n",
      "          -1.0272e-01,  6.1988e-02, -8.0208e-02,  1.1501e-01, -1.0875e-01],\n",
      "         [ 4.9124e-01, -6.2773e-01,  3.6967e-01, -1.4356e+00, -3.2525e-02,\n",
      "          -6.1815e-01,  3.7302e-01, -4.8266e-01,  6.9208e-01, -6.5440e-01],\n",
      "         [ 3.3529e-01, -4.2845e-01,  2.5231e-01, -9.7984e-01, -2.2199e-02,\n",
      "          -4.2191e-01,  2.5460e-01, -3.2944e-01,  4.7237e-01, -4.4665e-01]],\n",
      "\n",
      "        [[ 2.3227e-01, -1.7730e-02, -1.3520e-01,  7.1296e-01,  6.7405e-01,\n",
      "           3.5976e-02, -1.7041e-01,  1.7784e+00,  1.3913e+00,  6.0692e-01],\n",
      "         [ 3.4666e-01, -2.6461e-02, -2.0179e-01,  1.0641e+00,  1.0060e+00,\n",
      "           5.3692e-02, -2.5433e-01,  2.6542e+00,  2.0765e+00,  9.0580e-01],\n",
      "         [-3.5831e-02,  2.7351e-03,  2.0857e-02, -1.0998e-01, -1.0398e-01,\n",
      "          -5.5497e-03,  2.6288e-02, -2.7434e-01, -2.1463e-01, -9.3625e-02],\n",
      "         [-2.8116e-01,  2.1462e-02,  1.6366e-01, -8.6302e-01, -8.1592e-01,\n",
      "          -4.3548e-02,  2.0628e-01, -2.1527e+00, -1.6841e+00, -7.3466e-01]],\n",
      "\n",
      "        [[-8.7474e-01,  3.4380e-01, -6.2916e-01,  4.4411e-01, -1.9717e-01,\n",
      "          -5.7080e-01,  3.2955e-01, -2.1794e-03,  4.5986e-03,  2.6821e-01],\n",
      "         [-1.7599e+00,  6.9169e-01, -1.2658e+00,  8.9351e-01, -3.9669e-01,\n",
      "          -1.1484e+00,  6.6302e-01, -4.3848e-03,  9.2519e-03,  5.3962e-01],\n",
      "         [ 1.3668e-01, -5.3720e-02,  9.8309e-02, -6.9394e-02,  3.0809e-02,\n",
      "           8.9190e-02, -5.1493e-02,  3.4055e-04, -7.1855e-04, -4.1909e-02],\n",
      "         [ 6.2861e-01, -2.4706e-01,  4.5213e-01, -3.1915e-01,  1.4169e-01,\n",
      "           4.1019e-01, -2.3682e-01,  1.5662e-03, -3.3046e-03, -1.9274e-01]],\n",
      "\n",
      "        [[-1.3600e+00,  7.9213e-01, -9.8586e-01,  3.8661e-01,  3.6256e-01,\n",
      "           1.2599e-01, -9.8366e-01, -6.9468e-01, -1.3077e+00,  5.4426e-01],\n",
      "         [-9.1203e-01,  5.3119e-01, -6.6111e-01,  2.5925e-01,  2.4313e-01,\n",
      "           8.4484e-02, -6.5963e-01, -4.6585e-01, -8.7693e-01,  3.6497e-01],\n",
      "         [-7.0492e-01,  4.1057e-01, -5.1098e-01,  2.0038e-01,  1.8792e-01,\n",
      "           6.5299e-02, -5.0984e-01, -3.6006e-01, -6.7779e-01,  2.8209e-01],\n",
      "         [-1.9539e-01,  1.1380e-01, -1.4163e-01,  5.5541e-02,  5.2086e-02,\n",
      "           1.8100e-02, -1.4132e-01, -9.9800e-02, -1.8787e-01,  7.8190e-02]],\n",
      "\n",
      "        [[ 4.8618e-01, -6.9885e-02,  3.2073e-01, -7.4819e-01,  3.3051e-01,\n",
      "           7.4850e-01,  8.3283e-01,  1.8208e+00, -1.4287e-01, -1.7148e+00],\n",
      "         [ 3.2664e-01, -4.6953e-02,  2.1549e-01, -5.0268e-01,  2.2206e-01,\n",
      "           5.0289e-01,  5.5954e-01,  1.2233e+00, -9.5990e-02, -1.1521e+00],\n",
      "         [ 7.6524e-01, -1.1000e-01,  5.0483e-01, -1.1776e+00,  5.2022e-01,\n",
      "           1.1781e+00,  1.3109e+00,  2.8660e+00, -2.2488e-01, -2.6990e+00],\n",
      "         [ 4.7766e-01, -6.8661e-02,  3.1511e-01, -7.3509e-01,  3.2472e-01,\n",
      "           7.3539e-01,  8.1824e-01,  1.7889e+00, -1.4037e-01, -1.6847e+00]]],\n",
      "       grad_fn=<UnsafeViewBackward>)\n",
      "grad : tensor([[[ 4.1464e-01, -5.1156e-02, -2.3399e-01,  2.6103e-01, -1.7065e-01,\n",
      "           8.5778e-02,  1.4549e-01, -2.5460e-01, -4.1824e-01, -9.4061e-02],\n",
      "         [ 1.4339e+00, -1.7691e-01, -8.0919e-01,  9.0270e-01, -5.9015e-01,\n",
      "           2.9664e-01,  5.0314e-01, -8.8046e-01, -1.4464e+00, -3.2529e-01],\n",
      "         [ 6.1797e-01, -7.6240e-02, -3.4873e-01,  3.8902e-01, -2.5433e-01,\n",
      "           1.2784e-01,  2.1683e-01, -3.7944e-01, -6.2332e-01, -1.4018e-01],\n",
      "         [-9.3010e-01,  1.1475e-01,  5.2486e-01, -5.8552e-01,  3.8279e-01,\n",
      "          -1.9241e-01, -3.2635e-01,  5.7109e-01,  9.3816e-01,  2.1099e-01]],\n",
      "\n",
      "        [[-1.4043e-01, -7.4285e-01,  3.5533e+00, -6.6963e-01, -8.1995e-01,\n",
      "           3.3541e-01, -3.4242e-01, -2.1228e+00,  8.3746e-01, -1.6526e+00],\n",
      "         [-4.2548e-02, -2.2507e-01,  1.0766e+00, -2.0289e-01, -2.4843e-01,\n",
      "           1.0162e-01, -1.0375e-01, -6.4317e-01,  2.5374e-01, -5.0070e-01],\n",
      "         [ 4.8353e-03,  2.5578e-02, -1.2235e-01,  2.3057e-02,  2.8233e-02,\n",
      "          -1.1549e-02,  1.1790e-02,  7.3093e-02, -2.8836e-02,  5.6902e-02],\n",
      "         [-2.3526e-02, -1.2445e-01,  5.9527e-01, -1.1218e-01, -1.3736e-01,\n",
      "           5.6190e-02, -5.7364e-02, -3.5562e-01,  1.4030e-01, -2.7685e-01]],\n",
      "\n",
      "        [[ 1.8821e+00,  7.9446e-01,  3.8600e-01, -1.6903e+00, -6.2797e-01,\n",
      "           7.7187e-01,  3.3379e+00, -9.6299e-01,  3.6908e+00,  1.0272e-02],\n",
      "         [-2.9231e-01, -1.2339e-01, -5.9949e-02,  2.6251e-01,  9.7530e-02,\n",
      "          -1.1988e-01, -5.1840e-01,  1.4956e-01, -5.7321e-01, -1.5954e-03],\n",
      "         [-3.8545e-01, -1.6270e-01, -7.9051e-02,  3.4616e-01,  1.2861e-01,\n",
      "          -1.5807e-01, -6.8358e-01,  1.9722e-01, -7.5585e-01, -2.1037e-03],\n",
      "         [-8.4902e-01, -3.5838e-01, -1.7412e-01,  7.6246e-01,  2.8327e-01,\n",
      "          -3.4818e-01, -1.5057e+00,  4.3440e-01, -1.6649e+00, -4.6338e-03]],\n",
      "\n",
      "        [[ 2.2278e-01, -1.6242e-01, -2.0027e-01, -6.8161e-01,  4.0466e-01,\n",
      "           3.4474e-02,  3.1834e-01,  2.9143e-01, -4.2308e-01,  2.9651e-01],\n",
      "         [-1.3254e-01,  9.6627e-02,  1.1914e-01,  4.0550e-01, -2.4074e-01,\n",
      "          -2.0509e-02, -1.8938e-01, -1.7338e-01,  2.5170e-01, -1.7640e-01],\n",
      "         [ 1.3581e-01, -9.9015e-02, -1.2209e-01, -4.1552e-01,  2.4669e-01,\n",
      "           2.1016e-02,  1.9406e-01,  1.7766e-01, -2.5792e-01,  1.8076e-01],\n",
      "         [ 1.0900e-01, -7.9468e-02, -9.7984e-02, -3.3349e-01,  1.9799e-01,\n",
      "           1.6867e-02,  1.5575e-01,  1.4259e-01, -2.0700e-01,  1.4507e-01]],\n",
      "\n",
      "        [[-8.3727e-02,  1.6440e-02, -1.1964e-01, -8.2087e-02,  4.3532e-01,\n",
      "          -7.8822e-03, -1.8344e-01, -2.6932e-01,  7.6290e-02, -2.4007e-01],\n",
      "         [-1.5421e-01,  3.0279e-02, -2.2035e-01, -1.5119e-01,  8.0177e-01,\n",
      "          -1.4518e-02, -3.3786e-01, -4.9604e-01,  1.4051e-01, -4.4217e-01],\n",
      "         [ 6.1880e-01, -1.2150e-01,  8.8418e-01,  6.0668e-01, -3.2173e+00,\n",
      "           5.8255e-02,  1.3557e+00,  1.9905e+00, -5.6383e-01,  1.7743e+00],\n",
      "         [-4.2715e-02,  8.3872e-03, -6.1034e-02, -4.1878e-02,  2.2209e-01,\n",
      "          -4.0213e-03, -9.3586e-02, -1.3740e-01,  3.8921e-02, -1.2248e-01]]],\n",
      "       grad_fn=<UnsafeViewBackward>)\n",
      "grad : tensor([[[ 9.9097e-02,  5.1656e-01, -2.2640e-01,  1.9749e+00,  3.0928e-01,\n",
      "          -5.7190e-01,  1.0115e+00, -1.2614e-01, -1.5840e-01,  1.2075e+00],\n",
      "         [ 2.1615e-01,  1.1267e+00, -4.9381e-01,  4.3076e+00,  6.7458e-01,\n",
      "          -1.2474e+00,  2.2063e+00, -2.7513e-01, -3.4551e-01,  2.6338e+00],\n",
      "         [-1.1381e-01, -5.9326e-01,  2.6001e-01, -2.2681e+00, -3.5520e-01,\n",
      "           6.5681e-01, -1.1617e+00,  1.4487e-01,  1.8192e-01, -1.3868e+00],\n",
      "         [ 1.7557e-01,  9.1519e-01, -4.0111e-01,  3.4989e+00,  5.4794e-01,\n",
      "          -1.0132e+00,  1.7921e+00, -2.2348e-01, -2.8064e-01,  2.1394e+00]],\n",
      "\n",
      "        [[ 2.4034e-01,  1.0111e-01,  5.3604e-01, -1.4108e-01,  3.8119e-01,\n",
      "           6.3643e-01,  5.8428e-02,  7.2079e-02, -9.2881e-01,  3.5992e-01],\n",
      "         [ 1.4701e-01,  6.1851e-02,  3.2790e-01, -8.6296e-02,  2.3318e-01,\n",
      "           3.8930e-01,  3.5740e-02,  4.4090e-02, -5.6815e-01,  2.2016e-01],\n",
      "         [-4.0025e-01, -1.6839e-01, -8.9270e-01,  2.3494e-01, -6.3482e-01,\n",
      "          -1.0599e+00, -9.7304e-02, -1.2004e-01,  1.5468e+00, -5.9939e-01],\n",
      "         [-3.0788e-01, -1.2953e-01, -6.8668e-01,  1.8072e-01, -4.8832e-01,\n",
      "          -8.1527e-01, -7.4847e-02, -9.2334e-02,  1.1898e+00, -4.6106e-01]],\n",
      "\n",
      "        [[-2.7431e-01, -6.1659e-01,  8.9806e-01,  6.0961e-01, -1.2576e+00,\n",
      "          -1.6632e-01,  1.2513e-01, -9.1894e-01, -1.4511e+00, -5.3280e-01],\n",
      "         [ 4.3514e-03,  9.7811e-03, -1.4246e-02, -9.6703e-03,  1.9950e-02,\n",
      "           2.6384e-03, -1.9849e-03,  1.4577e-02,  2.3018e-02,  8.4519e-03],\n",
      "         [-1.8742e-01, -4.2127e-01,  6.1358e-01,  4.1650e-01, -8.5923e-01,\n",
      "          -1.1364e-01,  8.5492e-02, -6.2785e-01, -9.9141e-01, -3.6403e-01],\n",
      "         [ 3.7411e-01,  8.4092e-01, -1.2248e+00, -8.3140e-01,  1.7151e+00,\n",
      "           2.2683e-01, -1.7065e-01,  1.2533e+00,  1.9790e+00,  7.2664e-01]],\n",
      "\n",
      "        [[ 9.3613e-02,  3.7652e-02, -1.8379e-04, -2.3454e-02, -1.2454e-01,\n",
      "           3.3482e-01, -1.3679e-01,  4.1796e-01, -1.7780e-01, -2.0904e-01],\n",
      "         [ 3.5916e-01,  1.4446e-01, -7.0512e-04, -8.9985e-02, -4.7782e-01,\n",
      "           1.2846e+00, -5.2481e-01,  1.6036e+00, -6.8215e-01, -8.0203e-01],\n",
      "         [-2.2837e-01, -9.1852e-02,  4.4834e-04,  5.7215e-02,  3.0381e-01,\n",
      "          -8.1678e-01,  3.3369e-01, -1.0196e+00,  4.3373e-01,  5.0996e-01],\n",
      "         [ 2.6464e-01,  1.0644e-01, -5.1955e-04, -6.6304e-02, -3.5207e-01,\n",
      "           9.4653e-01, -3.8669e-01,  1.1816e+00, -5.0263e-01, -5.9096e-01]],\n",
      "\n",
      "        [[-1.4160e-01, -1.6213e+00, -3.7161e-01, -7.8386e-01, -1.1778e+00,\n",
      "           4.5011e-01, -1.5460e+00,  1.4252e-01,  2.7707e-01, -3.8492e-01],\n",
      "         [-3.0706e-01, -3.5156e+00, -8.0581e-01, -1.6998e+00, -2.5539e+00,\n",
      "           9.7605e-01, -3.3525e+00,  3.0904e-01,  6.0081e-01, -8.3468e-01],\n",
      "         [ 2.5978e-01,  2.9743e+00,  6.8174e-01,  1.4380e+00,  2.1607e+00,\n",
      "          -8.2576e-01,  2.8363e+00, -2.6146e-01, -5.0830e-01,  7.0616e-01],\n",
      "         [-1.2034e-01, -1.3778e+00, -3.1581e-01, -6.6616e-01, -1.0009e+00,\n",
      "           3.8253e-01, -1.3139e+00,  1.2112e-01,  2.3547e-01, -3.2712e-01]]],\n",
      "       grad_fn=<UnsafeViewBackward>)\n",
      "grad : tensor([[[ 0.4104, -0.3327,  0.3006, -0.8848, -0.1348, -1.2419,  0.2601,\n",
      "           0.2146, -0.3907,  0.5675],\n",
      "         [ 0.1082, -0.0877,  0.0792, -0.2332, -0.0355, -0.3273,  0.0686,\n",
      "           0.0566, -0.1030,  0.1496],\n",
      "         [-1.3382,  1.0849, -0.9803,  2.8851,  0.4395,  4.0494, -0.8482,\n",
      "          -0.6998,  1.2739, -1.8505],\n",
      "         [-0.1049,  0.0851, -0.0769,  0.2262,  0.0345,  0.3175, -0.0665,\n",
      "          -0.0549,  0.0999, -0.1451]],\n",
      "\n",
      "        [[-0.9667,  0.8785, -0.5868,  0.5523, -0.7422, -0.2112,  0.3182,\n",
      "           2.0072, -1.4591,  1.1738],\n",
      "         [ 1.0410, -0.9461,  0.6319, -0.5948,  0.7993,  0.2275, -0.3427,\n",
      "          -2.1616,  1.5713, -1.2641],\n",
      "         [-0.9908,  0.9005, -0.6015,  0.5661, -0.7608, -0.2165,  0.3262,\n",
      "           2.0574, -1.4956,  1.2032],\n",
      "         [-1.0660,  0.9688, -0.6471,  0.6091, -0.8185, -0.2329,  0.3509,\n",
      "           2.2135, -1.6090,  1.2945]],\n",
      "\n",
      "        [[ 0.2915,  1.0587,  0.4271,  1.7197,  1.6082, -2.1267, -1.2400,\n",
      "          -0.5776, -1.9386, -0.1677],\n",
      "         [-0.0295, -0.1073, -0.0433, -0.1742, -0.1629,  0.2154,  0.1256,\n",
      "           0.0585,  0.1964,  0.0170],\n",
      "         [ 0.0148,  0.0538,  0.0217,  0.0873,  0.0817, -0.1080, -0.0630,\n",
      "          -0.0293, -0.0984, -0.0085],\n",
      "         [-0.0237, -0.0862, -0.0348, -0.1401, -0.1310,  0.1732,  0.1010,\n",
      "           0.0470,  0.1579,  0.0137]],\n",
      "\n",
      "        [[ 0.4086,  0.3932, -0.6372,  0.1510,  0.2756,  0.0483, -0.1753,\n",
      "          -0.1204, -0.3082, -0.4432],\n",
      "         [-0.6124, -0.5892,  0.9550, -0.2263, -0.4131, -0.0723,  0.2627,\n",
      "           0.1804,  0.4619,  0.6643],\n",
      "         [ 0.8650,  0.8322, -1.3488,  0.3196,  0.5834,  0.1022, -0.3711,\n",
      "          -0.2548, -0.6523, -0.9382],\n",
      "         [-1.7733, -1.7062,  2.7652, -0.6551, -1.1961, -0.2095,  0.7608,\n",
      "           0.5225,  1.3374,  1.9235]],\n",
      "\n",
      "        [[-0.4382, -0.0066, -0.2317,  0.1687,  0.2072,  0.0751,  0.3196,\n",
      "          -0.0360,  0.4175,  0.0554],\n",
      "         [ 0.8680,  0.0131,  0.4590, -0.3341, -0.4105, -0.1487, -0.6331,\n",
      "           0.0713, -0.8271, -0.1098],\n",
      "         [ 1.0424,  0.0157,  0.5512, -0.4012, -0.4929, -0.1786, -0.7602,\n",
      "           0.0856, -0.9932, -0.1319],\n",
      "         [ 2.1216,  0.0320,  1.1219, -0.8166, -1.0033, -0.3634, -1.5473,\n",
      "           0.1742, -2.0215, -0.2685]]], grad_fn=<UnsafeViewBackward>)\n",
      "grad : tensor([[[ 2.9862e-01,  8.2654e-01, -2.1583e+00,  1.0748e+00,  6.4901e-01,\n",
      "          -8.0230e-01, -1.2947e-01, -9.0896e-01, -5.9129e-01, -6.1053e-02],\n",
      "         [-3.1510e-01, -8.7216e-01,  2.2774e+00, -1.1341e+00, -6.8483e-01,\n",
      "           8.4659e-01,  1.3661e-01,  9.5914e-01,  6.2393e-01,  6.4423e-02],\n",
      "         [ 3.0310e-01,  8.3895e-01, -2.1907e+00,  1.0909e+00,  6.5876e-01,\n",
      "          -8.1435e-01, -1.3141e-01, -9.2261e-01, -6.0017e-01, -6.1970e-02],\n",
      "         [ 2.7406e-02,  7.5855e-02, -1.9807e-01,  9.8636e-02,  5.9563e-02,\n",
      "          -7.3631e-02, -1.1882e-02, -8.3420e-02, -5.4265e-02, -5.6031e-03]],\n",
      "\n",
      "        [[-1.0627e-01,  4.1393e-02,  4.1717e-02, -6.6524e-02, -5.2125e-02,\n",
      "           4.0492e-02, -6.2384e-02,  7.8607e-02,  3.3004e-02, -1.4420e-02],\n",
      "         [-1.0861e+00,  4.2308e-01,  4.2639e-01, -6.7994e-01, -5.3277e-01,\n",
      "           4.1387e-01, -6.3762e-01,  8.0344e-01,  3.3733e-01, -1.4739e-01],\n",
      "         [-3.8225e-01,  1.4889e-01,  1.5006e-01, -2.3929e-01, -1.8750e-01,\n",
      "           1.4565e-01, -2.2440e-01,  2.8276e-01,  1.1872e-01, -5.1871e-02],\n",
      "         [-2.5499e-01,  9.9325e-02,  1.0010e-01, -1.5963e-01, -1.2508e-01,\n",
      "           9.7164e-02, -1.4969e-01,  1.8862e-01,  7.9195e-02, -3.4602e-02]],\n",
      "\n",
      "        [[ 1.4430e-01, -4.4618e-01,  1.0625e+00, -6.7631e-01, -7.6532e-01,\n",
      "          -7.8152e-02, -9.0699e-01,  1.8721e+00,  9.4319e-01,  2.4194e-01],\n",
      "         [-2.7549e-01,  8.5183e-01, -2.0284e+00,  1.2912e+00,  1.4611e+00,\n",
      "           1.4920e-01,  1.7316e+00, -3.5741e+00, -1.8007e+00, -4.6190e-01],\n",
      "         [ 1.3598e-01, -4.2044e-01,  1.0012e+00, -6.3730e-01, -7.2117e-01,\n",
      "          -7.3643e-02, -8.5467e-01,  1.7641e+00,  8.8877e-01,  2.2798e-01],\n",
      "         [-2.5609e-01,  7.9182e-01, -1.8855e+00,  1.2002e+00,  1.3582e+00,\n",
      "           1.3869e-01,  1.6096e+00, -3.3224e+00, -1.6738e+00, -4.2936e-01]],\n",
      "\n",
      "        [[-1.6351e+00, -1.8566e-01,  4.9221e-01, -1.1316e-01, -1.0372e+00,\n",
      "           6.3463e-01, -5.5195e-02,  1.1599e+00,  1.9297e+00,  2.8944e-01],\n",
      "         [-3.7110e-01, -4.2136e-02,  1.1171e-01, -2.5682e-02, -2.3539e-01,\n",
      "           1.4403e-01, -1.2527e-02,  2.6323e-01,  4.3795e-01,  6.5689e-02],\n",
      "         [-1.0710e+00, -1.2161e-01,  3.2239e-01, -7.4121e-02, -6.7935e-01,\n",
      "           4.1568e-01, -3.6152e-02,  7.5970e-01,  1.2639e+00,  1.8958e-01],\n",
      "         [-8.8074e-01, -1.0000e-01,  2.6512e-01, -6.0952e-02, -5.5866e-01,\n",
      "           3.4183e-01, -2.9729e-02,  6.2473e-01,  1.0394e+00,  1.5590e-01]],\n",
      "\n",
      "        [[ 2.1120e+00, -9.1795e-02,  5.6255e-01, -8.3863e-02,  1.0399e+00,\n",
      "          -1.2047e-01, -9.3318e-01,  1.9376e+00, -2.5099e+00, -2.8721e+00],\n",
      "         [-3.3592e-01,  1.4600e-02, -8.9477e-02,  1.3339e-02, -1.6540e-01,\n",
      "           1.9162e-02,  1.4843e-01, -3.0818e-01,  3.9921e-01,  4.5682e-01],\n",
      "         [-7.7335e-02,  3.3612e-03, -2.0599e-02,  3.0708e-03, -3.8079e-02,\n",
      "           4.4113e-03,  3.4170e-02, -7.0948e-02,  9.1905e-02,  1.0517e-01],\n",
      "         [ 1.3317e-01, -5.7880e-03,  3.5471e-02, -5.2879e-03,  6.5571e-02,\n",
      "          -7.5962e-03, -5.8840e-02,  1.2217e-01, -1.5826e-01, -1.8110e-01]]],\n",
      "       grad_fn=<UnsafeViewBackward>)\n",
      "grad : tensor([[[-2.7271e-01, -1.9300e-02, -7.8821e-02, -1.1053e-01, -2.2817e-01,\n",
      "           1.0961e-01,  5.6789e-02,  1.3503e-01, -1.6009e-01, -5.2359e-03],\n",
      "         [ 1.0488e+00,  7.4226e-02,  3.0314e-01,  4.2509e-01,  8.7753e-01,\n",
      "          -4.2155e-01, -2.1840e-01, -5.1931e-01,  6.1570e-01,  2.0137e-02],\n",
      "         [ 2.6425e+00,  1.8701e-01,  7.6376e-01,  1.0710e+00,  2.2109e+00,\n",
      "          -1.0621e+00, -5.5027e-01, -1.3084e+00,  1.5513e+00,  5.0734e-02],\n",
      "         [ 1.7491e+00,  1.2378e-01,  5.0553e-01,  7.0890e-01,  1.4634e+00,\n",
      "          -7.0300e-01, -3.6422e-01, -8.6603e-01,  1.0268e+00,  3.3581e-02]],\n",
      "\n",
      "        [[ 5.5078e-02,  1.1866e-01, -9.8318e-02,  1.4797e-01, -1.2057e-03,\n",
      "           2.3916e-01, -4.4854e-02,  7.3272e-02,  1.7037e-01, -8.4492e-02],\n",
      "         [-5.6719e-01, -1.2220e+00,  1.0125e+00, -1.5238e+00,  1.2416e-02,\n",
      "          -2.4628e+00,  4.6191e-01, -7.5455e-01, -1.7545e+00,  8.7009e-01],\n",
      "         [ 7.8539e-02,  1.6920e-01, -1.4020e-01,  2.1101e-01, -1.7192e-03,\n",
      "           3.4103e-01, -6.3961e-02,  1.0448e-01,  2.4294e-01, -1.2048e-01],\n",
      "         [-7.6647e-02, -1.6513e-01,  1.3682e-01, -2.0592e-01,  1.6778e-03,\n",
      "          -3.3281e-01,  6.2420e-02, -1.0196e-01, -2.3709e-01,  1.1758e-01]],\n",
      "\n",
      "        [[ 4.6676e-01,  1.1608e+00, -1.7245e+00, -3.2167e+00,  8.3897e-01,\n",
      "           4.8351e-01,  6.7940e-01, -2.1265e+00,  2.6887e+00,  8.4719e-01],\n",
      "         [ 2.8463e-01,  7.0788e-01, -1.0516e+00, -1.9616e+00,  5.1161e-01,\n",
      "           2.9485e-01,  4.1430e-01, -1.2967e+00,  1.6396e+00,  5.1662e-01],\n",
      "         [ 2.1512e-01,  5.3501e-01, -7.9481e-01, -1.4825e+00,  3.8667e-01,\n",
      "           2.2284e-01,  3.1312e-01, -9.8006e-01,  1.2392e+00,  3.9045e-01],\n",
      "         [ 1.0486e-01,  2.6079e-01, -3.8744e-01, -7.2267e-01,  1.8848e-01,\n",
      "           1.0863e-01,  1.5263e-01, -4.7774e-01,  6.0405e-01,  1.9033e-01]],\n",
      "\n",
      "        [[ 1.2860e+00,  1.0551e+00, -1.5442e+00,  1.6006e+00, -6.1650e-01,\n",
      "           1.3282e+00,  5.1489e-01, -1.2951e+00,  1.6959e+00, -2.0513e+00],\n",
      "         [-1.1810e+00, -9.6896e-01,  1.4182e+00, -1.4700e+00,  5.6619e-01,\n",
      "          -1.2198e+00, -4.7287e-01,  1.1894e+00, -1.5575e+00,  1.8839e+00],\n",
      "         [ 1.8358e-01,  1.5062e-01, -2.2045e-01,  2.2850e-01, -8.8011e-02,\n",
      "           1.8962e-01,  7.3505e-02, -1.8489e-01,  2.4211e-01, -2.9284e-01],\n",
      "         [ 8.8730e-01,  7.2799e-01, -1.0655e+00,  1.1044e+00, -4.2538e-01,\n",
      "           9.1647e-01,  3.5527e-01, -8.9360e-01,  1.1702e+00, -1.4154e+00]],\n",
      "\n",
      "        [[-2.2421e+00, -4.5483e+00,  1.8392e+00, -1.6100e+00,  3.9646e-01,\n",
      "          -1.3862e+00, -9.3612e-01, -2.1831e+00, -9.3295e-01,  3.2483e+00],\n",
      "         [ 2.1083e+00,  4.2769e+00, -1.7294e+00,  1.5139e+00, -3.7280e-01,\n",
      "           1.3035e+00,  8.8025e-01,  2.0528e+00,  8.7728e-01, -3.0544e+00],\n",
      "         [-2.5956e+00, -5.2655e+00,  2.1292e+00, -1.8639e+00,  4.5897e-01,\n",
      "          -1.6048e+00, -1.0837e+00, -2.5273e+00, -1.0801e+00,  3.7604e+00],\n",
      "         [-2.0170e-01, -4.0918e-01,  1.6546e-01, -1.4484e-01,  3.5666e-02,\n",
      "          -1.2471e-01, -8.4215e-02, -1.9639e-01, -8.3930e-02,  2.9222e-01]]],\n",
      "       grad_fn=<UnsafeViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "def f(x,y_i): \n",
    "    return 1/2*torch.norm(x@beta-y_i)**2\n",
    "\n",
    "def F(beta): \n",
    "    return 1/2*torch.mean(torch.norm(Y-X@beta, dim = (1))**2)\n",
    "def grad_f(beta,y_i,x_i): \n",
    "    return torch.outer(x_i, y_i-x_i@beta)\n",
    "\n",
    "def grad_F(beta): \n",
    "    return torch.mean(torch.matmul(X.unsqueeze(2), (Y-X@beta).unsqueeze(1)) , axis = 0)\n",
    "    \n",
    "def batch_grad(beta,x_batch, y_batch): \n",
    "    return torch.matmul(x_batch.unsqueeze(2), (y_batch-x_batch@beta).unsqueeze(1))\n",
    "def fit(optim, nb_step):\n",
    "    beta = torch.zeros((d,p),requires_grad = True)\n",
    "    optim = torch.optim.SGD([beta], lr = 0.5)\n",
    "    for i in range(nb_step): \n",
    "        optim.zero_grad()\n",
    "        loss = F(beta) \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    print('res :', beta)\n",
    "    print('grad :', grad_F(beta))\n",
    "    for x_b,y_b, indices in get_batch(X,Y, 5): \n",
    "        print('grad :', batch_grad(beta, x_b, y_b))\n",
    "fit(torch.optim.Rprop, 1000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGA(Optimizer):\n",
    "    '''\n",
    "    This class aims at defining the SAGA optimizer in pytorch, deriving from \n",
    "    the torch.optim class. We hope that we will be able to call torch.optim.SAGA \n",
    "    and the attributes (such as .step, .zero_grad) as we do for torch.optim.SGD\n",
    "    '''\n",
    "    def __init__(self, params, init_grads, lr):\n",
    "        '''\n",
    "        initialization for the SAGA optimizer. \n",
    "        \n",
    "        args : \n",
    "            params : list with each parameters\n",
    "            lr : learning rate \n",
    "            init_grad : for each param in params, for each sample \n",
    "            in the samples we have, we need a first gradient to store. \n",
    "            We will associate to each sample i the gradient of the corresponding function i  \n",
    "            evaluated in the starting point. It should be a list of size len(params).\n",
    "            For each k, the size of init_grad[k] should be : (sample_size, param[k].shape)\n",
    "        '''\n",
    "        dims = [param.shape for param in params]\n",
    "        print('dims :', dims)\n",
    "            \n",
    "        # set a warning message if all the sample size are differents. \n",
    "        sample_size = init_grads[0].shape[0]\n",
    "        defaults = dict(lr=lr, table = init_grads)#, momentum=momentum, dampening=dampening,\n",
    "                        #weight_decay=weight_decay, nesterov=nesterov)\n",
    "        super(SAGA, self).__init__(params, defaults)\n",
    "        \n",
    "    \n",
    "    def __setstate__(self, state):\n",
    "        super(SAGA, self).__setstate__(state)\n",
    "        for group in self.param_groups:\n",
    "            group.setdefault('nesterov', False)\n",
    "            \n",
    "    @torch.no_grad()\n",
    "    def step(self, batch_grads, selected_indices):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "        Args:\n",
    "            batch_grads : list that contains the gradients computed for a subset \n",
    "            of the samples. should be a list of size nb_params and each item\n",
    "            should be of size (batch_size, shape of the parameter)\n",
    "            \n",
    "            selected_indices : list of indices, the ones we used to estimate the gradient with.\n",
    "            \n",
    "        \"\"\"\n",
    "        grads = [torch.mean(batch_grad, axis = 0) for batch_grad in batch_grads]\n",
    "        print('grads :', grads)\n",
    "        loss = None\n",
    "        \n",
    "        for group in self.param_groups:\n",
    "            params_with_grad = []\n",
    "            d_p_list = []\n",
    "            old_grads = []\n",
    "            #momentum_buffer_list = []\n",
    "            #weight_decay = group['weight_decay']\n",
    "            #momentum = group['momentum']\n",
    "            #dampening = group['dampening']\n",
    "            #nesterov = group['nesterov']\n",
    "            lr = group['lr']\n",
    "            for i,param in enumerate(group['params']):\n",
    "                if param.grad is not None:\n",
    "                    params_with_grad.append(param)\n",
    "                    d_p_list.append(grads[i])\n",
    "                    print('groupe table', group['table'][i].shape)\n",
    "                    old_grads.append(group['table'][i][selected_indices])\n",
    "                    \n",
    "                    state = self.state[param]\n",
    "                    #if 'momentum_buffer' not in state:\n",
    "                    #    momentum_buffer_list.append(None)\n",
    "                    #else:\n",
    "                    #    momentum_buffer_list.append(state['momentum_buffer'])\n",
    "            saga_step(params_with_grad,d_p_list,interval)\n",
    "            '''\n",
    "            F.sgd(params_with_grad,\n",
    "                  d_p_list,\n",
    "                  momentum_buffer_list,\n",
    "                  weight_decay=weight_decay,\n",
    "                  momentum=momentum,\n",
    "                  lr=lr,\n",
    "                  dampening=dampening,\n",
    "                  nesterov=nesterov)\n",
    "            \n",
    "            # update momentum_buffers in state\n",
    "            for p, momentum_buffer in zip(params_with_grad, momentum_buffer_list):\n",
    "                state = self.state[p]\n",
    "                state['momentum_buffer'] = momentum_buffer\n",
    "            '''\n",
    "        return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dims : [torch.Size([15, 4]), torch.Size([8, 6])]\n",
      "groupe table torch.Size([3, 15, 4])\n",
      "groupe table torch.Size([3, 8, 6])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'saga_step' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-2c93a15b8cf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_bis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_bis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msaga\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-125-e8bc2ccef3f3>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, interval, closure)\u001b[0m\n\u001b[1;32m     67\u001b[0m                     \u001b[0;31m#else:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                     \u001b[0;31m#    momentum_buffer_list.append(state['momentum_buffer'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0msaga_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_p_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             '''\n\u001b[1;32m     71\u001b[0m             F.sgd(params_with_grad,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'saga_step' is not defined"
     ]
    }
   ],
   "source": [
    "saga = SAGA([y,y_bis],init_grads, 0.1)\n",
    "y.grad = torch.clone(y)\n",
    "y_bis.grad = torch.clone(y_bis)\n",
    "saga.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.zeros((15,4), requires_grad = True)\n",
    "y_bis = torch.zeros((8,6), requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 15, 4])\n"
     ]
    }
   ],
   "source": [
    "first_init = torch.cat((2*(y-2).unsqueeze(0), 2*(y-1).unsqueeze(0), 2*(y-4).unsqueeze(0)),0)\n",
    "second_init = torch.cat((2*(y_bis-2).unsqueeze(0), 2*(y_bis-1).unsqueeze(0), 2*(y_bis-4).unsqueeze(0)),0)\n",
    "print(first_init.shape)\n",
    "init_grads = [first_init, second_init]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
