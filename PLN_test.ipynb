{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "automated-dispute",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradient_descent import gradient_descent, minibatch_class\n",
    "import utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import scipy.linalg as SLA \n",
    "from scipy.linalg import toeplitz \n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "desperate-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction des données \n",
    "Y_tricho = torch.from_numpy(read_csv('trichoptera.csv', sep=',').to_numpy())\n",
    "O_tricho = torch.outer(Y_tricho.sum(1), torch.ones(Y_tricho.shape[1]))/1000\n",
    "\n",
    "n_tricho,p_tricho = Y_tricho.shape \n",
    "d_tricho = 4\n",
    "covariates_tricho = torch.ones((n_tricho,d_tricho))\n",
    "\n",
    "data_tricho = [Y_tricho,O_tricho, covariates_tricho]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-geography",
   "metadata": {},
   "source": [
    "## The Poisson lognormal (PLN) model\n",
    "\n",
    "\n",
    "- Consider $n$ sites $(i=1 \\ldots n)$\n",
    "\n",
    "- Measure $x_{i}=\\left(x_{i h}\\right)_{1 \\leq h \\leq d}$ :\n",
    "$x_{i h}=$ given environmental descriptor (covariate) for site $i$\n",
    "(altitude, temperature, latitude, ...)\n",
    "\n",
    "- Consider $p$ species $(j=1 \\ldots p)$ Measure $Y=\\left(Y_{i j}\\right)_{1 \\leq i \\leq n, 1 \\leq j \\leq p}$ :\n",
    "\n",
    "- Measure $Y = Y_{i j}=$ number of observed individuals from species $j$ in site $i$ (abundance). \n",
    "\n",
    "- Associate a random vector $Z_{i}$ with each site Assume that the unknown $\\left(Z_{i}\\right)_{1 \\leq i \\leq n}$ are iid (no spatial structure):\n",
    "$$\n",
    "Z_{i} \\sim \\mathcal{N}_{p}(0, \\Sigma)\n",
    "$$\n",
    "- Assume that the observed abundances $\\left(Y_{i j}\\right)_{1 \\leq i \\leq n, 1 \\leq j \\leq p}$ are independent conditionally on the $Z=\\left(Z_{i}\\right)_{i}$\n",
    "\n",
    "\n",
    "$$\n",
    "\\left(Y_{i j} \\mid Z_{i j}\\right) \\sim \\mathcal{P}\\left(\\exp \\left(o_{i j}+x_{i}^{\\top} \\beta_{j}+Z_{i j}\\right)\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "The parameter of the model is $\\theta = (\\beta, \\Sigma)$. \n",
    "\n",
    "Since the model depends on latent variables, we want to apply the EM algortihm. However, EM requires to compute the following : \n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{\\theta}\\left[p_{\\theta}\\left(Z_{i} \\mid Y\\right)\\right]=\\mathbb{E}_{\\theta}\\left[p_{\\theta}\\left(Z_{i} \\mid Y_{i}\\right)\\right] \\propto \\int_{\\mathbb{R}^{p}} p_{\\Sigma}\\left(Z_{i}\\right) \\prod_{j} p_{\\theta}\\left(Y_{i j} \\mid Z_{i j}\\right) \\mathrm{d} Z_{i}\n",
    "$$\n",
    "\n",
    "Which is intractable in practice. \n",
    "\n",
    "We have two alternatives here. The first one is an approximation of this integral via MCMC methods. The second one is the variationnal approach. We adopt here the second approach. \n",
    "\n",
    "The goal of variationnal approach is to approximate $p_{\\theta}(Z \\mid Y)$ with some law $q^{\\star}(Z)$ from which we can compute the expectation with respect to $\\theta$. \n",
    "\n",
    "\n",
    "We find such a law by maximizing the Evidence Lower BOund (ELBO), that is : \n",
    "$$ \n",
    "q^{\\star} = \\underset{q \\in \\mathcal{Q}}{\\operatorname{argmax}} J_{\\theta,q}(Y) \n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "\\begin{align} J_{\\theta, q}(Y)& =\\log p_{\\theta}(Y)-K L\\left[q(Z) \\| p_{\\theta}(Z \\mid Y)\\right]                                    \\\\ \n",
    "                              & = \\mathbb{E}_{q}\\left[\\log p_{\\theta}(Y, Z)\\right] \\underbrace{-\\mathbb{E}_{q}[\\log q(Z)]}_{\\text {entropy } \\mathcal{H}(q)}    \\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "Where $\\mathcal{Q}$ is a set of distributions. \n",
    "The Variational EM (VEM) consists in alternate between two steps : \n",
    "- VE step: update $q$\n",
    "$$\n",
    "q^{h+1}=\\underset{q \\in \\mathcal{Q}}{\\arg \\max } J_{\\theta^{h}, q}(Y)=\\underset{q \\in \\mathcal{Q}}{\\arg \\min } K L\\left[q(Z) \\| p_{\\theta^{h}}(Z \\mid Y)\\right]\n",
    "$$\n",
    "- M step: update $\\theta$\n",
    "$$\n",
    "\\theta^{h+1}=\\underset{\\theta}{\\arg \\max } J_{\\theta, q^{h+1}}(Y)=\\underset{\\theta}{\\arg \\max } \\mathbb{E}_{q^{h+1}}\\left[\\log p_{\\theta}(Y, Z)\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-river",
   "metadata": {},
   "source": [
    "# VEM for PLN \n",
    "\n",
    "We consider \n",
    "$$\n",
    "\\mathcal{Q}_{\\text {Gauss }}=\\{q: q=\\mathcal{N}(m, S)\\}\n",
    "$$\n",
    "\n",
    "The parameters $M = (m_i)_{1\\leq i \\leq n} \\in \\mathbb{R}^{n\\times p}$  and $ S = (S_i)_{1\\leq i \\leq n} \\in \\mathbb{R}^{n\\times p} $ are called variational parameters whereas $\\theta = (\\beta,\\Sigma)$ is called model parameter.  \n",
    "\n",
    "The ELBO can be computed as : \n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "J_{\\theta, q}(Y)=& \\sum_{i} \\mathbb{E}_{q_{i}}\\left[\\log p_{\\theta}\\left(Z_{i}\\right)\\right]+\\sum_{i} \\mathbb{E}_{q_{i}}\\left[\\log p_{\\theta}\\left(Y_{i} \\mid Z_{i}\\right)\\right]+\\sum_{i} \\mathcal{H}\\left[\\mathcal{N}\\left(m_{i}, S_{i}\\right)\\right] \\\\\n",
    "=&-\\frac{n}{2} \\log |\\Sigma|-\\frac{1}{2} \\sum_{i} \\mathbb{E}_{\\mathcal{N}\\left(\\cdot m_{i}, S_{i}\\right)}\\left[Z_{i}^{\\top} \\Sigma^{-1} Z_{i}\\right] \\\\\n",
    "&+\\sum_{i, j} \\mathbb{E}_{\\mathcal{N}\\left(\\cdot ; m_{i}, S_{i}\\right)}\\left[-\\exp \\left(o_{i j}+x_{i}^{\\top} \\beta_{j}+Z_{i j}\\right)+Y_{i j}\\left(\\rho_{i j}+x_{i}^{\\top} \\beta_{j}+Z_{i j}\\right)\\right] \\\\\n",
    "&+\\frac{1}{2} \\sum_{i} \\log \\left|S_{i}\\right|+\\mathrm{cst}\n",
    "\\end{aligned}\n",
    "$$\n",
    "We can evaluate some moments of $Z$ : \n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}_{\\mathcal{N}\\left(\\cdot ; m_{i}, s_{i}\\right)}\\left(Z_{i}\\right) &=m_{i}, & \\mathbb{E}_{\\mathcal{N}\\left(\\cdot ; m_{i}, S_{i}\\right)}\\left(Z_{i}^{\\top} \\Sigma^{-1} Z_{i}\\right)=m_{i}^{\\top} \\Sigma^{-1} m_{i}+\\operatorname{tr}\\left(\\Sigma^{-1} S_{i}\\right) \\\\\n",
    "\\mathbb{E}_{\\mathcal{N}\\left(\\cdot ; m_{i}, S_{i}\\right)}\\left(e^{Z_{i j}}\\right) &=\\exp \\left(m_{i j}+\\left[S_{i}\\right]_{j j}^{2} / 2\\right) &\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We then get : \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "J_{\\theta, q}(y) &=-\\frac{n}{2} \\log |\\Sigma|-\\frac{1}{2} \\sum_{i} m_{i}^{\\top} \\Sigma^{-1} m_{i}+tr\\left(\\Sigma^{-1} S_{i}\\right) \\\\\n",
    "&+\\sum_{i, j}-\\exp \\left(o_{i j}+x_{i}^{T} \\beta_{j}+m_{i j}+\\left[S_{i}\\right]_{j j}^{2} / 2\\right)+Y_{i j}\\left(o_{i j}+x_{i}^{T} \\beta_{j}+m_{i j}\\right) \\\\\n",
    "&+\\frac{1}{2} \\sum_{i} \\log \\left|S_{i}\\right|+c s t .\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "% the problem is convex if the S_i are diagonals. %\n",
    "\n",
    "We have a closed form for the M step, that is : \n",
    "\n",
    "$$\n",
    "\\widehat{\\Sigma}=\\frac{1}{n} \\sum_{i}\\left(m_{i} m_{i}^{\\top}+S_{i}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{\\beta}}=\\left(\\mathbf{X}^{\\top} \\mathbf{X}\\right)^{-1} \\mathbf{X} \\mathbf{M}\n",
    "$$\n",
    "\n",
    "However, we don't have a closed form for the VE step. \n",
    "\n",
    "We consider now $S$ as $(n,p)$ matrix. Indeed, we consider the $S_i$ as diagonal matrices so we only need $p$ points to encode each of them. Considering $S$ this way is simpler for calculus. Here are the gradients with respect to the variational parameters. \n",
    "\n",
    "$$\n",
    "\\nabla_{M} J=-M \\Sigma^{-1}-\\exp \\left(O+x \\beta+M+\\frac{S \\odot S}{2}\\right)+Y\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\nabla_{S} J=-\\frac{1}{2}\\mathbb{1}_{n}\\mathbb{1}_{p}^{T} D_{\\Sigma^{-1}}-S\\odot  \\exp \\left(0+X \\beta+M+\\frac{S \\odot  S}{2}\\right)+\\frac{1}{2} \\frac{1}{S}\n",
    "$$\n",
    "\n",
    "\n",
    "We denote $D_{\\Sigma^{-1}}$ the diagonal matrix composed of thof the diagonal of $\\Sigma^{-1}$. The exponential is applied component-wise, as well as the division $\\frac 1 S$. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "imperial-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sample_PLN(): \n",
    "    def __init__(self): \n",
    "        pass \n",
    "\n",
    "    def sample(self, Sigma, beta, O, covariates): \n",
    "        '''\n",
    "        sample Poisson log Normal variables. \n",
    "        The number of samples is the the first size of O, the number of species\n",
    "        considered is the second size of O\n",
    "        The number of covariates considered is the first size of beta. \n",
    "        \n",
    "        '''\n",
    "        self.Sigma = Sigma # unknown parameter in practice\n",
    "        self.beta = beta #unknown parameter in practice\n",
    "        \n",
    "        self.O = O \n",
    "        self.covariates = covariates\n",
    "        \n",
    "        self.Z = torch.stack([self.Sigma@np.random.randn(p) for _ in range(n)]) \n",
    "        \n",
    "        self.n = self.O.shape[0]\n",
    "        self.p = self.Sigma.shape[0]\n",
    "        self.d = self.covariates.shape[1]\n",
    "        \n",
    "        parameter = torch.exp(self.O + self.covariates@self.beta + self.Z)\n",
    "        self.Y = np.random.poisson(lam = parameter)\n",
    "        return self.Y \n",
    "    \n",
    "    def plot_Y(self): \n",
    "        '''\n",
    "        plot all the Y_ij sampled before. There will be n*p values in total. The color represent the site number. \n",
    "        Note that we need to have called self.sample() before otherwise it won't print anything \n",
    "        '''\n",
    "        color = np.array([[site]*self.p for site in range(self.n) ]).ravel()*10\n",
    "        plt.scatter(np.arange(0,self.n*self.p),self.Y.ravel(), c = color, label = 'color = site number')\n",
    "        plt.legend()\n",
    "        plt.ylabel('count number')\n",
    "        plt.show()\n",
    "\n",
    "    def conditionalprior(self): \n",
    "        mu = self.O[0,0]\n",
    "        functions = list()\n",
    "        for i in range(self.n): \n",
    "            mu_i = self.covariates[i].dot(self.beta[0])\n",
    "            functions.append(lambda z : -z**2/(2*self.Sigma[0,0]**2)-np.exp(mu_i+z)+float(self.Y[i])*(mu_i+z))\n",
    "        return functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "desirable-infrared",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PLNmodel(): \n",
    "    '''\n",
    "    PLN model. The goal of this class is to compute the parameter beta and Sigma of the PLN model. \n",
    "    We use here variationnal approximation since we can't compute the log likelihood of the \n",
    "    latent variables given the data. \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, Sigma_init, beta_init, M_init, S_init): \n",
    "        \n",
    "        '''\n",
    "            Initialization : \n",
    "            'Y' : the data, size (n,p). n is the number of samples we have and p the number of species. \n",
    "                  THE TYPE IS INT\n",
    "            'O': offset : additional offset. (not very important for comprehension). size (n,p)\n",
    "            'covariates' : covariates, size (n,d)\n",
    "            'Sigma_init' : initialization for Sigma. I plan to do a more advanced initialization. \n",
    "            'beta_init ' : Initialization for beta. I plan to do a more advanced initialization. \n",
    "            'M_init' : initialization for the variational parameter M\n",
    "            'S_init ': initialization for the variational parameter S\n",
    "        '''\n",
    "        \n",
    "        # model parameters\n",
    "        self.Sigma = torch.clone(Sigma_init)\n",
    "        self.Sigma.requires_grad_(True)\n",
    "        self.beta = torch.clone(beta_init)\n",
    "        self.beta.requires_grad_(True)\n",
    "        \n",
    "        #variational parameters\n",
    "        self.M = torch.clone(M_init)\n",
    "        self.M.requires_grad_(True)\n",
    "        self.S = torch.clone(S_init) \n",
    "        self.S.requires_grad_(True)\n",
    "        \n",
    "        # some useful variables\n",
    "        self.det_Sigma = torch.det(self.Sigma)\n",
    "        self.inv_Sigma = torch.inverse(self.Sigma)\n",
    "        \n",
    "        # optimizer for the VE_step\n",
    "        self.VE_step_optimizer = torch.optim.Adam([self.S,self.M], lr = 0.01)\n",
    "        self.VE_step_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.VE_step_optimizer, patience = 3, factor = 0.9)\n",
    "        \n",
    "        #optimizer for the M_step\n",
    "        self.M_step_optimizer = torch.optim.Adam([self.beta])\n",
    "        self.M_step_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.M_step_optimizer, patience = 3, factor = 0.9)        \n",
    "    \n",
    "    def compute_ELBO(self): \n",
    "        ''' \n",
    "        computes the ELBO. We simply apply the formula given above. \n",
    "        '''\n",
    "        \n",
    "        inv_Sigma = torch.inverse(self.Sigma)\n",
    "        tmp = -self.n/2*torch.log(torch.det(self.Sigma))\n",
    "        \n",
    "        # formula with the quadratic function and the trace \n",
    "        tmp -=1/2*( torch.sum(torch.mm(torch.mm(self.M,inv_Sigma),self.M.T).diagonal()))   # we can simplify here, takes too much time \n",
    "                                                                                           # we should remove the diagonal and do a more efficient multiplication\n",
    "                                            \n",
    "                        \n",
    "        Gram_matrix = torch.mm(self.covariates,self.beta) # matrix with term (i,j): <x_i,beta_j>\n",
    "        \n",
    "        Exp_moment = torch.exp(self.M + torch.pow(self.S,2)/2)\n",
    "        \n",
    "        tmp += torch.sum(-torch.exp(self.O + Gram_matrix + self.M + torch.pow(self.S,2)/2) + torch.multiply(self.Y, self.O + Gram_matrix + self.M))\n",
    "        \n",
    "        for i in range(self.n): \n",
    "            tmp += 1/2* torch.log(self.S[i,:].prod())\n",
    "            tmp -= 1/2 * torch.trace(torch.multiply(inv_Sigma,self.S[i,:]))\n",
    "            \n",
    "        return tmp\n",
    "          \n",
    "        \n",
    "    # we define here the gradients computed manually as a sanity check. We can check that they are equals \n",
    "    # to the gradients computed with the autodifferentiation of pytorch (diff = 1e-15)\n",
    "    def grad_Sigma(self): \n",
    "        with torch.no_grad():\n",
    "            self.inv_Sigma = torch.inverse(self.Sigma)\n",
    "            grad = -self.n/2*(self.inv_Sigma)# + torch.diag(torch.diagonal(self.inv_Sigma))) on a enlevé car avec ça ca match avec pytorch. \n",
    "            grad += 1/2*(sum([self.inv_Sigma@(torch.outer(self.M[i,:],self.M[i,:])+ torch.diag(self.S[i,:]))@self.inv_Sigma  for i in range(self.n)]))\n",
    "        return grad\n",
    "    def grad_M(self): \n",
    "        with torch.no_grad():\n",
    "            grad = -torch.mm(self.M,self.inv_Sigma)\n",
    "            grad -= torch.exp(self.O + torch.mm(self.covariates,self.beta) + self.M + torch.pow(self.S,2)/2)\n",
    "            grad += self.Y \n",
    "        return grad \n",
    "    def grad_S(self):\n",
    "        with torch.no_grad():\n",
    "            grad = -1/2*torch.mm(torch.ones((self.n,self.p)), torch.diag(torch.diag(self.inv_Sigma)))\n",
    "            grad-= torch.mul(self.S,torch.exp(self.O + torch.mm(self.covariates,self.beta) + self.M + torch.pow(self.S,2)/2))\n",
    "            grad += 1/2*torch.div(1,self.S)\n",
    "        return grad \n",
    "    def grad_beta(self): \n",
    "        with torch.no_grad():\n",
    "            grad = - torch.mm(self.covariates.T,torch.exp( self.O + self.M + torch.pow(self.S,2)/2 + torch.mm(self.covariates,self.beta)))\n",
    "            grad += torch.mm(self.covariates.T,self.Y.double())\n",
    "        return grad \n",
    "    \n",
    "    \n",
    "    \n",
    "    def torch_gradient_ascent(self,optimizer, scheduler, params, params_names, lr = None, tolerance = 2, Niter_max = 500, verbose = True): \n",
    "        '''\n",
    "        gradient ascent function. We compute the gradients thanks to the autodifferentiation of pytorch. \n",
    "        \n",
    "        args : \n",
    "                'optimizer' : torch.optim.optimizer. the optimizer for the parameters. \n",
    "                'scheduler' : torch.optim.lr_scheduler.  scheduler for the optimizer above. \n",
    "                \n",
    "                # I will generalize this with dictionnaries \n",
    "                'params' : torch.Tensor . the params we want to optimize. they should have required_grad = True. \n",
    "                'params_names' : the names of the parameter \n",
    "                \n",
    "                'lr' : float.  a learning rate if we want to set the optimizer learning rate to a certain lr. If None, \n",
    "                      it will take the actual learning_rate of the optimizer. \n",
    "                'tolerance': float. the threshold we set to stop the algorithm. It will stop if the norm of each gradient's parameter \n",
    "                             is lower than this threshold. \n",
    "                'Niter_max': int. the Maximum number of iterations we are ready to do. \n",
    "                \n",
    "                'Verbose' : bool. if True, will print some messages useful to interpret the gradient ascent. If False, nothing will be printed. \n",
    "        \n",
    "        returns : the parameters optimized. \n",
    "        '''\n",
    "        \n",
    "        \n",
    "        # we set the gradient to zero just to make sure the gradients are properly calculated\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if lr is not None : # if we want to set a threshold, we set it. Ohterwise, we skip this condition and keep the actual learning_rate\n",
    "            optimizer.param_groups[0]['lr'] = lr \n",
    "        \n",
    "        stop_condition = False \n",
    "        i = 0 \n",
    "        \n",
    "        while i < Niter_max and stop_condition == False: \n",
    "            optimizer.zero_grad()\n",
    "            loss = -self.compute_ELBO()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(loss)\n",
    "            self.current_ELBO = -loss.item()\n",
    "            \n",
    "            # condition to see if we have reach the tolerance threshold\n",
    "            if max([torch.norm(param.grad) for param in params]) < tolerance : \n",
    "                stop_condition = True \n",
    "                \n",
    "            i += 1 \n",
    "        if verbose : # just print some stats if we want to \n",
    "            if stop_condition : \n",
    "                print('---------------------------------Tolerance reached in {} iterations'.format(i))\n",
    "            else : \n",
    "                print('---------------------------------Maximum number of iterations reached')\n",
    "            self.print_stats(loss, params, params_names, optimizer)    \n",
    "        return params\n",
    "        \n",
    "\n",
    "    def print_stats(self, loss, params, params_names, optimizer): \n",
    "        '''\n",
    "        small function that print some stats. \n",
    "        \n",
    "        It will print the actual learning rate of the optimizer, the actual log likelihood \n",
    "        and the norms of each parameter's gradient. The norm of the parameter's gradient should be low\n",
    "        when we are close to the optimum. \n",
    "        '''\n",
    "        \n",
    "        print('---------------------------------lr :', optimizer.param_groups[0]['lr'])\n",
    "        print('---------------------------------log likelihood :', - loss.item())\n",
    "        for param, param_name in zip(params,params_names): \n",
    "            print('---------------------------------grad_{}_norm : '.format(param_name), round(torch.norm(param.grad).item(), 3))\n",
    "    \n",
    "     \n",
    "            \n",
    "    def VE_step(self, lr = None, tolerance = 2, Niter_max = 500, verbose = True  ): \n",
    "        '''\n",
    "        VE_step : optimize the variational parameter. \n",
    "        We don't have a closed form for the parameters M and S so we have to do a gradient \n",
    "        ascent to do optimize them. \n",
    "        \n",
    "        args : \n",
    "             'lr' : learning if we want to set the learning rate of the optimizer\n",
    "        '''\n",
    "        \n",
    "        self.torch_gradient_ascent(self.VE_step_optimizer, self.VE_step_scheduler, [self.M,self.S], ['M', 'S'], lr = lr,\n",
    "                                    tolerance= tolerance, Niter_max= Niter_max, verbose= verbose)\n",
    "    def M_step(self,  lr = None, tolerance = 2, Niter_max = 500, verbose = True  ):\n",
    "        \n",
    "        '''\n",
    "        Optimize the model parameters. \n",
    "        We have a closed form for Sigma so we actually don't need to do a gradient ascent for Sigma, just apply the formula. \n",
    "        We do a gradient ascent for beta. \n",
    "        '''\n",
    "\n",
    "        # closed form for Sigma, we don't need to optimize\n",
    "        with torch.no_grad(): \n",
    "            self.Sigma = 1/self.n*(torch.sum(torch.stack([torch.outer(self.M[i,:],self.M[i,:]) + torch.diag(self.S[i,:])  for i in range(self.n)]), axis = 0))\n",
    "        \n",
    "        # gradient ascent to optimize beta, the model parameter\n",
    "        self.torch_gradient_ascent(self.M_step_optimizer, self.M_step_scheduler, [self.beta], ['beta'], lr = lr,\n",
    "                                    tolerance = tolerance, Niter_max= Niter_max, verbose= verbose)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def VEM(self,data, number_VEM_step ,  beginning_M_S_lr = 0.1, beginning_beta_lr = 0.1 ): \n",
    "        '''\n",
    "        function to optimize both the variational parameters and the model parameters.\n",
    "        We alternate between two steps : Variational step (VE_step) and Maximization step (M_step). \n",
    "        \n",
    "        \n",
    "        args : \n",
    "            'number_VEM_step' : int . Number of times we want to do the VEM step, i.e. alternate between VE step and M step. \n",
    "                                The greater the better the approximation, the greater the longer time it takes. \n",
    "            \n",
    "            'beginning_VE_step_lr' : float. the beginning of the learning for the VE_step. The VE will start with this lr. \n",
    "            'beginning_M_step_lr' : float. Same for beta, the M step will start with this lr. \n",
    "            \n",
    "       returns : \n",
    "               M_S_lr, beta_lr : the learning rates of both steps, so that we can continue after that with the appropriate learning rates.  \n",
    "        ''' \n",
    "        # we first extract the data. \n",
    "        self.extract_data(data)\n",
    "        \n",
    "        # we start with one VEM step with the appropriate learning_rate\n",
    "        self.VE_step(verbose = False, tolerance = 0.1, Niter_max = 20, lr = beginning_M_S_lr)\n",
    "        self.M_step(verbose = False, tolerance = 0.1, Niter_max = 50, lr = beginning_beta_lr)\n",
    "        \n",
    "        # we do as many VEM_step we are asked to. \n",
    "        for i in range(number_VEM_step): \n",
    "            self.VE_step(verbose = False, tolerance = 0.1, Niter_max = 20)\n",
    "            self.M_step(verbose = False, tolerance = 0.1, Niter_max = 50)\n",
    "            print('-------UPDATE-------')\n",
    "            print(' MSE with Sigma : ', round(torch.mean((self.Sigma-true_Sigma)**2).item()),6)\n",
    "            print(' MSE with beta : ', round(torch.mean((self.beta-true_beta)**2).item()),6)\n",
    "            print('ELBO : ', round(self.current_ELBO),6)\n",
    "        return self.VE_step_optimizer.param_groups[0]['lr'],self.M_step_optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    def extract_data(self,data): \n",
    "        '''\n",
    "        function to extract the data. This function is just here to have a code more compact. \n",
    "        \n",
    "        args : \n",
    "              'data': list with 3 elements : Y, O and covariates in this order. \n",
    "        '''\n",
    "        \n",
    "        #known variables\n",
    "        self.Y = data[0];self.O = data[1];self.covariates = data[2]\n",
    "    \n",
    "        self.n, self.p = self.Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "rural-novelty",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2 # nb of cavariates\n",
    "n = 200; p = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-ordinary",
   "metadata": {},
   "source": [
    "\n",
    "d = 2 # nb of cavariates\n",
    "n = 200; p = 50\n",
    "\n",
    "\n",
    "Does not work very well : \n",
    "\n",
    "$MSE_{Sigma} = 1.15$ : probably stock in a local minima. \n",
    "$MSE_{beta} = 0.95$\n",
    "lr = 0.1 for both \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "plastic-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "noise = torch.randn(p,p) \n",
    "Sigma_init =  (noise+ noise.T)\n",
    "beta_init = torch.rand((d, p))\n",
    "\n",
    "M_init = torch.ones((n,p))/100# some random values to initialize we divide to avoid nan values \n",
    "S_init = torch.ones((n,p))/8 # some random values to initializ. we divise to avoid nan values \n",
    "\n",
    "covariates = torch.ones((n,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "stock-powder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "true_Sigma = torch.from_numpy(toeplitz(0.5**np.arange(p)))\n",
    "true_beta = torch.randn(d, p)\n",
    "\n",
    "covariates = torch.ones((n,d))\n",
    "O = 1 + torch.zeros((n,p))\n",
    "\n",
    "sample_model = sample_PLN()\n",
    "Y_sampled = torch.from_numpy(sample_model.sample(true_Sigma,true_beta, O, covariates))\n",
    "sample_model.plot_Y()\n",
    "\n",
    "data = [Y_sampled, O, covariates]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-meaning",
   "metadata": {},
   "source": [
    "sizes : \n",
    "\n",
    "$ Y : (n,p)$ \n",
    "\n",
    "$O : (n,p)$ \n",
    "\n",
    "$\\Sigma :  (p,p)$ \n",
    "\n",
    "covariates ($x$) : $(n,d)$\n",
    "\n",
    "$\\beta : (d,p)$\n",
    "\n",
    "$M : (n,p)$\n",
    "\n",
    "$S : (n,p)$ . Should be seen as $(n,p,p)$ but since all the $n$  matrix $(p,p)$ are diagonal, we only need $p$ points to encode it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "realistic-browser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.023704564481086175\n",
      " MSE with beta :  0.7565529806773551\n",
      "ELBO :  1403311.778978412\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.022959731733738203\n",
      " MSE with beta :  0.7662170391305829\n",
      "ELBO :  1435818.7043352406\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.020918880953763208\n",
      " MSE with beta :  0.772644261915382\n",
      "ELBO :  1463205.073629715\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.01881525362669799\n",
      " MSE with beta :  0.7780519677746895\n",
      "ELBO :  1486831.7286593711\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.017187499604957315\n",
      " MSE with beta :  0.7824406875774487\n",
      "ELBO :  1507297.6910804105\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.016461983262147855\n",
      " MSE with beta :  0.7860412344198449\n",
      "ELBO :  1525018.8661578647\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.016978981954389346\n",
      " MSE with beta :  0.7889582363306735\n",
      "ELBO :  1540345.5582999117\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.018975351121573038\n",
      " MSE with beta :  0.7912423528499418\n",
      "ELBO :  1553585.9310780177\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.022585940467673662\n",
      " MSE with beta :  0.7929135593042507\n",
      "ELBO :  1565011.0180013822\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.02785237867427099\n",
      " MSE with beta :  0.7939769325612089\n",
      "ELBO :  1574857.934814723\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.03473020869500835\n",
      " MSE with beta :  0.7944737864297767\n",
      "ELBO :  1583333.4561017687\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.043108616259551424\n",
      " MSE with beta :  0.794444187755694\n",
      "ELBO :  1590617.5926454663\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.05282503831004352\n",
      " MSE with beta :  0.7939302481711568\n",
      "ELBO :  1596866.6449975218\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.0636782970923059\n",
      " MSE with beta :  0.7929733114159057\n",
      "ELBO :  1602215.8974110489\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.0754443129458801\n",
      " MSE with beta :  0.7916507612158719\n",
      "ELBO :  1606782.3258420152\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.08790536746293416\n",
      " MSE with beta :  0.7900066607343157\n",
      "ELBO :  1610667.3583080072\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.10084916996066981\n",
      " MSE with beta :  0.7880621904459355\n",
      "ELBO :  1613959.550186019\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.11406439160109344\n",
      " MSE with beta :  0.7858644173706799\n",
      "ELBO :  1616736.9374023462\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.127359286097814\n",
      " MSE with beta :  0.7834689935198559\n",
      "ELBO :  1619068.9068209725\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.14057091665760582\n",
      " MSE with beta :  0.780916788303158\n",
      "ELBO :  1621017.554019695\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.1535579414113242\n",
      " MSE with beta :  0.778242761138272\n",
      "ELBO :  1622638.5973822088\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.1662001533390059\n",
      " MSE with beta :  0.775483928400908\n",
      "ELBO :  1623981.9359107695\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.17840719903129149\n",
      " MSE with beta :  0.7726826800055562\n",
      "ELBO :  1625091.9483261043\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.19012343816111973\n",
      " MSE with beta :  0.7698685817349952\n",
      "ELBO :  1626007.686288678\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.20131231077169767\n",
      " MSE with beta :  0.767058274300947\n",
      "ELBO :  1626763.0614360585\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2119447467282632\n",
      " MSE with beta :  0.7642567706102475\n",
      "ELBO :  1627387.0950077642\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.22199130650967955\n",
      " MSE with beta :  0.7614935301309441\n",
      "ELBO :  1627904.2247957962\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.23145121865084076\n",
      " MSE with beta :  0.758805260249304\n",
      "ELBO :  1628334.674279577\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.24035478264943969\n",
      " MSE with beta :  0.7562107674744445\n",
      "ELBO :  1628694.9425705732\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2487388477342086\n",
      " MSE with beta :  0.7537079857127299\n",
      "ELBO :  1628998.34517135\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2566289400456414\n",
      " MSE with beta :  0.751281635781117\n",
      "ELBO :  1629255.5685844945\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2640329996374868\n",
      " MSE with beta :  0.7489513685417655\n",
      "ELBO :  1629475.1327346445\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2709860864917832\n",
      " MSE with beta :  0.7467354505208739\n",
      "ELBO :  1629663.7863968648\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2775366915099619\n",
      " MSE with beta :  0.7446314551766976\n",
      "ELBO :  1629826.8832621041\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2837207269646067\n",
      " MSE with beta :  0.7426225213376787\n",
      "ELBO :  1629968.6962274604\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.28955143481561746\n",
      " MSE with beta :  0.7407010642359307\n",
      "ELBO :  1630092.6770061227\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2950407602426591\n",
      " MSE with beta :  0.7388815866692481\n",
      "ELBO :  1630201.6066747445\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3002263950441692\n",
      " MSE with beta :  0.7371544550860186\n",
      "ELBO :  1630297.741223752\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.30513097405725254\n",
      " MSE with beta :  0.7355071026854606\n",
      "ELBO :  1630382.9229132114\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3097661427577769\n",
      " MSE with beta :  0.7339385622789903\n",
      "ELBO :  1630458.6774483584\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.31415009537288213\n",
      " MSE with beta :  0.7324733381499258\n",
      "ELBO :  1630526.2569281103\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.31833434898720586\n",
      " MSE with beta :  0.7311021206833948\n",
      "ELBO :  1630586.6977908632\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3223403956291913\n",
      " MSE with beta :  0.7298030920904891\n",
      "ELBO :  1630640.880720132\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3261660281221586\n",
      " MSE with beta :  0.7285685078073396\n",
      "ELBO :  1630689.5786844639\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3298120377287148\n",
      " MSE with beta :  0.7274006496708003\n",
      "ELBO :  1630733.4484565482\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3332904722685367\n",
      " MSE with beta :  0.7262927462442527\n",
      "ELBO :  1630773.0526781953\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.33660778472828656\n",
      " MSE with beta :  0.7252502987574998\n",
      "ELBO :  1630808.8761870298\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.33979197520815696\n",
      " MSE with beta :  0.7242610183039369\n",
      "ELBO :  1630841.3351834808\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3428470843255802\n",
      " MSE with beta :  0.7232976116019714\n",
      "ELBO :  1630870.792117301\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.34573586952518587\n",
      " MSE with beta :  0.7224071598003138\n",
      "ELBO :  1630897.5713589978\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.34851974293950894\n",
      " MSE with beta :  0.7215836968246481\n",
      "ELBO :  1630921.9468648722\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.35122655045236306\n",
      " MSE with beta :  0.7207838742281186\n",
      "ELBO :  1630944.160320961\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3538040092165538\n",
      " MSE with beta :  0.7200387539535764\n",
      "ELBO :  1630964.4447949827\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.35629417689537723\n",
      " MSE with beta :  0.7193240956765489\n",
      "ELBO :  1630982.9983321226\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.35868919491625695\n",
      " MSE with beta :  0.7186258838441226\n",
      "ELBO :  1630999.9944892523\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.36096090724609214\n",
      " MSE with beta :  0.7179906724857292\n",
      "ELBO :  1631015.5934769493\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.36318277814948785\n",
      " MSE with beta :  0.7173731139193796\n",
      "ELBO :  1631029.9188600378\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3653082409829545\n",
      " MSE with beta :  0.7167843187393365\n",
      "ELBO :  1631043.097030285\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3673522936331747\n",
      " MSE with beta :  0.7162234062488406\n",
      "ELBO :  1631055.2342370236\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.36930992012854225\n",
      " MSE with beta :  0.7156918183626663\n",
      "ELBO :  1631066.4264506567\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3711947023916059\n",
      " MSE with beta :  0.7151692423718755\n",
      "ELBO :  1631076.7547727472\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.37298021166165224\n",
      " MSE with beta :  0.7146772567424438\n",
      "ELBO :  1631086.2935973024\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3746998214235824\n",
      " MSE with beta :  0.7142150899821218\n",
      "ELBO :  1631095.1063196433\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3763632134302016\n",
      " MSE with beta :  0.7137894706670675\n",
      "ELBO :  1631103.254798215\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.37799163390181056\n",
      " MSE with beta :  0.7133586162296762\n",
      "ELBO :  1631110.795763942\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3795272777199666\n",
      " MSE with beta :  0.7129481547660663\n",
      "ELBO :  1631117.7969356752\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.38099689582470464\n",
      " MSE with beta :  0.7125550950563815\n",
      "ELBO :  1631124.301960788\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3824124460420634\n",
      " MSE with beta :  0.712187771831719\n",
      "ELBO :  1631130.350507213\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.383788154866837\n",
      " MSE with beta :  0.7118464079983999\n",
      "ELBO :  1631135.9760023507\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3851338356291619\n",
      " MSE with beta :  0.7115133796379114\n",
      "ELBO :  1631141.211500085\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.38642760800321624\n",
      " MSE with beta :  0.7111962020237249\n",
      "ELBO :  1631146.0924428434\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3876750999145648\n",
      " MSE with beta :  0.7108929413339311\n",
      "ELBO :  1631150.6553220914\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3888842813903131\n",
      " MSE with beta :  0.7105604074450514\n",
      "ELBO :  1631154.910544853\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.38996625028771537\n",
      " MSE with beta :  0.7102829407191735\n",
      "ELBO :  1631158.9056510045\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3910577131004322\n",
      " MSE with beta :  0.7100483260351155\n",
      "ELBO :  1631162.6308458117\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3921706016313991\n",
      " MSE with beta :  0.709760415699177\n",
      "ELBO :  1631166.1072842253\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.39315737210703294\n",
      " MSE with beta :  0.7095419544030045\n",
      "ELBO :  1631169.3766223958\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3941767785260804\n",
      " MSE with beta :  0.7092867500271993\n",
      "ELBO :  1631172.436769278\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.395107857504778\n",
      " MSE with beta :  0.7090792855756195\n",
      "ELBO :  1631175.3199544516\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3960466545848795\n",
      " MSE with beta :  0.7088398200518844\n",
      "ELBO :  1631178.0301911372\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3968954461838694\n",
      " MSE with beta :  0.7086332780668182\n",
      "ELBO :  1631180.590457352\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.39773602203295566\n",
      " MSE with beta :  0.7084290944701668\n",
      "ELBO :  1631183.0032737828\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3985436299963646\n",
      " MSE with beta :  0.7082800933041233\n",
      "ELBO :  1631185.2672837342\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3994061729013265\n",
      " MSE with beta :  0.7080890869002849\n",
      "ELBO :  1631187.398014981\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40017466138129587\n",
      " MSE with beta :  0.7079094059061651\n",
      "ELBO :  1631189.4117883604\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40091227418846664\n",
      " MSE with beta :  0.7077365895116153\n",
      "ELBO :  1631191.3254155733\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.4016258324109452\n",
      " MSE with beta :  0.7075139128720466\n",
      "ELBO :  1631193.097764174\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.402175123126672\n",
      " MSE with beta :  0.7073815268228515\n",
      "ELBO :  1631194.8514831807\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.4028295595847475\n",
      " MSE with beta :  0.7072078405034706\n",
      "ELBO :  1631196.4836250492\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40340898870597697\n",
      " MSE with beta :  0.7070464425914875\n",
      "ELBO :  1631198.0305706332\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.4039586298981347\n",
      " MSE with beta :  0.7069048733107363\n",
      "ELBO :  1631199.4886071237\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40449830987220287\n",
      " MSE with beta :  0.7067727591523552\n",
      "ELBO :  1631200.8921281814\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40502963522024177\n",
      " MSE with beta :  0.7066093406649911\n",
      "ELBO :  1631202.223399186\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40548780174829974\n",
      " MSE with beta :  0.7065171478781619\n",
      "ELBO :  1631203.4586910543\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.406063122793947\n",
      " MSE with beta :  0.7063568299640537\n",
      "ELBO :  1631204.6858865847\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.4064839477818608\n",
      " MSE with beta :  0.7062281655504031\n",
      "ELBO :  1631205.8526754978\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.4068957467144544\n",
      " MSE with beta :  0.7061060459235631\n",
      "ELBO :  1631206.9525871652\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.4073147930576952\n",
      " MSE with beta :  0.7060057641329683\n",
      "ELBO :  1631207.9983219262\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.4077578767309538\n",
      " MSE with beta :  0.7057904046871587\n",
      "ELBO :  1631208.9906186587\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40793775608723526\n",
      " MSE with beta :  0.7057032602299965\n",
      "ELBO :  1631209.98324751\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.4082738263142672\n",
      " MSE with beta :  0.70552003649616\n",
      "ELBO :  1631210.8952058344\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40844434488694253\n",
      " MSE with beta :  0.7054188276292542\n",
      "ELBO :  1631211.781306755\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40868769969810154\n",
      " MSE with beta :  0.7052619048730228\n",
      "ELBO :  1631212.6315763236\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.4088403444933587\n",
      " MSE with beta :  0.705163939105676\n",
      "ELBO :  1631213.4434443228\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40908095651152726\n",
      " MSE with beta :  0.7049703922278538\n",
      "ELBO :  1631214.2263884717\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.4091023231478123\n",
      " MSE with beta :  0.7048268814322671\n",
      "ELBO :  1631215.0183028723\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.4091626607071758\n",
      " MSE with beta :  0.704675991248689\n",
      "ELBO :  1631215.7598961045\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40920879861616166\n",
      " MSE with beta :  0.704536326903614\n",
      "ELBO :  1631216.4648750008\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40923701124560086\n",
      " MSE with beta :  0.704395008879463\n",
      "ELBO :  1631217.1604479149\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.4092394746628689\n",
      " MSE with beta :  0.7042743756515862\n",
      "ELBO :  1631217.8253564395\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.4092556451122031\n",
      " MSE with beta :  0.704136699314412\n",
      "ELBO :  1631218.4328740137\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40927033353989545\n",
      " MSE with beta :  0.7039735296016488\n",
      "ELBO :  1631219.0859164393\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.4091633741794498\n",
      " MSE with beta :  0.7038004739390125\n",
      "ELBO :  1631219.68615843\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.409016771138965\n",
      " MSE with beta :  0.703651986462699\n",
      "ELBO :  1631220.260610816\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40885544513851535\n",
      " MSE with beta :  0.7034319064487484\n",
      "ELBO :  1631220.7398500943\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40854860471886995\n",
      " MSE with beta :  0.7033417885846158\n",
      "ELBO :  1631221.348765079\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40843401546831676\n",
      " MSE with beta :  0.7031823933560483\n",
      "ELBO :  1631221.9259038467\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40823923632761105\n",
      " MSE with beta :  0.703009839420682\n",
      "ELBO :  1631222.4197167237\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40792218861964114\n",
      " MSE with beta :  0.7028621392362269\n",
      "ELBO :  1631222.930212375\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.4077150924888965\n",
      " MSE with beta :  0.7026801724523111\n",
      "ELBO :  1631223.4053694373\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.4074185220909184\n",
      " MSE with beta :  0.7026235144503401\n",
      "ELBO :  1631223.8653384524\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.4073292563569198\n",
      " MSE with beta :  0.7023967504536143\n",
      "ELBO :  1631224.2863950892\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.4069770089989661\n",
      " MSE with beta :  0.7022410605369451\n",
      "ELBO :  1631224.7985062755\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40664036866909087\n",
      " MSE with beta :  0.7020734264139975\n",
      "ELBO :  1631225.2334520963\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40628185171318637\n",
      " MSE with beta :  0.7017639845736252\n",
      "ELBO :  1631225.523138466\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.4056720871276508\n",
      " MSE with beta :  0.7017514799550204\n",
      "ELBO :  1631226.0539856085\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40549029736791387\n",
      " MSE with beta :  0.7014413419943816\n",
      "ELBO :  1631226.1253833314\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40485465920835023\n",
      " MSE with beta :  0.701307803724903\n",
      "ELBO :  1631226.8171137036\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40441896646549913\n",
      " MSE with beta :  0.7011989981987113\n",
      "ELBO :  1631227.328099309\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.404110237351709\n",
      " MSE with beta :  0.7010419167385161\n",
      "ELBO :  1631227.6788894641\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.4037238986430828\n",
      " MSE with beta :  0.700808544123644\n",
      "ELBO :  1631228.0844597719\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.4031801378461293\n",
      " MSE with beta :  0.7006368250992666\n",
      "ELBO :  1631228.3974559142\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.4026526643562012\n",
      " MSE with beta :  0.7004175720934178\n",
      "ELBO :  1631228.8053738172\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40201905835851937\n",
      " MSE with beta :  0.7002104557198993\n",
      "ELBO :  1631229.1839564233\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40141423689933753\n",
      " MSE with beta :  0.7000219836780519\n",
      "ELBO :  1631229.3541950604\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.4008719141275283\n",
      " MSE with beta :  0.6998193150884936\n",
      "ELBO :  1631229.5635936635\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.40019119688702365\n",
      " MSE with beta :  0.6995572374029392\n",
      "ELBO :  1631229.8717550663\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3994411832404526\n",
      " MSE with beta :  0.6992922735008453\n",
      "ELBO :  1631230.2622095817\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.39861265299182863\n",
      " MSE with beta :  0.6990146859539109\n",
      "ELBO :  1631230.669519459\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3976930376862463\n",
      " MSE with beta :  0.6988831169099555\n",
      "ELBO :  1631231.1551996334\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3970254028922789\n",
      " MSE with beta :  0.6986401213938734\n",
      "ELBO :  1631231.3820218528\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3963445215997698\n",
      " MSE with beta :  0.6984553397620665\n",
      "ELBO :  1631231.3077097214\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3956194186325534\n",
      " MSE with beta :  0.6983661803566565\n",
      "ELBO :  1631231.5222558312\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3951181934631501\n",
      " MSE with beta :  0.6980212263325178\n",
      "ELBO :  1631231.9252634896\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.39422084091173903\n",
      " MSE with beta :  0.6978078517033236\n",
      "ELBO :  1631232.192895371\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3933635079998361\n",
      " MSE with beta :  0.6975573569897944\n",
      "ELBO :  1631232.758692136\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.39249833926874506\n",
      " MSE with beta :  0.6973520840414613\n",
      "ELBO :  1631232.8388244826\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.39161584659733045\n",
      " MSE with beta :  0.6972132359384863\n",
      "ELBO :  1631230.8984832722\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.39089966225060796\n",
      " MSE with beta :  0.6969604247009054\n",
      "ELBO :  1631233.4499656768\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3900757056658972\n",
      " MSE with beta :  0.6966920493832973\n",
      "ELBO :  1631234.0254518336\n"
     ]
    }
   ],
   "source": [
    "model = PLNmodel(Sigma_init, beta_init, M_init, S_init)\n",
    "last_M_S_lr, last_beta_lr = model.VEM(data, number_VEM_step = 150, beginning_M_S_lr=0.01, beginning_beta_lr= 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "coastal-briefing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3853862536139941\n",
      " MSE with beta :  0.705331568354551\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.38500890521970915\n",
      " MSE with beta :  0.7051823490104059\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3846059028982727\n",
      " MSE with beta :  0.7050326234752663\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3841887728709181\n",
      " MSE with beta :  0.7048842879368987\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.38376648628027726\n",
      " MSE with beta :  0.7047347407113488\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.38333443698433084\n",
      " MSE with beta :  0.7045826793983383\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.38288817212378873\n",
      " MSE with beta :  0.7044310956872785\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.38243233363365914\n",
      " MSE with beta :  0.704275069148218\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.381956476566407\n",
      " MSE with beta :  0.7041118797600981\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3814514569079773\n",
      " MSE with beta :  0.7039416046886402\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3809152304550268\n",
      " MSE with beta :  0.7037665507577691\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3803526182622933\n",
      " MSE with beta :  0.7035889827096027\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.37977126026112346\n",
      " MSE with beta :  0.7034097324288072\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3791755787516183\n",
      " MSE with beta :  0.7032285139690603\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.37856658346905386\n",
      " MSE with beta :  0.7030464939003361\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.37794767603599\n",
      " MSE with beta :  0.7028638329973805\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.377319656167222\n",
      " MSE with beta :  0.7026798367951976\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.376680753681228\n",
      " MSE with beta :  0.7024946173568363\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3760311614075542\n",
      " MSE with beta :  0.7023064840894417\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.37536680208866946\n",
      " MSE with beta :  0.7021129910855909\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3746800710038824\n",
      " MSE with beta :  0.7019147492485013\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3739698094612793\n",
      " MSE with beta :  0.7017135836980981\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.373239900371211\n",
      " MSE with beta :  0.7015068776148395\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.37248579017243993\n",
      " MSE with beta :  0.7012951161123039\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3717083441360592\n",
      " MSE with beta :  0.7010825364478928\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3709194648722538\n",
      " MSE with beta :  0.7008727476949227\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.37013150782092485\n",
      " MSE with beta :  0.7006648533262996\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3693457076602151\n",
      " MSE with beta :  0.7004577751948581\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.36855824825526595\n",
      " MSE with beta :  0.7002482916566427\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3677594449419801\n",
      " MSE with beta :  0.7000345565641121\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3669420148124753\n",
      " MSE with beta :  0.6998173161183989\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.36610648097762544\n",
      " MSE with beta :  0.6995979748374397\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3652577422427863\n",
      " MSE with beta :  0.6993758869480408\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.36439597645839084\n",
      " MSE with beta :  0.6991502676420923\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.36351904725145584\n",
      " MSE with beta :  0.6989229203320768\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.36263075657361876\n",
      " MSE with beta :  0.6986961894341245\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3617378153132756\n",
      " MSE with beta :  0.6984693032451245\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.36084027297272814\n",
      " MSE with beta :  0.6982387668025146\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3599293377464686\n",
      " MSE with beta :  0.6980033432976317\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3590003044473773\n",
      " MSE with beta :  0.6977645761969582\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.35805698973023725\n",
      " MSE with beta :  0.6975234709023512\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3571029179057593\n",
      " MSE with beta :  0.697282193429093\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3561436889964999\n",
      " MSE with beta :  0.6970413046745102\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3551822382748213\n",
      " MSE with beta :  0.6967997689139672\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3542145466183982\n",
      " MSE with beta :  0.6965521327129056\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3532245491817821\n",
      " MSE with beta :  0.6963021308720765\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3522156523692385\n",
      " MSE with beta :  0.6960453900027147\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3511801677130916\n",
      " MSE with beta :  0.6957879835945875\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3501328803508774\n",
      " MSE with beta :  0.6955327233651409\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3490902282104048\n",
      " MSE with beta :  0.6952797451694831\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3480577124711489\n",
      " MSE with beta :  0.695028142725634\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.34703112942678993\n",
      " MSE with beta :  0.694775013085823\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3459986765019472\n",
      " MSE with beta :  0.6945173776201305\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3449491404022805\n",
      " MSE with beta :  0.6942539881169649\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.34387982918485366\n",
      " MSE with beta :  0.6939918816302783\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.34281152635982287\n",
      " MSE with beta :  0.6937324323348361\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3417528145058566\n",
      " MSE with beta :  0.6934788133576165\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3407094026249033\n",
      " MSE with beta :  0.6932211881604431\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.33965566704318373\n",
      " MSE with beta :  0.6929615171863981\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.33858775837522725\n",
      " MSE with beta :  0.6926987302307017\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.33750856697718223\n",
      " MSE with beta :  0.6924369673980806\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.336433722602436\n",
      " MSE with beta :  0.692174961328708\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.33536091656164224\n",
      " MSE with beta :  0.6919117442842936\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3342837183877278\n",
      " MSE with beta :  0.6916401341059452\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.33318531582731037\n",
      " MSE with beta :  0.6913738395738693\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.332088091829705\n",
      " MSE with beta :  0.6911019109488515\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.330980554766265\n",
      " MSE with beta :  0.6908348752974982\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.32988088042443503\n",
      " MSE with beta :  0.6905704143988598\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3287916368532193\n",
      " MSE with beta :  0.6903034295126639\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3277005190179324\n",
      " MSE with beta :  0.6900374406995495\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.326604320058867\n",
      " MSE with beta :  0.6897681730971147\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3254996128653176\n",
      " MSE with beta :  0.6894972601267442\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.32439119984905884\n",
      " MSE with beta :  0.6892311625176559\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.32329505098774114\n",
      " MSE with beta :  0.6889601310601375\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3221940571601461\n",
      " MSE with beta :  0.6886873870523202\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3210865813498864\n",
      " MSE with beta :  0.688410388555144\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3199602960929621\n",
      " MSE with beta :  0.6881298408178026\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3188168805835265\n",
      " MSE with beta :  0.6878464004478795\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.317660069226058\n",
      " MSE with beta :  0.6875612387339263\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.31650011154905466\n",
      " MSE with beta :  0.6872792957773768\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3153457684888906\n",
      " MSE with beta :  0.6869983329633357\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.31419967860912323\n",
      " MSE with beta :  0.6867222766146825\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.31307364562031226\n",
      " MSE with beta :  0.6864480118932561\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.31195870620211824\n",
      " MSE with beta :  0.6861699758033524\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.310833017948796\n",
      " MSE with beta :  0.6858915204591435\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3097044205100468\n",
      " MSE with beta :  0.685613833147572\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3085725534720206\n",
      " MSE with beta :  0.6853320944976469\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3074366069407675\n",
      " MSE with beta :  0.6850487760829103\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3062924740357889\n",
      " MSE with beta :  0.6847666712963261\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3051486735447972\n",
      " MSE with beta :  0.6844862538359741\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.30401658860845043\n",
      " MSE with beta :  0.6842096673540009\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.302893614380849\n",
      " MSE with beta :  0.6839272781744231\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3017609351949567\n",
      " MSE with beta :  0.6836532998044923\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.3006515006422487\n",
      " MSE with beta :  0.6833785233124254\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.29955415334446417\n",
      " MSE with beta :  0.6831003950366019\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2984484559972952\n",
      " MSE with beta :  0.6828239895103656\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2973498362211488\n",
      " MSE with beta :  0.6825503467626387\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.29625999801527525\n",
      " MSE with beta :  0.6822782897570647\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.29516892621924123\n",
      " MSE with beta :  0.6820081565996944\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2940810702627581\n",
      " MSE with beta :  0.6817386231050557\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.29299576517634607\n",
      " MSE with beta :  0.6814675874021561\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.29191426658562925\n",
      " MSE with beta :  0.6811940532317581\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.29082901159716135\n",
      " MSE with beta :  0.6809210763106881\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.289745010779424\n",
      " MSE with beta :  0.6806423286639979\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2886537142677778\n",
      " MSE with beta :  0.6803675536707067\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2875690605995241\n",
      " MSE with beta :  0.6800888536231382\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.28648340984450915\n",
      " MSE with beta :  0.6798113121314823\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2854029151902022\n",
      " MSE with beta :  0.6795394154905022\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2843283461853753\n",
      " MSE with beta :  0.6792697454423862\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.28326834361454334\n",
      " MSE with beta :  0.6789995049224907\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.28221195504053803\n",
      " MSE with beta :  0.6787306378017695\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.28116869317527887\n",
      " MSE with beta :  0.6784628962368069\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.28013211939164456\n",
      " MSE with beta :  0.6781971977586123\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.27909249611083914\n",
      " MSE with beta :  0.6779351852947676\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.27806337895698335\n",
      " MSE with beta :  0.6776720729784452\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.27705216771283214\n",
      " MSE with beta :  0.6774065718743302\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2760358547995432\n",
      " MSE with beta :  0.6771459237802498\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.27502607587777145\n",
      " MSE with beta :  0.676883157791288\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2740119689193751\n",
      " MSE with beta :  0.6766224395906815\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2730124578213257\n",
      " MSE with beta :  0.6763607293565655\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2720115433132606\n",
      " MSE with beta :  0.6760986250371032\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2710116230356075\n",
      " MSE with beta :  0.6758394072272863\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2700152940544995\n",
      " MSE with beta :  0.6755810958218842\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.26903011502685703\n",
      " MSE with beta :  0.6753291724744411\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2680627100101564\n",
      " MSE with beta :  0.6750763921718209\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.26710314931594514\n",
      " MSE with beta :  0.6748241877305773\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2661450228891631\n",
      " MSE with beta :  0.6745781280892156\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2652071878453076\n",
      " MSE with beta :  0.6743344357428979\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2642914843255696\n",
      " MSE with beta :  0.6740909618365343\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.26338261084183057\n",
      " MSE with beta :  0.6738482331687989\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2624699322392146\n",
      " MSE with beta :  0.6736059171600843\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.26155946270463004\n",
      " MSE with beta :  0.6733686521441576\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2606617365057678\n",
      " MSE with beta :  0.6731350536673197\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.259784615245722\n",
      " MSE with beta :  0.6729029333794998\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.25891148272340825\n",
      " MSE with beta :  0.6726698286144475\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2580413497587293\n",
      " MSE with beta :  0.6724374327778756\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2571757007308865\n",
      " MSE with beta :  0.6722034282021937\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.256296231259043\n",
      " MSE with beta :  0.6719702823489239\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.25544090491768573\n",
      " MSE with beta :  0.6717400510931614\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2545843131800902\n",
      " MSE with beta :  0.6715125815311711\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.25373677451654497\n",
      " MSE with beta :  0.6712837769755154\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2528870658534983\n",
      " MSE with beta :  0.6710560607782835\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.25205662349543506\n",
      " MSE with beta :  0.6708314188830894\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2512260308685921\n",
      " MSE with beta :  0.6706033489169769\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.25038827367355343\n",
      " MSE with beta :  0.6703770087088751\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.24956037089365654\n",
      " MSE with beta :  0.670151979574699\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.24874517132817317\n",
      " MSE with beta :  0.669927283030243\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2479256885678633\n",
      " MSE with beta :  0.6697070314927035\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.247128307675133\n",
      " MSE with beta :  0.669485142060132\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2463238562513784\n",
      " MSE with beta :  0.6692610971474195\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.24550805660883815\n",
      " MSE with beta :  0.6690388712101745\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.24469727192460697\n",
      " MSE with beta :  0.6688218783033933\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2439185024306801\n",
      " MSE with beta :  0.6686042191992285\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.24313847750769174\n",
      " MSE with beta :  0.6683914510050044\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2423739432422653\n",
      " MSE with beta :  0.6681778924162749\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2416096463690787\n",
      " MSE with beta :  0.6679670276221797\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2408555082136189\n",
      " MSE with beta :  0.6677564782975917\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.24009998805903587\n",
      " MSE with beta :  0.6675456975634582\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.23933523881793972\n",
      " MSE with beta :  0.667333220128655\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.23856918321953768\n",
      " MSE with beta :  0.6671225560252492\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.23782190021050173\n",
      " MSE with beta :  0.6669139727706392\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.23707524108627803\n",
      " MSE with beta :  0.6667063143950946\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2363337039102098\n",
      " MSE with beta :  0.6665024815532078\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2356055968589294\n",
      " MSE with beta :  0.6663007941778614\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.23489683868517017\n",
      " MSE with beta :  0.6660992296474881\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2341874804915254\n",
      " MSE with beta :  0.6658985609779993\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.23346951638057195\n",
      " MSE with beta :  0.6656984640582558\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.23277061841491992\n",
      " MSE with beta :  0.6654988973816128\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.23206456840818013\n",
      " MSE with beta :  0.6653009042001421\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.23136332513224975\n",
      " MSE with beta :  0.6651069187106401\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.23068762500148368\n",
      " MSE with beta :  0.6649125699892686\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.23000723747148427\n",
      " MSE with beta :  0.6647186375552516\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.22932847545115087\n",
      " MSE with beta :  0.6645276796825013\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.22866838802262873\n",
      " MSE with beta :  0.6643389921787537\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2280173472022916\n",
      " MSE with beta :  0.6641492838039791\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.22735810635717185\n",
      " MSE with beta :  0.6639635721452823\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.22671608365541168\n",
      " MSE with beta :  0.6637758971828434\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2260591629416527\n",
      " MSE with beta :  0.6635844119711058\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.22538919125368634\n",
      " MSE with beta :  0.6633933683822729\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.22472052533661607\n",
      " MSE with beta :  0.6632041164863387\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.22408142171375076\n",
      " MSE with beta :  0.6630161672386826\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2234321265046115\n",
      " MSE with beta :  0.662831187380299\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.22279903942481324\n",
      " MSE with beta :  0.6626450957754488\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.22215933772097632\n",
      " MSE with beta :  0.6624570719498278\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.22150813321136006\n",
      " MSE with beta :  0.6622722759251755\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.22086292159136078\n",
      " MSE with beta :  0.662084974267097\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.22022278674195886\n",
      " MSE with beta :  0.6619039837979744\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2195923081169617\n",
      " MSE with beta :  0.6617201042268326\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2189663208434078\n",
      " MSE with beta :  0.661538959783486\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2183451065280492\n",
      " MSE with beta :  0.6613566830622533\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2177289656712695\n",
      " MSE with beta :  0.661177626653052\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.21712356936516572\n",
      " MSE with beta :  0.661000296289189\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.21652716676877184\n",
      " MSE with beta :  0.660830812899963\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.21594558893891608\n",
      " MSE with beta :  0.6606576362682647\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2153681400220832\n",
      " MSE with beta :  0.6604880346198627\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2147974437824887\n",
      " MSE with beta :  0.6603165706252603\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.21422480346782535\n",
      " MSE with beta :  0.6601491786738165\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.21365604165900928\n",
      " MSE with beta :  0.6599807348760359\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.21309460263342422\n",
      " MSE with beta :  0.6598131536763132\n",
      "-------UPDATE-------\n",
      " MSE with Sigma :  0.2125329436883918\n",
      " MSE with beta :  0.6596456848452857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.005904900000000002, 0.01)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.VEM(data,number_VEM_step = 200, beginning_M_S_lr= last_M_S_lr, beginning_beta_lr= last_beta_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "rough-center",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------Maximum number of iterations reached\n",
      "---------------------------------lr : 9.253701853187628e-08\n",
      "---------------------------------log likelihood : nan\n",
      "---------------------------------grad_M_norm :  0.049\n",
      "---------------------------------grad_S_norm :  96.863\n",
      "---------------------------------Tolerance reached in 68 iterations\n",
      "---------------------------------lr : 0.0016677181699666583\n",
      "---------------------------------log likelihood : nan\n",
      "---------------------------------grad_beta_norm :  1.809\n"
     ]
    }
   ],
   "source": [
    "model.VE_step(lr = 0.0059)\n",
    "model.M_step(lr = 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-cliff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
