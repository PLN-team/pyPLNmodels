{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "phantom-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradient_descent import gradient_descent, minibatch_class\n",
    "import utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm \n",
    "import time \n",
    "import sys \n",
    "from __future__ import print_function\n",
    "import psutil\n",
    "import multiprocessing\n",
    "import concurrent.futures\n",
    "import threading\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import scipy.linalg as SLA \n",
    "from scipy.linalg import toeplitz \n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "operational-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Poisson_reg():\n",
    "    '''\n",
    "    Poisson regressor class. The purpose of this class is to initialize the PLN model.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self): \n",
    "        pass\n",
    "    \n",
    "\n",
    "    \n",
    "    def fit(self,O,X,Y, Niter_max = 300, tol = 0.1, lr = 0.00008,  verbose = False): \n",
    "        '''\n",
    "        We run a gradient ascent to maximize the log likelihood. We do this by hand : we compute the gradient ourselves. \n",
    "        The log likelihood considered is the one from a poisson regression model. It is the same as PLN without the latent layer Z. \n",
    "        We are only trying to have a good guess of beta before doing anything. \n",
    "        \n",
    "        args : \n",
    "                '0' : offset, size (n,p)\n",
    "                'X' : covariates, size (n,p)\n",
    "                'Y' : samples , size (n,p)\n",
    "                'Niter_max' :int  the number of iteration we are ready to do \n",
    "                'tol' : float. the tolerance criteria. We will stop if the norm of the gradient is less than \n",
    "                       or equal to this threshold\n",
    "                'lr' : float. learning rate for the gradient ascent\n",
    "                'verbose' : bool. if True, will print some stats on the \n",
    "                \n",
    "        returns : None but update the parameter beta \n",
    "        '''\n",
    "        \n",
    "        #we initiate beta \n",
    "        beta = torch.rand(X.shape[1])\n",
    "        i = 0\n",
    "        grad_norm = 2*tol\n",
    "        while i<Niter_max and  grad_norm > tol : # condition to keep going\n",
    "            grad = grad_poiss_beta(O,X,Y,beta) # computes the gradient \n",
    "            grad_norm = torch.norm(grad) \n",
    "            beta += lr*grad_poiss_beta(O,X,Y,beta)# update beta \n",
    "            i+=1\n",
    "            \n",
    "            # some stats if we want some \n",
    "            if verbose == True : \n",
    "                if i % 10 == 0 : \n",
    "                    print('log likelihood  : ', compute_l(0,X,Y,beta))\n",
    "                    print('Gradient norm : ', grad_norm)\n",
    "        if i < Niter_max : \n",
    "            print('---------------------Tolerance reachedin {} iterations'.format(i))\n",
    "        else : \n",
    "            print('---------------------Maximum number of iterations reached')\n",
    "        print('----------------------Gradient norm : ', grad_norm)\n",
    "        self.beta = beta # save beta \n",
    "        \n",
    "        \n",
    "    def fit_torch(self,O,X,Y, Niter_max = 300, tol = 0.1, lr = 0.0001, verbose = False): \n",
    "        '''\n",
    "        Does exaclty the same as fit() but uses autodifferentiation of pytorch. \n",
    "        '''\n",
    "        \n",
    "        beta = torch.rand(X.shape[1], requires_grad = True)\n",
    "        optimizer = torch.optim.Adam([beta], lr = lr)\n",
    "        i = 0\n",
    "        grad_norm = 2*tol\n",
    "        while i<Niter_max and  grad_norm > tol :\n",
    "            loss = -compute_l(O,X,Y,beta)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            grad_norm = torch.norm(beta.grad)\n",
    "            beta.grad.zero_()\n",
    "            i+=1\n",
    "            if verbose == True : \n",
    "                if i % 10 == 0 : \n",
    "                    print('log like : ', -loss)\n",
    "                    print('grad_norm : ', grad_norm)\n",
    "        if verbose :\n",
    "            if i < Niter_max : \n",
    "                print('-------------------Tolerance reached in {} iterations'.format(i))\n",
    "            else : \n",
    "                print('-------------------Maxium number of iterations reached')\n",
    "        self.beta = beta \n",
    "    \n",
    "\n",
    "def grad_poiss_beta(O,X,Y,beta): \n",
    "    return torch.sum(-torch.multiply(X,torch.exp(O+X@beta).reshape(-1,1))+torch.multiply(Y.reshape(-1,1),X),dim = 0)\n",
    "    \n",
    "def compute_l(O,X,Y,beta):\n",
    "    return torch.sum(-torch.exp(O + X@beta)+torch.multiply(Y,O+X@beta))    \n",
    "    \n",
    "def sample(O,X,true_beta):\n",
    "        parameter = np.exp(O + X@true_beta)\n",
    "        return torch.poisson(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "narrative-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sample_PLN(): \n",
    "    '''\n",
    "    simple class to sample some variables with the PLN model. \n",
    "    The main method is the sample one, however we can also plot the data calling the plot_Y method. \n",
    "    The method conditional prior should not be used and have not been tested properly. \n",
    "    '''\n",
    "    \n",
    "    def __init__(self): \n",
    "        pass \n",
    "\n",
    "    def sample(self, Sigma, beta, O, covariates): \n",
    "        '''\n",
    "        sample Poisson log Normal variables. \n",
    "        The number of samples is the the first size of O, the number of species\n",
    "        considered is the second size of O\n",
    "        The number of covariates considered is the first size of beta. \n",
    "        \n",
    "        '''\n",
    "        self.Sigma = Sigma # unknown parameter in practice\n",
    "        self.beta = beta #unknown parameter in practice\n",
    "        \n",
    "        self.O = O \n",
    "        self.covariates = covariates\n",
    "        \n",
    "        self.Z = torch.stack([self.Sigma@np.random.randn(p) for _ in range(n)])\n",
    "        \n",
    "        self.n = self.O.shape[0]\n",
    "        self.p = self.Sigma.shape[0]\n",
    "        self.d = self.covariates.shape[1]\n",
    "        \n",
    "        parameter = torch.exp(self.O + self.covariates@self.beta + self.Z)\n",
    "        self.Y = np.random.poisson(lam = parameter)\n",
    "        return self.Y \n",
    "        #return parameter.numpy()\n",
    "    def plot_Y(self): \n",
    "        '''\n",
    "        plot all the Y_ij sampled before. There will be n*p values in total. The color represent the site number. \n",
    "        Note that we need to have called self.sample() before otherwise it won't print anything \n",
    "        '''\n",
    "        color = np.array([[site]*self.p for site in range(self.n) ]).ravel()*10\n",
    "        plt.scatter(np.arange(0,self.n*self.p),self.Y.ravel(), c = color, label = 'color = site number')\n",
    "        plt.legend()\n",
    "        plt.ylabel('count number')\n",
    "        plt.show()\n",
    "\n",
    "    def conditionalprior(self): \n",
    "        mu = self.O[0,0]\n",
    "        functions = list()\n",
    "        for i in range(self.n): \n",
    "            mu_i = self.covariates[i].dot(self.beta[0])\n",
    "            functions.append(lambda z : -z**2/(2*self.Sigma[0,0]**2)-np.exp(mu_i+z)+float(self.Y[i])*(mu_i+z))\n",
    "        return functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "composed-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PLNmodel(): \n",
    "    '''\n",
    "    PLN model. The goal of this class is to compute the parameter beta and Sigma of the PLN model. \n",
    "    We use here variationnal approximation since we can't compute the log likelihood of the \n",
    "    latent variables given the data. \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, Sigma_init, beta_init, M_init, S_init): \n",
    "        \n",
    "        '''\n",
    "            Initialization : \n",
    "            'Y' : the data, size (n,p). n is the number of samples we have and p the number of species. \n",
    "                  THE TYPE IS INT\n",
    "            'O': offset : additional offset. (not very important for comprehension). size (n,p)\n",
    "            'covariates' : covariates, size (n,d)\n",
    "            'Sigma_init' : initialization for Sigma. I plan to do a more advanced initialization. \n",
    "            'beta_init ' : Initialization for beta. I plan to do a more advanced initialization. \n",
    "            'M_init' : initialization for the variational parameter M\n",
    "            'S_init ': initialization for the variational parameter S\n",
    "        '''\n",
    "        \n",
    "        # model parameters\n",
    "        self.Sigma = torch.clone(Sigma_init)\n",
    "        self.Sigma.requires_grad_(True)\n",
    "        self.beta = torch.clone(beta_init)\n",
    "        self.beta.requires_grad_(True)\n",
    "        \n",
    "        #variational parameters\n",
    "        self.M = torch.clone(M_init)\n",
    "        self.M.requires_grad_(True)\n",
    "        self.S = torch.clone(S_init) \n",
    "        self.S.requires_grad_(True)\n",
    "        \n",
    "        # some useful variables\n",
    "        self.det_Sigma = torch.det(self.Sigma)\n",
    "        self.inv_Sigma = torch.inverse(self.Sigma)\n",
    "        \n",
    "        # optimizer for the VE_step\n",
    "        self.VE_step_optimizer = torch.optim.Adam([self.S,self.M], lr = 0.01)\n",
    "        self.VE_step_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.VE_step_optimizer, patience = 3, factor = 0.9)\n",
    "        \n",
    "        #optimizer for the M_step\n",
    "        self.M_step_optimizer = torch.optim.Adam([self.beta])\n",
    "        self.M_step_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.M_step_optimizer, patience = 3, factor = 0.9)        \n",
    "        \n",
    "        self.full_optimizer = torch.optim.Adam([self.S,self.M,self.beta])\n",
    "        \n",
    "        self.params = {'M': self.M, 'S' : self.S, 'beta' : self.beta, 'Sigma': self.Sigma}\n",
    "\n",
    "        self.MSE_Sigma_list = list()\n",
    "        self.MSE_beta_list = list()\n",
    "        self.ELBO_list = list()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    # we define here the gradients computed manually as a sanity check. We can check that they are equals \n",
    "    # to the gradients computed with the autodifferentiation of pytorch (diff = 1e-15)\n",
    "    def grad_Sigma(self): \n",
    "        with torch.no_grad():\n",
    "            self.inv_Sigma = torch.inverse(self.Sigma)\n",
    "            grad = -self.n/2*(self.inv_Sigma)# + torch.diag(torch.diagonal(self.inv_Sigma))) on a enlevé car avec ça ca match avec pytorch. \n",
    "            grad += 1/2*(sum([self.inv_Sigma@(torch.outer(self.M[i,:],self.M[i,:])+ torch.diag(self.S[i,:]))@self.inv_Sigma  for i in range(self.n)]))\n",
    "        return grad\n",
    "    def grad_M(self): \n",
    "        with torch.no_grad():\n",
    "            grad = -torch.mm(self.M,self.inv_Sigma)\n",
    "            grad -= torch.exp(self.O + torch.mm(self.covariates,self.beta) + self.M + torch.pow(self.S,2)/2)\n",
    "            grad += self.Y \n",
    "        return grad \n",
    "    def grad_S(self):\n",
    "        with torch.no_grad():\n",
    "            grad = -1/2*torch.mm(torch.ones((self.n,self.p)), torch.diag(torch.diag(self.inv_Sigma)))\n",
    "            grad-= torch.mul(self.S,torch.exp(self.O + torch.mm(self.covariates,self.beta) + self.M + torch.pow(self.S,2)/2))\n",
    "            grad += 1/2*torch.div(1,self.S)\n",
    "        return grad \n",
    "    def grad_beta(self): \n",
    "        with torch.no_grad():\n",
    "            grad = - torch.mm(self.covariates.T,torch.exp( self.O + self.M + torch.pow(self.S,2)/2 + torch.mm(self.covariates,self.beta)))\n",
    "            grad += torch.mm(self.covariates.T,self.Y.double())\n",
    "        return grad \n",
    "    \n",
    "        \n",
    "    def extract_data(self,data): \n",
    "        '''\n",
    "        function to extract the data. This function is just here to have a code more compact. \n",
    "        \n",
    "        args : \n",
    "              'data': list with 3 elements : Y, O and covariates in this order. \n",
    "        '''\n",
    "        \n",
    "        #known variables\n",
    "        self.Y = data[0];self.O = data[1];self.covariates = data[2]\n",
    "    \n",
    "        self.n, self.p = self.Y.shape\n",
    "    \n",
    "        \n",
    "    def compute_ELBO_bis(self, Y, covariates,O,M,S,Sigma,beta): \n",
    "        ''' \n",
    "        computes the ELBO. We simply apply the formula given above. \n",
    "        '''\n",
    "        batch_size = Y.shape[0]\n",
    "        inv_Sigma = torch.inverse(Sigma)\n",
    "        tmp = -batch_size/2*torch.log(torch.det(Sigma))\n",
    "        \n",
    "        # formula with the quadratic function and the trace \n",
    "        tmp -=1/2*( torch.sum(torch.mm(torch.mm(M,inv_Sigma),M.T).diagonal()))   # we can simplify here, takes too much time \n",
    "                                                                                           # we should remove the diagonal and do a more efficient multiplication\n",
    "                                            \n",
    "                        \n",
    "        Gram_matrix = torch.mm(covariates,beta) # matrix with term (i,j): <x_i,beta_j>\n",
    "        \n",
    "        Exp_moment = torch.exp(M + torch.pow(S,2)/2)\n",
    "        \n",
    "        tmp += torch.sum(-torch.exp(O + Gram_matrix + M + torch.pow(S,2)/2) + torch.multiply(Y, O + Gram_matrix + M))\n",
    "        \n",
    "        for i in range(batch_size): \n",
    "            tmp += 1/2* torch.log(S[i,:].prod())\n",
    "            tmp -= 1/2 * torch.trace(torch.multiply(inv_Sigma,S[i,:]))\n",
    "            \n",
    "        return tmp\n",
    "    \n",
    "    \n",
    "    def compute_ELBO(self): \n",
    "        ''' \n",
    "        computes the ELBO. We simply apply the formula given above. \n",
    "        '''\n",
    "        \n",
    "        inv_Sigma = torch.inverse(self.Sigma)\n",
    "        tmp = -self.n/2*torch.log(torch.det(self.Sigma))\n",
    "        \n",
    "        # formula with the quadratic function and the trace \n",
    "        tmp -=1/2*( torch.sum(torch.mm(torch.mm(self.M,inv_Sigma),self.M.T).diagonal()))   # we can simplify here, takes too much time \n",
    "                                                                                           # we should remove the diagonal and do a more efficient multiplication\n",
    "                                            \n",
    "        Gram_matrix = torch.mm(self.covariates,self.beta) # matrix with term (i,j): <x_i,beta_j>\n",
    "        \n",
    "        Exp_moment = torch.exp(self.M + torch.pow(self.S,2)/2)\n",
    "        \n",
    "        tmp += torch.sum(-torch.exp(self.O + Gram_matrix + self.M + torch.pow(self.S,2)/2) + torch.multiply(self.Y, self.O + Gram_matrix + self.M))\n",
    "        \n",
    "        for i in range(self.n): \n",
    "            tmp += 1/2* torch.log(self.S[i,:].prod())\n",
    "            tmp -= 1/2 * torch.trace(torch.multiply(inv_Sigma,self.S[i,:]))\n",
    "            \n",
    "        return tmp\n",
    "    \n",
    "    def torch_gradient_ascent(self,optimizer, scheduler, params, params_names, lr = None, tolerance = 2, N_epoch = 500, verbose = True, batch_size = None ): \n",
    "        '''\n",
    "        gradient ascent function. We compute the gradients thanks to the autodifferentiation of pytorch. \n",
    "        \n",
    "        args : \n",
    "                'optimizer' : torch.optim.optimizer. the optimizer for the parameters. \n",
    "                'scheduler' : torch.optim.lr_scheduler.  scheduler for the optimizer above. \n",
    "                \n",
    "                # I will generalize this with dictionnaries \n",
    "                'params' : torch.Tensor . the params we want to optimize. they should have required_grad = True. \n",
    "                'params_names' : the names of the parameter \n",
    "                \n",
    "                'lr' : float.  a learning rate if we want to set the optimizer learning rate to a certain lr. If None, \n",
    "                      it will take the actual learning_rate of the optimizer. \n",
    "                'tolerance': float. the threshold we set to stop the algorithm. It will stop if the norm of each gradient's parameter \n",
    "                             is lower than this threshold, or if we are not improving the loss more than tolerance. \n",
    "                'N_epoch': int. the Maximum number of epoch we are ready to do. \n",
    "                \n",
    "                'Verbose' : bool. if True, will print some messages useful to interpret the gradient ascent. If False, nothing will be printed. \n",
    "                \n",
    "                'batch_size' : int or None. If None, the batch size will be n, so it will be a classical vanilla algorithm. \n",
    "                              if int, we will split the data set in batch size and do a gradient step for each mini_batch. \n",
    "                              \n",
    "        \n",
    "        returns : the parameters optimized. \n",
    "        '''\n",
    "        \n",
    "        \n",
    "        # we set the gradient to zero just to make sure the gradients are properly calculated\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if lr is not None : # if we want to set a threshold, we set it. Ohterwise, we skip this condition and keep the actual learning_rate\n",
    "            optimizer.param_groups[0]['lr'] = lr \n",
    "            \n",
    "        if batch_size == None : \n",
    "            batch_size = self.Y.shape[0]\n",
    "        \n",
    "        stop_condition = False \n",
    "        i = 0\n",
    "        old_epoch_loss = 1.\n",
    "        while i < N_epoch and stop_condition == False: \n",
    "            epoch_loss = 0.\n",
    "            #print('beginning of epoch')\n",
    "            for Y_b, covariates_b, O_b, M_b, S_b in self.get_batch(batch_size): \n",
    "                epoch_loss += self.train_step(optimizer, Y_b, covariates_b, O_b, M_b, S_b, self.Sigma,self.beta)\n",
    "            #print('epoch loss : ', epoch_loss)\n",
    "            \n",
    "            if verbose and i % 25 == 0 : \n",
    "                self.print_stats(loss, self.params, optimizer)\n",
    "            i += 1\n",
    "            scheduler.step(epoch_loss)\n",
    "            \n",
    "            # condition to see if we have reach the tolerance threshold\n",
    "            if max([torch.norm(param.grad) for param in params]) < tolerance  or abs(epoch_loss.item() - old_epoch_loss) < tolerance : #and i > 10:\n",
    "                #if max([torch.norm(param.grad) for param in params]) < tolerance  or abs(loss.item()- old_loss)>  tolerance :\n",
    "                stop_condition = True \n",
    "            old_epoch_loss = epoch_loss\n",
    "        self.current_ELBO = -epoch_loss.item()\n",
    "\n",
    "        if verbose : # just print some stats if we want to \n",
    "            if stop_condition : \n",
    "                print('---------------------------------Tolerance reached in {} iterations'.format(i))\n",
    "            else : \n",
    "                print('---------------------------------Maximum number of iterations reached')\n",
    "            self.print_stats(loss, params, params_names, optimizer)    \n",
    "        \n",
    "        return params\n",
    "    \n",
    "    def train_step(self, optimizer, Y_,covariates_, O_,M_,S_,Sigma_, beta_): \n",
    "        optimizer.zero_grad()\n",
    "        loss = -self.compute_ELBO_bis(Y_, covariates_, O_, M_, S_,Sigma_,beta_)\n",
    "        #print('loss : ', loss)\n",
    "        loss.backward()\n",
    "        if torch.isnan(loss).item() == True : \n",
    "            print('NAAAAAAAAN')\n",
    "        else : self.last_param = self.params \n",
    "        optimizer.step()\n",
    "        return loss \n",
    "\n",
    "    def print_stats(self, loss, params, params_names, optimizer): \n",
    "        '''\n",
    "        small function that print some stats. \n",
    "        \n",
    "        It will print the actual learning rate of the optimizer, the actual log likelihood \n",
    "        and the norms of each parameter's gradient. The norm of the parameter's gradient should be low\n",
    "        when we are close to the optimum. \n",
    "        '''\n",
    "        print('---------------------------------lr :', optimizer.param_groups[0]['lr'])\n",
    "        print('---------------------------------log likelihood :', - loss.item())\n",
    "        for param, param_name in params.items(): \n",
    "            print('---------------------------------grad_{}_norm : '.format(param_name), round(torch.norm(param.grad).item(), 3))\n",
    "    \n",
    "    def VEM(self,data, number_VEM_step ,batch_size,   beginning_VE_step_lr = 0.002, \n",
    "            beginning_M_step_lr = 0.01, requires_init = False,N_epoch_VE = 50, N_epoch_M = 75): \n",
    "        '''\n",
    "        function to optimize both the variational parameters and the model parameters.\n",
    "        We alternate between two steps : Variational step (VE_step) and Maximization step (M_step). \n",
    "        \n",
    "        \n",
    "        args : \n",
    "            'number_VEM_step' : int . Number of times we want to do the VEM step, i.e. alternate between VE step and M step. \n",
    "                                The greater the better the approximation, the greater the longer time it takes. \n",
    "            \n",
    "            'beginning_VE_step_lr' : float. the beginning of the learning for the VE_step. The VE will start with this lr. \n",
    "            'beginning_M_step_lr' : float. Same for beta, the M step will start with this lr. \n",
    "            \n",
    "       returns : \n",
    "               M_S_lr, beta_lr : the learning rates of both steps, so that we can continue after that with the appropriate learning rates.  \n",
    "        ''' \n",
    "        self.running_time = time.time()\n",
    "        \n",
    "        # we first extract the data. \n",
    "        self.extract_data(data)\n",
    "        \n",
    "        self.MSE_Sigma_list.append(torch.mean((self.Sigma-true_Sigma)**2).item())\n",
    "        self.MSE_beta_list.append(torch.mean((self.beta-true_beta)**2).item())\n",
    "        self.ELBO_list.append(1)\n",
    "        \n",
    "        if requires_init : \n",
    "            print('Initialisation ... ')\n",
    "            clf = Poisson_reg()\n",
    "            for j in range(p): \n",
    "                Y_j = self.Y[:,j]   \n",
    "                O_j = self.O[:,j]\n",
    "                \n",
    "                clf.fit_torch(O_j,self.covariates,Y_j, verbose = False , Niter_max = 500, lr = 0.1)\n",
    "                with torch.no_grad():\n",
    "                    self.beta[:,j] = clf.beta\n",
    "            print('Initialisation finished')\n",
    "    \n",
    "        \n",
    "        # we start with one VEM step with the appropriate learning_rate. We start with the M_step here \n",
    "        # since the log likelihood is Nan otherwise\n",
    "        \n",
    "        self.M_step(verbose = False, tolerance = 0.1, N_epoch = N_epoch_M, lr = beginning_M_step_lr)\n",
    "        self.VE_step(verbose = False, tolerance = 0.1, N_epoch = N_epoch_VE, lr = beginning_VE_step_lr)\n",
    "        self.MSE_Sigma_list.append(torch.mean((self.Sigma-true_Sigma)**2).item())\n",
    "        self.MSE_beta_list.append(torch.mean((self.beta-true_beta)**2).item())\n",
    "        self.ELBO_list.append(self.current_ELBO)\n",
    "        \n",
    "        # we do as many VEM_step we are asked to. \n",
    "        for i in range(number_VEM_step): \n",
    "            #print('MMMM_step')\n",
    "            self.M_step(verbose = False, tolerance = 0.1, N_epoch = N_epoch_M, batch_size = batch_size)\n",
    "            #print('VVVV_step')\n",
    "            self.VE_step(verbose = False, tolerance = 0.1, N_epoch = N_epoch_VE)\n",
    "            \n",
    "            \n",
    "            self.MSE_Sigma_list.append(torch.mean((self.Sigma-true_Sigma)**2).item())\n",
    "            self.MSE_beta_list.append(torch.mean((self.beta-true_beta)**2).item())\n",
    "            self.ELBO_list.append(self.current_ELBO)\n",
    "            if i %  100 == 0 : \n",
    "                print('-------UPDATE-------', batch_size)\n",
    "                print(' MSE with Sigma : ', np.round(self.MSE_Sigma_list[-1],5))\n",
    "                print(' MSE with beta : ', np.round(self.MSE_beta_list[-1],5))\n",
    "                print('ELBO : ', np.round(self.current_ELBO,5))\n",
    "\n",
    "            \n",
    "        self.running_time = time.time()- self.running_time\n",
    "        return self.VE_step_optimizer.param_groups[0]['lr'],self.M_step_optimizer.param_groups[0]['lr']\n",
    "        \n",
    "    def VE_step(self, lr = None, tolerance = 2, N_epoch = 200, verbose = True  ): \n",
    "        '''\n",
    "        VE_step : optimize the variational parameter. \n",
    "        We don't have a closed form for the parameters M and S so we have to do a gradient \n",
    "        ascent to do optimize them. \n",
    "        \n",
    "        args : \n",
    "             'lr' : learning if we want to set the learning rate of the optimizer\n",
    "        '''\n",
    "        \n",
    "        self.torch_gradient_ascent(self.VE_step_optimizer, self.VE_step_scheduler, [self.M,self.S], ['M', 'S'], lr = lr,\n",
    "                                    tolerance= tolerance, N_epoch= N_epoch, verbose= verbose)\n",
    "    def M_step(self,  lr = None, tolerance = 2, N_epoch = 50, verbose = True, batch_size = None):\n",
    "        \n",
    "        '''\n",
    "        Optimize the model parameters. \n",
    "        We have a closed form for Sigma so we actually don't need to do a gradient ascent for Sigma, just apply the formula. \n",
    "        We do a gradient ascent for beta. \n",
    "        '''\n",
    "        # closed form for Sigma, we don't need to optimize\n",
    "        with torch.no_grad(): \n",
    "            self.Sigma = 1/self.n*(torch.sum(torch.stack([torch.outer(self.M[i,:],self.M[i,:]) + torch.diag(self.S[i,:])  for i in range(self.n)]), axis = 0))\n",
    "        \n",
    "            \n",
    "            #self.beta = torch.mm(torch.inverse(torch.mm(self.covariates.T,self.covariates)),torch.mm(self.covariates.T,self.M))\n",
    "            #print('grad : ', self.grad_beta())\n",
    "        #print('grad :', self.beta.grad)\n",
    "\n",
    "        # gradient ascent to optimize beta, the model parameter\n",
    "        self.torch_gradient_ascent(self.M_step_optimizer, self.M_step_scheduler, [self.beta], ['beta'], \n",
    "                                   lr = lr, tolerance = tolerance, N_epoch= N_epoch, verbose= verbose, batch_size = batch_size )\n",
    "\n",
    "   \n",
    "    def get_batch(self,batch_size): \n",
    "        \n",
    "        indices = np.arange(self.n)\n",
    "        np.random.shuffle(indices)\n",
    "        nb_full_batch, last_batch_size  = self.n//batch_size, self.n % batch_size  \n",
    "        self.batch_size = batch_size\n",
    "        for i in range(nb_full_batch): \n",
    "            yield   (self.Y[indices[i*batch_size: (i+1)*batch_size]], \n",
    "                    self.covariates[indices[i*batch_size: (i+1)*batch_size]],\n",
    "                    self.O[indices[i*batch_size: (i+1)*batch_size]], \n",
    "                    self.M[indices[i*batch_size: (i+1)*batch_size]], \n",
    "                    self.S[indices[i*batch_size: (i+1)*batch_size]])\n",
    "                  \n",
    "        if last_batch_size != 0 : \n",
    "            self.batch_size = last_batch_size\n",
    "            yield   (self.Y[indices[-last_batch_size:]], \n",
    "                    self.covariates[indices[-last_batch_size:]],\n",
    "                    self.O[indices[-last_batch_size:]],\n",
    "                    self.M[indices[-last_batch_size:]], \n",
    "                    self.S[indices[-last_batch_size:]])\n",
    "            \n",
    "    \n",
    "    def full_grad_ascent(self, data, lr = None, tolerance = 2, N_iter = 500, verbose = True): \n",
    "        '''\n",
    "        gradient ascent function. We compute the gradients thanks to the autodifferentiation of pytorch. \n",
    "        \n",
    "        args : \n",
    "                \n",
    "                # I will generalize this with dictionnaries \n",
    "                'params' : torch.Tensor . the params we want to optimize. they should have required_grad = True. \n",
    "                'params_names' : the names of the parameter \n",
    "                \n",
    "                'lr' : float.  a learning rate if we want to set the optimizer learning rate to a certain lr. If None, \n",
    "                      it will take the actual learning_rate of the optimizer. \n",
    "                'tolerance': float. the threshold we set to stop the algorithm. It will stop if the norm of each gradient's parameter \n",
    "                             is lower than this threshold, or if we are not improving the loss more than tolerance. \n",
    "                'N_iter': int. the Maximum number of iterations we are ready to do. \n",
    "                \n",
    "                'Verbose' : bool. if True, will print some messages useful to interpret the gradient ascent. If False, nothing will be printed. \n",
    "\n",
    "        \n",
    "        returns : the parameters optimized. \n",
    "        '''\n",
    "        self.extract_data(data)\n",
    "        \n",
    "        # we set the gradient to zero just to make sure the gradients are properly calculated\n",
    "        self.full_optimizer.zero_grad()\n",
    "        \n",
    "        if lr is not None : # if we want to set a threshold, we set it. Ohterwise, we skip this condition and keep the actual learning_rate\n",
    "            self.full_optimizer.param_groups[0]['lr'] = lr \n",
    "            \n",
    "        \n",
    "        stop_condition = False \n",
    "        i = 0\n",
    "        old_loss = 0 \n",
    "        \n",
    "        while i < N_iter and stop_condition == False: \n",
    "\n",
    "            self.full_optimizer.zero_grad()\n",
    "            loss = -self.compute_ELBO_bis(self.Y, self.covariates, self.O, self.M, self.S,self.Sigma, self.beta)\n",
    "            loss.backward()\n",
    "            if torch.isnan(loss).item() == True : \n",
    "                print('NAN')\n",
    "                \n",
    "            else : self.last_param = [self.M, self.S, self.beta, self.Sigma]\n",
    "\n",
    "            self.full_optimizer.step()\n",
    "            i += 1 \n",
    "            \n",
    "            # condition to see if we have reach the tolerance threshold\n",
    "            if max([torch.norm(param.grad) for param in [self.S,self.M,self.beta]]) < tolerance  or abs(loss - old_loss) < tolerance : #and i > 10:\n",
    "                stop_condition = True \n",
    "            old_loss = loss \n",
    "            \n",
    "            #update Sigma with the closed form. \n",
    "            with torch.no_grad(): \n",
    "                self.Sigma = 1/self.n*(torch.sum(torch.stack([torch.outer(self.M[i,:],self.M[i,:]) + torch.diag(self.S[i,:])  for i in range(self.n)]), axis = 0))\n",
    "            \n",
    "            self.MSE_Sigma_list.append(torch.mean((self.Sigma-true_Sigma)**2).item())\n",
    "            self.MSE_beta_list.append(torch.mean((self.beta-true_beta)**2).item())\n",
    "            self.ELBO_list.append(-loss)\n",
    "            \n",
    "            if verbose and i % 100 == 0 : \n",
    "                print('iteration : ', i)\n",
    "                self.print_stats(loss, [self.M,self.S,self.beta],['M','S','beta'], self.full_optimizer)\n",
    "                print('-------UPDATE-------')\n",
    "                print(' MSE with Sigma : ', np.round(self.MSE_Sigma_list[-1],5))\n",
    "                print(' MSE with beta : ', np.round(self.MSE_beta_list[-1],5))\n",
    "                print('ELBO : ', np.round(-loss.item(),5))\n",
    "            \n",
    "\n",
    "\n",
    "        if verbose : # just print some stats if we want to \n",
    "            if stop_condition : \n",
    "                print('---------------------------------Tolerance reached in {} iterations'.format(i))\n",
    "            else : \n",
    "                print('---------------------------------Maximum number of iterations reached')\n",
    "            self.print_stats(loss, [self.M,self.S,self.beta],['M','S','beta'], self.full_optimizer)   \n",
    "        \n",
    "        return [self.M,self.S,self.beta]\n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fantastic-distinction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.09115\n",
      " MSE with beta :  0.77091\n",
      "ELBO :  3237227.86365\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.09115\n",
      " MSE with beta :  0.74783\n",
      "ELBO :  3237899.47498\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.22351\n",
      " MSE with beta :  0.23856\n",
      "ELBO :  3383268.38598\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.22603\n",
      " MSE with beta :  0.22044\n",
      "ELBO :  3383310.18445\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.26085\n",
      " MSE with beta :  0.24673\n",
      "ELBO :  3383270.03366\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.22996\n",
      " MSE with beta :  0.21221\n",
      "ELBO :  3383324.97745\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.22217\n",
      " MSE with beta :  0.31689\n",
      "ELBO :  3383128.40728\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.22146\n",
      " MSE with beta :  0.27576\n",
      "ELBO :  3383205.81881\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.22293\n",
      " MSE with beta :  0.26397\n",
      "ELBO :  3383231.01869\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.22455\n",
      " MSE with beta :  0.2038\n",
      "ELBO :  3383335.7676\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.25003\n",
      " MSE with beta :  0.2233\n",
      "ELBO :  3383318.12418\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.22874\n",
      " MSE with beta :  0.23464\n",
      "ELBO :  3383281.05518\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.22185\n",
      " MSE with beta :  0.25136\n",
      "ELBO :  3383281.49918\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.22114\n",
      " MSE with beta :  0.19673\n",
      "ELBO :  3383323.79916\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.21347\n",
      " MSE with beta :  0.19356\n",
      "ELBO :  3383347.47485\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.22855\n",
      " MSE with beta :  0.2141\n",
      "ELBO :  3383322.10903\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.20825\n",
      " MSE with beta :  0.18891\n",
      "ELBO :  3383349.74236\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.22324\n",
      " MSE with beta :  0.2111\n",
      "ELBO :  3383324.53861\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.22545\n",
      " MSE with beta :  0.20641\n",
      "ELBO :  3383333.44255\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.27588\n",
      " MSE with beta :  0.23301\n",
      "ELBO :  3383308.8541\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.20065\n",
      " MSE with beta :  0.18541\n",
      "ELBO :  3383352.33992\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.20995\n",
      " MSE with beta :  0.19954\n",
      "ELBO :  3383342.77358\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.21861\n",
      " MSE with beta :  0.2036\n",
      "ELBO :  3383341.14669\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.18849\n",
      " MSE with beta :  0.19235\n",
      "ELBO :  3383351.66813\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.18396\n",
      " MSE with beta :  0.18275\n",
      "ELBO :  3383357.97098\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.18126\n",
      " MSE with beta :  0.18882\n",
      "ELBO :  3383354.77051\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.22255\n",
      " MSE with beta :  0.19862\n",
      "ELBO :  3383343.23376\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.26516\n",
      " MSE with beta :  0.22387\n",
      "ELBO :  3383323.44994\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.16516\n",
      " MSE with beta :  0.17913\n",
      "ELBO :  3383363.07246\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.17696\n",
      " MSE with beta :  0.18462\n",
      "ELBO :  3383355.94948\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.19378\n",
      " MSE with beta :  0.19449\n",
      "ELBO :  3383351.85886\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.24069\n",
      " MSE with beta :  0.21723\n",
      "ELBO :  3383334.1208\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.17228\n",
      " MSE with beta :  0.18017\n",
      "ELBO :  3383359.24566\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.16094\n",
      " MSE with beta :  0.17797\n",
      "ELBO :  3383366.77309\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.18821\n",
      " MSE with beta :  0.19188\n",
      "ELBO :  3383355.48695\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.2336\n",
      " MSE with beta :  0.21204\n",
      "ELBO :  3383341.34533\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.16538\n",
      " MSE with beta :  0.1766\n",
      "ELBO :  3383365.90298\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.1565\n",
      " MSE with beta :  0.17641\n",
      "ELBO :  3383366.47652\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.18498\n",
      " MSE with beta :  0.19114\n",
      "ELBO :  3383359.40142\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.15168\n",
      " MSE with beta :  0.17392\n",
      "ELBO :  3383369.99612\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.14605\n",
      " MSE with beta :  0.17381\n",
      "ELBO :  3383370.63105\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.20481\n",
      " MSE with beta :  0.20771\n",
      "ELBO :  3383348.03449\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.16183\n",
      " MSE with beta :  0.18728\n",
      "ELBO :  3383364.36028\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.15037\n",
      " MSE with beta :  0.17282\n",
      "ELBO :  3383370.57919\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.15135\n",
      " MSE with beta :  0.17219\n",
      "ELBO :  3383370.72509\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.15244\n",
      " MSE with beta :  0.18404\n",
      "ELBO :  3383368.89988\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.19393\n",
      " MSE with beta :  0.19839\n",
      "ELBO :  3383351.77878\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.13854\n",
      " MSE with beta :  0.17143\n",
      "ELBO :  3383375.05536\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.14548\n",
      " MSE with beta :  0.18092\n",
      "ELBO :  3383371.97734\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.13373\n",
      " MSE with beta :  0.16947\n",
      "ELBO :  3383375.05076\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.17672\n",
      " MSE with beta :  0.19548\n",
      "ELBO :  3383360.63094\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.13231\n",
      " MSE with beta :  0.16941\n",
      "ELBO :  3383376.17997\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.14521\n",
      " MSE with beta :  0.17875\n",
      "ELBO :  3383370.50174\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.16873\n",
      " MSE with beta :  0.19191\n",
      "ELBO :  3383364.37056\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.12731\n",
      " MSE with beta :  0.16893\n",
      "ELBO :  3383377.5516\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.14826\n",
      " MSE with beta :  0.17785\n",
      "ELBO :  3383368.93406\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.12566\n",
      " MSE with beta :  0.1689\n",
      "ELBO :  3383381.04482\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.12477\n",
      " MSE with beta :  0.1689\n",
      "ELBO :  3383381.74611\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.18015\n",
      " MSE with beta :  0.19225\n",
      "ELBO :  3383359.263\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.14895\n",
      " MSE with beta :  0.17902\n",
      "ELBO :  3383370.49719\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.12044\n",
      " MSE with beta :  0.16881\n",
      "ELBO :  3383381.98268\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.17531\n",
      " MSE with beta :  0.193\n",
      "ELBO :  3383364.20441\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.11681\n",
      " MSE with beta :  0.16813\n",
      "ELBO :  3383384.29074\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.11729\n",
      " MSE with beta :  0.16802\n",
      "ELBO :  3383384.24837\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.15511\n",
      " MSE with beta :  0.19508\n",
      "ELBO :  3383367.23359\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.13981\n",
      " MSE with beta :  0.19505\n",
      "ELBO :  3383371.64887\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.12886\n",
      " MSE with beta :  0.18875\n",
      "ELBO :  3383379.11198\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.12289\n",
      " MSE with beta :  0.18535\n",
      "ELBO :  3383381.19644\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.11771\n",
      " MSE with beta :  0.18347\n",
      "ELBO :  3383376.08662\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.11776\n",
      " MSE with beta :  0.18206\n",
      "ELBO :  3383380.34593\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.11585\n",
      " MSE with beta :  0.17974\n",
      "ELBO :  3383383.73348\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.11785\n",
      " MSE with beta :  0.17887\n",
      "ELBO :  3383380.90674\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.12758\n",
      " MSE with beta :  0.17934\n",
      "ELBO :  3383379.23116\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.12668\n",
      " MSE with beta :  0.18238\n",
      "ELBO :  3383380.46195\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.11916\n",
      " MSE with beta :  0.1805\n",
      "ELBO :  3383384.2384\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.11655\n",
      " MSE with beta :  0.17804\n",
      "ELBO :  3383384.55481\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.117\n",
      " MSE with beta :  0.17836\n",
      "ELBO :  3383384.91882\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model_batch  = PLNmodel(Sigma_init, beta_init, M_init, S_init)\n",
    "model = PLNmodel(Sigma_init, beta_init, M_init, S_init)\n",
    "\n",
    "t_batch = threading.Thread(target = model_batch.VEM, args = [data, 2500,25,0.002, 0.05, False, 100])\n",
    "t= threading.Thread(target = model.VEM, args = [data, 2500,None,0.002, 0.05, False, 100])\n",
    "\n",
    "t_batch.start()\n",
    "t.start()\n",
    "t_batch.join()\n",
    "t.join()\n",
    "\n",
    "save_models(model,model_batch,25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "forty-vault",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-bf551aa3be8b>\u001b[0m in \u001b[0;36mfull_grad_ascent\u001b[0;34m(self, data, lr, tolerance, N_iter, verbose)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_ELBO_bis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NAN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_full = PLNmodel(Sigma_init, beta_init, M_init, S_init)\n",
    "%time param_full = model_full.full_grad_ascent(data, lr = 0.005, tolerance = 0.001, N_iter = 3000, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "catholic-energy",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  tensor(-4559805.4845, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-5541144.8903, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-6147233.2496, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-6505287.5955, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-6677243.8997, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-6708084.5179, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-6718686.0289, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-6788438.1782, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-6891824.6367, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-6985237.0703, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7047338.0629, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7080570.6619, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7098626.6194, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7114315.5991, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7134697.7039, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7161896.1637, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7195500.8369, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7234274.1866, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7275832.7407, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7315790.1276, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7349251.6454, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7373687.3448, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7390531.8429, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7404434.5859, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7420563.6959, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7441609.9890, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7466682.8854, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7492426.9569, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7515111.7523, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7532716.4682, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7545868.1582, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7556955.8489, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7568367.1222, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7581344.8917, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7595941.7300, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7611459.5951, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7626734.9207, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7640499.6262, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7652115.7074, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7662045.7062, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7671446.1463, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7681277.0514, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7691764.1965, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7702504.7580, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7712833.9799, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7722153.4420, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7730251.7037, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7737437.6152, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7744262.2124, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7751101.2442, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7758027.5653, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7764935.7288, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7771611.6932, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7777774.6111, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7783272.3500, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7788240.3098, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7792976.4290, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7797694.8800, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7802427.5819, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7807063.7806, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7811422.0158, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7815369.5235, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7818940.9444, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7822307.2753, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7825622.2993, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7828930.7420, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7832189.6384, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7835315.0955, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7838231.9307, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7840937.8999, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7843510.3415, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7846029.1746, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7848516.8244, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7850949.8089, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7853288.5007, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7855499.7726, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7857301.3345, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7859093.4444, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7860876.0112, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7862648.9440, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7864412.1426, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7866165.5064, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7867908.9393, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7869642.3518, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7871365.6614, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7873078.7933, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7874781.6805, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7876474.2636, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7878156.4911, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7879828.3188, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7881489.7103, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7883140.6371, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7884781.0786, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7886411.0225, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7888030.4647, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7889639.4099, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7891237.8709, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7892825.8690, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7894403.4338, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7895970.6031, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7897527.4219, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7899073.9430, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7900610.2259, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7902136.3367, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7903652.3477, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7905158.3364, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7906654.3859, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7908140.5837, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7909617.0219, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7911083.7972, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7912541.0103, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7913988.7659, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7915427.1727, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7916856.3429, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7918276.3919, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7919687.4382, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7921089.6031, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7922483.0100, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7923867.7844, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7925244.0530, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7926611.9438, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7927971.5857, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7929323.1080, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7930666.6400, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7932002.3114, grad_fn=<NegBackward>)\n",
      "MMMM_step\n",
      "loss :  tensor(-782260.4993, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2119057.2058, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1237844.3682, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-758694.4313, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-454824.4036, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-736234.8581, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-608084.7655, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1237456.3566, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-453673.5818, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2454079.6049, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-375288.2275, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-601023.1515, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1043606.5423, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-746146.2322, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1058514.5422, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1208042.2010, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2945320.8623, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-546828.5823, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-789776.2094, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-899917.7462, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-691560.2413, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-564233.3774, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-767914.2364, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-729805.7433, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-633729.2785, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1298943.4720, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1106472.7317, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1965386.6453, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-878989.9928, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-580478.9062, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-728002.9568, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-740201.8230, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-555965.3768, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-774613.1456, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2791454.1663, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-621624.3220, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-575977.7955, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-957259.9779, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-516216.7917, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1139562.4329, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1168935.5915, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1139036.6960, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-643002.7136, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1138092.8063, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-708114.7041, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1894374.2416, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-648171.2464, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-602794.7887, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-702376.8524, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-628558.6393, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-700328.6841, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1488220.5620, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-715490.2869, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-684393.8380, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-502990.4701, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2496015.1384, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2321724.2911, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-566600.6075, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1334148.5803, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-449319.2346, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-688714.2092, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-855823.1950, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-538042.2622, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1177000.9109, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-806998.3364, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-994781.0175, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1388433.1979, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2242199.4080, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-759477.4305, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-847832.8552, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-548280.7749, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-364424.5876, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-672518.6313, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-474225.8521, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-666568.2363, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2362974.8941, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-637092.2013, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1936112.7021, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-471637.5905, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-665206.2985, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-960327.8056, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-332179.6535, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-811954.8792, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-763242.9615, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-334538.3608, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-844019.4641, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1119853.4881, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2782413.2772, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2005066.8910, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-904077.1214, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-410891.9772, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1399054.3592, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-686544.4058, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1059767.6233, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-710642.8589, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-770789.8802, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1035377.1600, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1941653.9353, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1060873.0255, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-631069.5838, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-640662.9414, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-436739.4378, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-668242.9900, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1530386.7626, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-897166.4258, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1370437.2902, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-493879.7374, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-654334.7865, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1351328.0667, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-455063.2094, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1959022.4915, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-772007.3308, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-477407.6058, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1151179.9221, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1407384.5721, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-483325.8271, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-804180.3766, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2152952.2267, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-892185.2098, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-588694.4783, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-692960.5239, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-619821.8893, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1527933.5670, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-625734.2618, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1128056.2646, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2286514.2340, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-658576.7007, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-419094.8318, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2027431.6423, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-930509.2309, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-716885.4606, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-395464.7238, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-920707.4093, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-645886.3457, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-464363.2323, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1853863.3060, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2166503.3810, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-629485.8791, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-699993.6133, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1364313.0955, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-398090.2913, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-905731.2421, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-655731.0479, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1142472.2000, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-510285.1979, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-677164.1631, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-878321.0579, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-552017.1261, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1452930.7227, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2069816.7608, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1281766.3131, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-537071.8326, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-462731.9553, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-345555.9289, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-972607.9639, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1975533.7582, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1168596.1690, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-998437.6418, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-491040.2492, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1542490.1733, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1328604.0775, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-835703.1608, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-929156.4056, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-468014.7359, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-667398.8964, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-734464.1860, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2453591.4414, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-537848.0102, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-634259.2974, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1137247.9470, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2144994.2964, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1506263.4221, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-360049.6583, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-610539.2954, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-565351.5852, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-999796.7357, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2224854.1902, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1162658.6463, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-457189.0430, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-534437.8033, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-785884.9672, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-770647.3452, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-474835.7243, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1545733.4230, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-505836.7547, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-865002.6849, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2414974.6814, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-602961.0579, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-933373.8288, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-529583.8924, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1285027.6411, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-829711.5653, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1060416.2568, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-911351.6105, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-677190.7586, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2669309.2649, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-707196.2352, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-697904.6614, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-602678.5266, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-634481.0299, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1317792.1573, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-379139.2760, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-395659.7925, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2012549.6818, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-766714.9327, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-715400.5734, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-653172.6337, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1719572.7770, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1501088.7472, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-912649.2338, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-700896.5269, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-561652.6008, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-560238.1670, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1958617.8749, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1453344.4796, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-303496.6346, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-770364.8984, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-746735.0148, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-291932.7485, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2866985.1301, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-462300.3989, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1552352.5357, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-585361.7914, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-682973.4514, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-567234.9041, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1167461.1588, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-503945.0334, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-700426.8707, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-938177.1571, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-924767.0936, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-910306.0435, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2255025.0833, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-671958.0121, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1377671.1982, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-566006.4737, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2388312.0879, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1260808.7080, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-720547.6052, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-546855.1701, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-438080.3101, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-889571.7683, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1166241.4508, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1167952.0375, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-440277.0967, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-510721.3740, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2084894.7854, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-808383.0223, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-901753.5841, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2307251.3503, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1511766.6446, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-502462.1423, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-569798.5524, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1050417.9931, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-497140.3295, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-759292.7856, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-769975.3257, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1265637.4262, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-403078.2810, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-886427.1294, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-701532.3275, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-774593.9798, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2471468.8369, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-550749.7912, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-915217.9287, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-566790.1880, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-996895.3978, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-758687.0599, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-640831.8244, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-738577.4642, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2052870.6826, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-700399.5992, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1512782.8370, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1369722.0051, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-516437.1739, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-323783.9689, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-848256.2213, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-573345.7502, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-874228.9937, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-443295.9646, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3020588.8957, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1027324.3907, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-606262.8769, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-583105.7196, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1275635.1364, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-451002.7118, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2318333.5064, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1118387.2771, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-591654.7079, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-401693.2994, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-594045.0063, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-957529.3468, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-456949.9692, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-977432.2442, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1060555.5016, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1247546.9726, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2271586.3232, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-753910.6790, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1242926.4072, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-343901.0493, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-987747.5916, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-528430.0013, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2494203.1202, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-567011.2974, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1053772.8950, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-513497.8582, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2200780.8608, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1160884.3177, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-490286.0228, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1392367.6085, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1077940.8467, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-775277.8120, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-358476.5893, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-735256.1202, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-982605.0917, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-766827.9309, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-585370.1271, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-503129.4435, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-713243.7935, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2205979.8079, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1473231.5259, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2454691.9602, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1489266.5682, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-450738.4428, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-672308.7895, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-526666.5299, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1038158.5266, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-602320.5882, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-740365.7012, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2056785.7002, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-883683.3028, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-778509.9799, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-685785.2053, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-561697.2914, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1414775.9843, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1001494.8656, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-592761.7310, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-543887.7832, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-651664.1201, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-893770.2626, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-937439.2906, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-695289.0874, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-809455.7504, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2862552.7979, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-576884.6635, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-518919.8402, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-592701.0107, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-744619.8180, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1112734.8935, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2221837.1567, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1170025.9886, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-965279.1841, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-648860.6881, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-448881.9700, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2236483.1531, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-630719.9273, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-983126.7004, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-379188.4786, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-891289.1532, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1083049.1457, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1323110.3966, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-693619.1588, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2232186.3218, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-369281.7847, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-570482.6267, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-710356.7317, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1977598.2055, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-630842.9666, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-796329.8873, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-569408.8602, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-731696.0120, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-531763.5899, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2522787.0584, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-734326.5621, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-685066.0360, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1147503.4996, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1054547.9693, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-575053.1906, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1038402.9469, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-694086.5408, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-557637.6510, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-373327.7231, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-434920.2401, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-444819.0421, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3853915.9472, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-566289.9028, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-655180.4743, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-533763.2116, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1518643.6532, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1322702.3879, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-663376.0130, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2107287.4944, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-613619.8455, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-398699.2589, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2107055.5322, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-572942.0840, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-774305.3667, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1084308.0636, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-852738.2409, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1438835.7010, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-748056.5427, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1379060.0328, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-659367.7274, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2244543.6073, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1185380.3601, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-822759.3054, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-402522.1364, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-619559.8570, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-663699.6921, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-616605.8901, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1034390.7584, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-385669.8015, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-930186.1065, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-257823.5587, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1362255.7812, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2093032.8408, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1286687.0052, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-735913.1579, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2503223.2514, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-463451.0150, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-584753.9187, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-436181.0220, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1311804.8398, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1307637.3992, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-633228.5721, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-549614.6145, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-714838.1560, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-749919.8195, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2316575.6936, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-983443.1518, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-457688.7130, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1453195.5312, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-753525.1404, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-916707.5617, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-656738.7177, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-911872.1821, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-476371.5055, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-523405.3997, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-854716.5549, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-965666.2783, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2665692.8034, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-858872.6122, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1396070.3491, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-957337.2008, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-721380.6461, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1891135.6106, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-660538.9493, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1032820.4897, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-464557.8165, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-816873.1694, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-697646.1364, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3161611.4784, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-709881.5297, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-407423.9273, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-362659.1045, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-554978.0974, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1265409.6563, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-933925.4326, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1339506.8086, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-404566.4547, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-700169.1585, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-641673.8134, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1439410.1088, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-481059.8218, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2038043.5137, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-733772.7910, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-547182.5996, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2196017.4794, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-631490.6351, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2057956.2811, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-847535.6800, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-732521.5142, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-225032.1705, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-648619.3967, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-596198.6942, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-633065.1260, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-655001.5425, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1279470.0648, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-626459.0170, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-775843.8615, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2762223.2462, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2142328.3425, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-629687.1086, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-345231.9485, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-384223.8719, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1163774.3190, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1006343.2396, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-672158.3589, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1637190.1980, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-465378.2616, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1248855.7541, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-326967.7368, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-915269.1935, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-623254.0317, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1316190.4742, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2146488.0184, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-940683.5752, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-802465.4415, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2317973.9202, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-924024.2200, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1030866.6449, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1125358.7145, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-389178.1433, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-885654.0183, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-504200.8214, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-293887.1451, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-919924.4581, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-775740.0266, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-900038.4666, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2181029.2176, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-750157.6363, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-649883.2711, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1511888.8533, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2055168.6304, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-618144.5328, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2134571.5325, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-551937.8780, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-583857.0762, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-505255.8636, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-708725.8745, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-828141.5447, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-802384.2332, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-503288.5642, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-983563.1495, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1174989.1074, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-850381.3528, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2507248.4066, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-482321.9252, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-676867.2202, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1692901.5891, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-855260.0966, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1993998.9400, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-632481.1078, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-420583.9742, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-688079.0606, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-766270.7988, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-933533.2373, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-245041.6153, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1091628.9507, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-987997.6364, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-659632.1031, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1447705.1771, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2102410.5855, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-977783.3170, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-468155.3433, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-710120.1704, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2167103.9305, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-562234.7433, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-857011.9642, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1117346.3665, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-667542.1081, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1050092.7634, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-849945.4818, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-434009.1583, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2290471.5210, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1173622.4088, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1016795.0410, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1337734.0758, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-817368.7361, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-213437.8267, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-702435.7682, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1312395.4478, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-831106.8340, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-822467.1004, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-321890.0230, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-451127.8286, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2116657.4621, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1174289.2296, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-953857.6108, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2439882.2418, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-453506.5532, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-945634.5808, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-930737.9972, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-588659.0542, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1332304.7195, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-798127.2981, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-495952.8963, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-506670.9270, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-743218.8157, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-814202.0329, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-711631.4297, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-431614.0079, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-811256.7834, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1670997.7599, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2288926.7739, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-576421.8369, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-737259.8328, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-803244.6450, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1278407.6486, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-722838.5594, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-664761.7012, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2116285.1176, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1091731.3587, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-872074.3438, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-566964.7415, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-646024.4082, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-552786.1868, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1253698.1358, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-900103.3796, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-475237.1718, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2716190.3634, grad_fn=<NegBackward>)\n",
      "VVVV_step\n",
      "loss :  tensor(-7989187.0922, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7990407.2583, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7991638.0810, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7992874.5470, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7994113.2929, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7995351.8699, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7996588.4177, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7997821.4906, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-7999049.9546, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8000272.9221, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8001489.7037, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8002699.7719, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8003902.7328, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8005098.3046, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8006286.2998, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8007466.6085, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8008639.1836, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8009804.0279, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8010961.1834, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8012110.7223, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8013252.7392, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8014387.3443, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8015514.6579, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8016634.8062, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8017747.9185, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8018854.1256, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8019953.5585, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8021046.3479, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8022132.6234, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8023212.5124, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8024286.1378, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8025353.6171, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8026415.0633, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8027470.5855, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8028520.2910, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8029564.2843, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8030602.6663, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8031635.5324, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8032662.9720, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8033685.0691, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8034701.9038, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8035713.5536, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8036720.0941, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8037721.5996, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8038718.1424, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8039709.7934, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8040696.6212, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8041678.6927, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8042656.0723, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8043628.8225, grad_fn=<NegBackward>)\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.09431\n",
      " MSE with beta :  0.80634\n",
      "ELBO :  8043628.82248\n",
      "MMMM_step\n",
      "loss :  tensor(-1172140.9520, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-769230.2992, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-671951.8564, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-591928.0063, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-489481.1894, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-569337.2717, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-750347.6691, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3023617.0933, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-744358.4860, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-983737.4873, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1602991.3663, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-519783.5256, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2221777.6092, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-762224.5011, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-393929.3610, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-810929.7506, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-800743.4790, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-488030.5715, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-608490.6606, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1130319.7834, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2103716.7495, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-849525.5071, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1375264.2587, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-687272.7333, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-638132.3332, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-659394.2739, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2478675.0138, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1628218.9024, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-682258.6206, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-882217.3164, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-383449.4702, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-690896.2568, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-635438.4494, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1555132.3363, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-735422.0578, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-455575.9731, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1297437.2094, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-589267.4873, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-557704.8683, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2215289.9998, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2029534.0827, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1036512.4233, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-538621.3529, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-878702.8986, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-483672.6290, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1952060.4864, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-518575.1819, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-604645.5759, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-875478.7570, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2918298.1184, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1318847.8051, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-664321.5223, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-633111.1968, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-489201.7503, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-606630.2589, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-536530.5770, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2007518.0610, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1942034.8918, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-717314.9286, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-728623.1644, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-606613.9355, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-721435.4981, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-520462.3651, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-801164.8692, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1088275.2584, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1539842.0187, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-779335.9203, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-436555.9753, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-561055.9748, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2127121.4984, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-455975.1503, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1054126.5078, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-628780.3607, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1928141.7430, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-617495.8656, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1014613.8717, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1364689.0373, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-987550.0094, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-675504.6672, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-826220.2654, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-422171.0487, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-739387.3384, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1120443.6373, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-989034.0792, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2243574.0008, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1244421.8718, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-697619.2032, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-588530.2335, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-783444.7425, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2090972.1994, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-600472.6123, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-764986.9415, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-621351.2251, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1019556.3828, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-967551.9082, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1197597.8595, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-377133.8692, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-748890.2755, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-520339.5401, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-740532.6786, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1222921.9593, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1494495.5287, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-929611.8865, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2010638.4633, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-538228.0940, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-684687.7214, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-884822.6152, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-644216.2361, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1882014.2226, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2113225.9659, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-738916.6120, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-558982.5790, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-768300.9076, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-723956.5845, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2848627.0894, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-626777.5856, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-501195.3595, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1103202.8833, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-591378.0902, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-874516.3250, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-781796.6487, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-584970.2734, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-937193.7888, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-523136.2996, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-555797.1492, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2835518.9726, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1109450.4347, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-709679.3134, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-668377.6664, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-919962.0783, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-570448.3728, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-648531.5209, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2545208.7771, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-573496.6437, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1619539.8990, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-493515.6717, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2038396.3837, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1116659.3997, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1191171.3601, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-949465.3044, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-754163.8764, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-538716.4434, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-823192.9112, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-629075.4842, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-738810.6263, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1529509.7189, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-888508.0470, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-726499.5841, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-373743.9510, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2139484.5742, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-433232.7927, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1216306.5101, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-743921.2453, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2581829.8396, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1026146.7315, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-610109.9584, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1391490.8926, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-548158.4945, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-735257.9952, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-404640.4860, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-964667.6536, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1261456.7471, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1140523.6927, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-652422.0207, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-883061.1133, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1785797.4907, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-698856.8282, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-660641.3931, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-638244.9752, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1190779.3860, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1168084.8265, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-826625.6012, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-585015.3318, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-533463.0571, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-518577.8498, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2586559.0250, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-918304.8966, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1084259.0171, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-613796.1763, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1971284.4723, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1398765.6841, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-906441.0300, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-578085.0571, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-573134.5618, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-715469.6636, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-824333.7215, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-579007.9858, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-576579.0874, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-729892.5590, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3501579.9166, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-617889.5108, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-502151.3804, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1276118.3338, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-537840.7106, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-392263.2515, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2325562.6855, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-826566.1580, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-932474.5228, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1148093.5477, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-607322.2135, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-802349.9132, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1284814.5727, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-906647.4263, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-745532.8896, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-811140.8173, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2057468.6820, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-665812.3082, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-773033.4032, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1109418.3808, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1204694.1576, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-684176.9728, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2268659.0326, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-696157.6909, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-712425.3280, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-723193.5922, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-649730.4200, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-692703.9237, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-756006.4953, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1118524.5927, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1566633.9832, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1956823.5797, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1120757.4971, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-398061.9284, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-436207.8405, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2311411.6418, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1463525.0611, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-517966.9474, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-408922.5165, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-652115.1471, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-860862.6223, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-671624.2262, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1160911.4557, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-339109.3969, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1544340.5685, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-875836.2234, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-606474.5730, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2133448.7002, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-376172.9625, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1477853.8079, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-693923.3001, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1947860.3975, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-976125.2352, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-451505.0755, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-866308.1110, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-570291.6712, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1939880.8403, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-598593.2079, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-696670.1885, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-803659.3028, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-459076.2430, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-336001.8162, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1425141.4817, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2263761.2319, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1191417.5759, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-580622.5240, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-986602.2138, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-420256.4555, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1606981.1665, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-629725.5663, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-419257.8613, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-790873.8707, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2359923.6948, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-711851.4869, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1107819.2298, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-672475.4767, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2317246.9263, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-768715.2656, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-530424.8298, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-970793.8590, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1179492.9265, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-600101.3378, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1007692.9345, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-420049.1807, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-514013.1709, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-950472.7808, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1406731.4746, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-312222.4068, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-965093.2421, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1822272.0006, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1656836.0979, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1110822.0277, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-643150.4067, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-940234.5562, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1048199.5445, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-737175.4549, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1911271.1670, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-745868.6021, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-912497.6213, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1360419.8464, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-889202.4404, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-562348.7833, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1224894.5797, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1961095.7014, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-629517.5495, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-848982.6950, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-572812.7169, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-398443.3840, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3327939.6333, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-554959.0652, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-467220.0676, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-968144.2390, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-760499.9120, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-655686.9094, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-913724.4723, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2509550.7088, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-610001.3800, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-813708.2139, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-420049.6316, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-997211.3474, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-713680.0223, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-834935.4628, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1146633.1078, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1251685.8999, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-805879.2976, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-490551.8194, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-863921.2813, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1284040.3240, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-752713.0202, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1984934.1310, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-614837.7161, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-789223.0500, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2893593.9321, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1174638.3558, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-482015.2584, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-845537.9995, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-559127.7952, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-684253.9951, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-609634.8596, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-674261.5999, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-658307.8918, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-561141.2456, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1078531.9680, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-552990.5396, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-855760.1631, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-534551.5420, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3116889.2553, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1192807.3531, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-596463.6453, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-880670.2345, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1989861.4649, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-895095.0415, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1368195.9168, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-419138.0535, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-703961.8197, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1189921.2600, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-678078.6194, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1150829.1792, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-522718.7734, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-687324.4303, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2127004.0043, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1024064.3073, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-665376.6366, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2736449.6759, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-463490.9559, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-331609.9341, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-504587.8370, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-635833.6272, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-814922.6839, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1386934.7277, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1172105.5636, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-454610.9710, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-694429.4763, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2238832.3049, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1003509.4732, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1972882.7511, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-471202.3226, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-545083.5304, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-668153.4565, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1995747.3451, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2067908.9586, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-453238.8004, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-775237.5932, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-649057.8355, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-618323.8196, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-570138.0286, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-917846.1380, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-584249.8433, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-530759.2987, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-947974.8624, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1069609.1821, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-468633.2295, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-517796.8992, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2869632.9167, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1051061.9884, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-775605.1696, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1268253.0041, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2111284.5022, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1252677.4407, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-762711.1137, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-839068.8787, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-370334.7911, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-669593.6169, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-817015.4485, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-722669.0999, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-426698.9200, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-574286.8842, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-927564.7158, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1903700.0305, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-649780.3292, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2024876.2738, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-545265.2999, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1018826.1452, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-443584.8745, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3290977.8467, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-487664.7680, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1139653.5990, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-388479.0330, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-732716.5598, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-727130.9683, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-837387.6833, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2915381.0473, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-440813.6830, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-706459.0648, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-789529.3355, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-408865.0007, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1223424.1538, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-515461.8661, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1143360.3850, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-707180.2025, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-694742.6359, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-637461.2137, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1949213.7868, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-961584.4678, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1439823.2963, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1212837.0603, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2476075.0920, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1012057.0865, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-772611.8749, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-746444.4452, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-665331.0394, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-259278.3686, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-903030.3232, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-431293.0027, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2264085.7951, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-782541.6479, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-382976.1766, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-519728.4757, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1502826.0005, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-596824.3770, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1569969.1507, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-329135.4537, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-749485.3620, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-885139.7011, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-766820.4615, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-598192.3901, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-777664.6605, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1333327.3412, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2607156.4823, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-926934.5116, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-515444.4239, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1736804.4626, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-718890.2612, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-836819.8193, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-679620.3090, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2009651.3031, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-625725.1692, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1164542.6836, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-632773.9219, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1997758.5334, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1257678.6531, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-659185.7611, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-975006.5083, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-653355.7593, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-708176.9145, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-587105.2771, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2283558.2524, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-757572.7793, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-983854.4149, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-706823.0932, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1321146.2220, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-522347.1898, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-885095.1786, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-447557.5437, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-515179.6480, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-833988.3188, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-887350.8101, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1178822.9386, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-809865.5085, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1180478.7331, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2195779.0914, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1243235.8993, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-796539.4818, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-442068.2989, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2154707.4531, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1868712.5543, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-658798.6222, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-427147.6067, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-457173.5934, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-612562.0952, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-466382.8953, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-511522.3546, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-479681.9467, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1450443.3263, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-868303.6833, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-764189.6485, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2890142.0009, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-705403.3221, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1062095.5157, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2514199.2571, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1111942.1794, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-655809.8655, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-936139.3616, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-550531.4559, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-512546.1434, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-675852.5372, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-805229.8656, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-333869.7049, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2132504.3207, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-800213.9719, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1292376.6970, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-533364.6716, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1474281.1841, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-628669.8230, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1458373.7852, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1893902.7004, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-322547.0927, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-682349.4143, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1209949.3528, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1199622.7837, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-654741.3369, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2073659.0066, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-554658.0183, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-907403.6884, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-554337.5321, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1086944.5859, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1491275.3750, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-445103.6341, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-933679.2698, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2236357.1365, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-671056.8412, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-566321.6320, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-637298.9682, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-825818.4667, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-596845.5276, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1970971.7442, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-546740.7328, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-426391.2005, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2193011.5853, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-836536.9966, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1075177.8485, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1243666.7657, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-754222.3439, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-986255.4533, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-534860.7590, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1124739.4596, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-573051.8989, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-568152.3260, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-639435.3351, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-519609.6103, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1200318.1689, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-878432.7848, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2546201.4686, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-957782.1734, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2777633.7447, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-694710.3871, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-651741.6303, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-548765.9645, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1397502.6771, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-467488.5236, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-553036.7975, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-938515.0130, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-522886.9904, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3016157.8280, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-483556.4366, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-680130.6239, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-787397.0500, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-871314.3130, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-747750.2665, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-775540.8887, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-698200.0130, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1625310.0717, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1053985.6932, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-750843.6320, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2114895.5213, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-502153.0336, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-531171.6866, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1048624.0920, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2650070.2776, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-496345.0774, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-582205.5639, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1053691.3778, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-722844.2632, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-982436.9045, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-514711.1696, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-420164.1536, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-821378.0374, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-950127.1290, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1215672.2744, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2456408.6197, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-572848.5383, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1029083.4135, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-585337.5426, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1340197.3790, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-813808.7933, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-866245.6624, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-641794.7215, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2254197.2327, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-555347.7249, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-437272.3356, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1143472.7798, grad_fn=<NegBackward>)\n",
      "VVVV_step\n",
      "loss :  tensor(-8053955.0390, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8054923.7326, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8055891.4493, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8056857.5888, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8057821.6879, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8058783.4147, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8059742.5229, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8060698.7940, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8061652.0083, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8062601.9474, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8063548.4092, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8064491.2194, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8065430.2353, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8066365.3442, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8067296.4602, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8068223.5201, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8069146.4781, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8070065.2998, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8070979.9579, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8071890.4300, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8072796.6981, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8073698.7515, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8074596.5878, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8075490.2131, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8076379.6397, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8077264.8833, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8078145.9611, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8079022.8905, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8079895.6904, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8080764.3815, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8081628.9865, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8082489.5301, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8083346.0377, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8084198.5357, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8085047.0509, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8085891.6111, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8086732.2447, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8087568.9809, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8088401.8496, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8089230.8807, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8090056.1046, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8090877.5517, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8091695.2526, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8092509.2381, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8093319.5385, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8094126.1842, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8094929.2053, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8095728.6319, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8096524.4936, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8097316.8202, grad_fn=<NegBackward>)\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.0919\n",
      " MSE with beta :  0.75464\n",
      "ELBO :  8097316.82021\n",
      "MMMM_step\n",
      "loss :  tensor(-512736.1426, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-581050.9737, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1204144.5575, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-945107.9348, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1751904.8281, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-472647.9273, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2027204.4066, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-601076.2500, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2056488.3321, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1133595.7558, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-547506.0227, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-880353.2959, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1125960.8536, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-496324.0748, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-673711.6487, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1182220.8976, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-583937.7411, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-439487.6969, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1159508.1539, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-820302.8063, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2834606.4788, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-887828.6687, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-825832.8493, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-545246.5632, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1861358.4412, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-781799.4399, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1464270.0153, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-585937.4318, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1009258.5300, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-880290.4248, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-560880.6759, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-952816.0111, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1331122.0491, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1471933.3805, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-524803.3510, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-539883.8300, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-639417.4653, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-759297.1141, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-433092.7057, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2393900.2513, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-582675.0155, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2077428.5041, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-506277.4195, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1145185.5544, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-809063.1616, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1514562.7602, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-958178.4570, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-501458.8505, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-545662.5085, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2732931.2942, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-599633.4462, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1093835.6019, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-652338.0206, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-707614.6309, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1339780.6287, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-425098.9546, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-726077.9921, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1330723.5974, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-963428.3652, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-405994.8300, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-830812.9621, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-582668.6383, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2030202.7613, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1225642.8164, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2007729.7150, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1017568.7364, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1539772.0587, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-834939.6725, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-539069.6627, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-692464.8488, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-611779.6751, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-849484.7748, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1491279.0874, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-659654.3237, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-766573.8817, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2169061.7443, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-403246.6493, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-931882.0706, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-987570.6465, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-688113.7697, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1432214.9505, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-825132.6118, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1176890.8955, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-808643.0287, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-787737.3194, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-801294.3668, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-399115.9662, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1865004.4207, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-665093.7060, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1126940.2330, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1377141.1324, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-716491.2055, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1945229.6990, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-461832.6879, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-542497.2616, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1260942.3498, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1103340.1041, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2029332.8547, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-366077.8547, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-590612.0942, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1156177.8301, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-813326.5623, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1184705.4843, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-853255.1683, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2188815.7618, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-249123.0405, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1169633.0677, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-507084.7516, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-666037.1441, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-980312.8597, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1677661.0382, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-658031.8723, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-584128.4802, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1250559.4431, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2150707.2076, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-608414.4800, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1087467.3231, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-986551.9352, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-913742.8366, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-516087.9314, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-976664.1909, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1593120.5114, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2496867.7538, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-339430.7882, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-669870.9121, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-657681.9626, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-686920.5464, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-676819.3978, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1034311.0878, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-454666.7479, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-438341.5863, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-816703.2254, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1438278.1814, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2372384.1922, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-479606.3151, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1062467.9473, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1523942.9010, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3271922.2395, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-588022.5216, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-774134.7347, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-282747.6521, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-614701.5317, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-581151.4371, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-454553.5720, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-531578.7644, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-485330.2235, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-847436.8888, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1034497.5285, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2182531.5551, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-961249.5140, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1318974.1731, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-733075.5287, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-581128.9897, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-616909.0557, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1106255.8334, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-353699.2443, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-722335.5223, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2062186.4049, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-822727.9211, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1826534.8127, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-847079.8283, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-645451.9142, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-895004.3418, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-515837.1948, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2009484.7202, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-780449.1927, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1200633.2771, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1205908.8746, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-880956.1126, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-486864.5391, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-687277.8262, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1350329.0430, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-636379.4535, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1219903.6050, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2076057.6476, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-757885.9420, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1188814.3324, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1950335.3166, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-965607.6054, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-849638.1438, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1076147.0117, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-710557.3752, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-691861.4711, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-664874.5166, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-587558.1997, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-870607.7912, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-493053.8368, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1793751.9266, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-824086.7527, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-807144.6342, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-697988.1913, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2023029.3457, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2129120.7147, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1080234.0848, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1465797.2167, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-729595.5429, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-463525.4617, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-402866.4290, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1240837.2442, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-583101.3332, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-449569.0386, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2761067.9063, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1676156.4112, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-692277.1540, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-719901.1876, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-390018.6832, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-722329.3287, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-687141.5198, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-506448.8553, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2026660.7509, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-609669.2766, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1134724.7304, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1661199.9987, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-429915.2743, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-802330.2132, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-925211.0514, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-740730.6066, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-757866.1594, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-836269.9617, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-734608.7982, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-792748.9653, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1376656.3160, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1139428.5011, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1721546.6473, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-487962.2106, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1110402.1873, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1237500.0474, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-561654.3059, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-734331.3572, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2197174.1036, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-485921.3213, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1280467.4570, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-577502.5740, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1737656.6679, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2549107.8166, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-679955.1653, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-752676.8393, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-525853.0775, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-767207.1299, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-509833.0868, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1090178.6557, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-765320.1475, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-450773.9597, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2165865.6831, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-678903.1099, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-679248.5192, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1457908.2885, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-806116.9931, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2264854.3813, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-402677.9319, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-483168.4554, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-610968.2246, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1205699.5876, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1215175.3617, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1260031.4371, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-653032.0255, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-809136.7045, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-522961.2070, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-897640.7953, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-726490.0501, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1003046.1093, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2716734.9963, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-380061.6395, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1039783.5694, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1978879.1353, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1106179.1335, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1475709.9146, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1046267.5743, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-458030.0631, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1145309.3274, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-422362.0338, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-465496.9150, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1286085.7460, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-743858.4750, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2946864.1261, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-720161.7451, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-317930.4910, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-698933.9795, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-786781.2333, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-598569.4687, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-898218.3671, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-661794.4761, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-529193.8815, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-426447.8878, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2902636.9870, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-897035.2005, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-681688.3384, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1097305.9258, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-587163.3583, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-826199.6400, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-956951.7254, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1913851.6912, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-816806.2724, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1069936.0926, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1168372.3255, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-754801.6591, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1659925.2239, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-589291.3550, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-706209.9870, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-776142.4518, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-598072.3864, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-697232.9999, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2356828.6681, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-714131.3792, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-538083.7403, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-576688.7856, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-618747.4494, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-975706.6951, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1979146.5995, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1777190.5996, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1078243.7985, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-553406.0759, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1419732.8757, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-688829.1961, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1220952.7258, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-540800.9884, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-482588.8752, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-800867.1544, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2322535.9821, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-621401.4423, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2243051.3068, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-573171.6533, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-416206.0363, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-946478.9001, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-838807.1108, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1022855.2841, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-856360.0518, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1202268.0807, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2217745.5459, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-621328.6546, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-617930.1746, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1623706.1434, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-642602.1532, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-579960.0238, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1080721.8981, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-714881.6242, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1567358.9518, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2021999.5521, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-708957.3590, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-484930.0660, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1297171.9037, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-573360.0825, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-975931.6410, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-470130.9951, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3285971.5129, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-556023.7377, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-763993.4443, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-812847.5315, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-850288.0090, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-327544.7555, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-797900.7105, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-703904.1585, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1206369.4577, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-720285.3651, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-644962.9487, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1055348.9139, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2050085.3120, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-543485.7059, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-596990.5981, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1279749.5324, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1204919.7062, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-583279.8489, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-597597.8502, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2004666.8419, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-894291.7828, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-680458.2109, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1233982.2987, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-900381.4095, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1111465.0726, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-912539.2996, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-560697.8532, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-372966.6495, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-721443.4406, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-374115.7221, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2427651.3380, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1616006.6838, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-330861.4267, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1334265.2587, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1255987.2700, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-587463.4919, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-979586.8803, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-777988.4481, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2092115.4588, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-740250.6206, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1792977.2129, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-606165.6232, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-958256.0433, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-608996.4448, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1783187.3946, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-530324.6379, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-596907.4129, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1221605.2802, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-768500.7135, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-874271.2937, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1412067.2718, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-350889.5649, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2312512.7223, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-506156.4549, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-594476.7755, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1279067.6510, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-552213.9610, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1112984.0351, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-749778.2553, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2796865.6377, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-723795.9473, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-512634.9423, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-868948.3864, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-781121.3938, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2171513.6904, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1095538.8631, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-847472.3683, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-913894.3163, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-812271.0066, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-552839.9990, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1301163.2217, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-404223.2214, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-564588.1456, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1389807.0408, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-605202.2761, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2060613.9893, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-669912.2327, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-648191.6011, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1342075.6423, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-817707.8969, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-678986.6374, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1226615.8141, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1552636.8961, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-368045.2106, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-857907.5489, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2101200.7394, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-724429.8920, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-589297.3714, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2030287.4419, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1320458.0392, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-821529.2305, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1526929.3964, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-687006.2987, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-307124.9300, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-918194.6788, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-486869.3336, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-727841.2117, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2277196.0557, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-650464.4916, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-697350.6343, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-530510.7478, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-577080.9073, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1791574.9893, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-846112.4932, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1313353.8244, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1544581.0666, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-447850.5648, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-548403.7994, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-734353.4731, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-426906.9972, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2311254.7186, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-772773.9538, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-857461.7016, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-652961.7791, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-549083.5243, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1032448.4177, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1960871.2941, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-694162.1825, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1359346.3712, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-990076.9917, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2017183.0285, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-835330.9953, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-749131.1424, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1792613.1208, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-883556.8484, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-537163.9427, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-631929.6828, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-648518.9064, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-850755.7753, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-896278.3831, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-601579.7307, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-514510.1688, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1026672.8058, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-809595.0121, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2515159.8030, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-881454.7788, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-742833.9937, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-840771.7236, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-797748.0256, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1072982.3840, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1977171.1738, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-687341.7629, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-634912.0110, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1346228.6285, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-887758.7718, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-582429.8004, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-421473.9556, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1109238.3653, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-711177.5895, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-775978.4122, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-769147.2676, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2839345.7590, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-573061.7053, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-682468.5344, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-517171.4248, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-890729.0832, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-963342.1826, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1320990.8947, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2319288.9681, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-831470.9383, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-636831.8797, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1595495.5402, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-470324.3755, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1112344.8160, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1946887.4448, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1245625.8247, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-624610.1439, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-464971.1637, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-797426.3759, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-594930.6941, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-570579.9300, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-527007.8462, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-702876.7664, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-787963.0394, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1549642.5222, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2565538.3295, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-510336.8109, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2443505.8164, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1242563.5532, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-832363.1345, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1208667.0523, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-391835.5337, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-828802.2946, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-641774.5879, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-837365.5377, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-998674.7871, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1987659.4156, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1085189.4967, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-576703.7656, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1012077.4361, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-614149.8460, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-987617.8489, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-711103.7610, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-846018.8948, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2285760.4100, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-530617.4351, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-697233.6240, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-504467.6960, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1250502.1498, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1272594.3838, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1313039.8935, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-473027.6697, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-480638.0008, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-738120.9296, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-940213.3571, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-599220.0222, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2877443.0402, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-677847.1258, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-516649.7098, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1487360.7461, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-545628.7166, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2067976.5595, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-889443.3215, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1039398.8771, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-624711.7231, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-927274.6525, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1013859.1705, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1670415.8820, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1849003.9115, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-948168.9229, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-949505.4752, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-516268.9442, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-629143.5529, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-520542.1415, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-905661.7140, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-562486.0499, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2068903.7536, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-513367.5925, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-898286.1545, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-798674.8743, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1017943.8523, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1334672.2036, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-522665.0878, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-682123.3613, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-971119.7403, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-836009.9687, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1042229.8895, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1301623.9725, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1957222.9185, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-785756.4789, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1561822.3976, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-627455.9817, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-505356.1214, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-827501.7635, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-685791.4509, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1234360.3652, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2090377.2355, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-567197.6181, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-421950.3666, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2882961.0737, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-551685.3988, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-952741.8536, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-748819.9836, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-842365.7442, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-974223.3723, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-723807.6329, grad_fn=<NegBackward>)\n",
      "VVVV_step\n",
      "loss :  tensor(-8100279.8461, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8101086.8527, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8101893.2329, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8102698.3526, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8103501.6987, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8104302.8881, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8105101.6533, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8105897.8128, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8106691.2393, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8107481.8352, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8108269.5149, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8109054.1968, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8109835.8027, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8110614.2581, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8111389.4916, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8112161.4358, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8112930.0327, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8113695.2386, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8114457.0292, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8115215.3981, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8115970.3525, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8116721.9051, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8117470.0674, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8118214.8467, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8118956.2460, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8119694.2668, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8120428.9119, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8121160.1881, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8121888.1067, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8122612.6832, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8123333.9363, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8124051.8875, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8124766.5601, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8125477.9788, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8126186.1689, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8126891.1555, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8127592.9631, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8128291.6150, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8128987.1343, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8129679.5439, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8130368.8670, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8131055.1279, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8131738.3515, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8132418.5628, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8133095.7868, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8133770.0480, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8134441.3703, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8135109.7769, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8135775.2908, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8136437.9346, grad_fn=<NegBackward>)\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.08647\n",
      " MSE with beta :  0.72193\n",
      "ELBO :  8136437.93455\n",
      "MMMM_step\n",
      "loss :  tensor(-1253667.0995, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1016802.2166, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-538911.7565, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-683077.1713, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-684629.0985, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2334278.8411, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-679911.6493, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-944904.3634, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-822793.8976, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-551169.1512, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-510641.5579, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1288477.6979, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2298356.7999, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-738002.0775, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1385662.1746, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-541770.5516, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2433994.8958, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-671779.8171, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1336953.6510, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1515382.3173, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-659811.2269, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-517635.8575, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-268310.3562, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-732720.2320, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-853199.8884, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-452912.2967, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-904636.0265, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-840752.1730, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-487477.1578, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2253084.6016, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1197754.5845, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1146471.5775, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-641249.0434, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-979262.9953, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1118455.0470, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-648681.5176, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1453994.2327, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1944058.2575, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-757018.4952, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-593908.4138, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-601536.3401, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-593684.8177, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-759309.8174, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-779610.8764, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2126762.2926, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1412546.9562, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-621266.3764, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1240763.7966, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-814112.7125, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2528318.2637, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-737210.6209, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-617249.9716, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1221434.0216, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-852784.1649, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-701724.5824, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-664206.6545, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2619556.1449, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-718744.0395, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-469732.9421, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1176978.6487, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-918236.0833, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-668114.8717, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-452966.2450, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1111984.4897, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1190109.1286, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-735492.9224, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-347470.7106, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-944501.7915, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1104117.8301, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-606308.2807, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-663608.6268, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2543340.8752, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-720806.8488, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1269950.5958, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-900189.8503, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-690988.4535, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-691413.9037, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2145644.4206, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1288909.5615, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-428064.2560, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-517021.0701, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-508980.3798, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-797285.3522, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-804717.1698, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2045108.9667, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1579958.6229, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-820428.9891, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1064099.8132, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-820127.9790, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-745799.4927, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-464546.2438, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1049154.4951, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-902657.2557, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-757566.5553, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-719120.2849, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2677766.8733, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-780812.8199, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-612672.6727, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2342039.1834, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1322669.2700, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-701025.3944, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-404353.2102, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1355223.6457, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-617639.0291, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-644974.6178, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-752493.7638, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2079007.5706, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-593211.3491, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-582546.1696, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1034943.2219, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1845128.0884, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-603845.5526, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1502348.1400, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-855172.6973, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-743731.0459, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-429782.6097, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-545799.5812, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2275021.9773, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1447783.2598, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-337535.3623, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-605148.9219, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1745826.8485, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-337133.2064, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-568280.5965, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-465377.9131, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1221899.0012, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2486259.9644, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-705582.1609, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-918311.2018, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1003240.0604, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1968269.3979, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-432370.9231, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-706602.9546, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1426908.9024, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-540053.4067, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1141378.8392, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-631820.8982, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1049101.1471, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2208896.3523, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-615662.0276, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-811830.5944, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-515904.3093, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1356053.8419, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-946427.9406, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1518608.7839, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-883794.7613, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2030462.4460, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-390386.8697, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1088030.6833, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-509942.2157, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-966455.4383, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-748351.1751, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-633921.5300, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-561863.9541, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-711459.4330, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-612382.5904, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2670463.2355, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-810041.7595, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1199820.2971, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-936886.2796, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-568214.1653, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1485524.5235, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1253079.5395, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-801832.6550, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-469307.8401, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-619480.7418, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-652541.0034, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2287355.3494, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-729682.1054, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-488400.7648, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-608269.7925, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1487242.9069, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-981491.9514, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1846028.8598, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1132884.2433, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-863922.9876, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1084428.5082, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-850990.0870, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-619447.6403, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1235223.9512, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2661626.9107, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-565301.6132, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-595986.9713, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-524278.3110, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1164733.5448, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-723782.2373, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1598184.3651, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-477363.1468, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-872321.0130, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-506112.4985, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2312848.4051, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-481632.1675, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-612293.1751, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-897270.0688, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-580026.2475, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2365504.3217, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-508728.2030, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1312513.7336, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1186678.6531, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-674725.6468, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-830912.3272, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-769497.4515, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1305180.4738, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-482696.7088, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2431528.4973, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-670615.7911, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-862501.9691, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-784771.2891, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-867313.5177, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-465794.1251, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-753239.5262, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-381127.0745, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-584994.4462, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2172953.2364, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-584576.5766, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2327444.1987, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-966374.1287, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-749150.5195, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2238021.9894, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1992318.9913, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-422834.1563, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-763036.5086, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-512438.2343, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-491186.2570, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-960670.0456, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2003191.0913, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-511560.0087, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1297174.6507, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-975472.4003, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1072604.3348, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-288693.7316, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1028519.2171, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-643907.9712, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-480099.2940, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-589482.9766, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1474217.2913, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-998862.2287, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2591119.3504, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-465051.7847, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-894612.2610, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-695939.1789, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2281026.3592, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-582845.7539, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-883060.5220, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-874727.0508, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-585716.5994, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1342058.0671, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-892212.4002, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-534683.6321, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-712547.5287, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-532591.7358, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2781880.1854, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-467809.0173, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-736167.7566, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-932545.9653, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1439939.5139, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-703307.9468, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-976616.0229, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1959852.8628, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-733946.9684, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1070343.5595, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-584666.7168, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1254580.5364, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-854323.5167, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-700680.4569, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-814995.4593, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-485450.4886, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-868968.8527, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-256590.0699, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3384954.5077, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-613617.3726, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1012231.7641, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-741453.9506, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1258310.3274, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1043438.2892, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1855985.0730, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1553952.6599, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-473028.3597, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-456902.6416, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-753547.7805, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-817167.6097, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2635122.8421, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-330703.7424, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-797573.8054, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-703965.8715, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1164167.9876, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1184621.9552, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-503500.9495, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-880089.5875, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2011602.5264, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1285641.2966, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-625983.0673, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1652201.5911, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-710258.7542, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-657930.3077, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-313584.3893, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-797324.1963, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1561027.2792, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-608262.3813, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-927069.4193, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2036179.5877, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-660548.3677, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-895116.8494, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-650262.8102, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1073413.1538, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2101516.7957, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1551114.1381, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-686071.0726, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-573340.3797, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-546744.8859, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-731559.4333, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-874055.2067, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1749470.8246, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1106241.4384, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-556026.3057, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1948266.0931, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-732546.2700, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-951158.6608, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-427438.8374, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-666653.4293, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-669015.7596, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1351305.5448, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-632358.9289, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1437897.1331, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-390020.4597, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-821029.2469, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2378730.5241, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-456654.9819, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2065731.0711, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-785228.8759, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2270274.0148, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-439594.6304, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-397077.7112, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-378437.6711, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-707930.6626, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1090965.5465, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-530552.3561, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-675348.8479, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-675407.6487, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-993270.4202, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-793575.1053, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1037589.8369, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1310483.4956, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2120664.9510, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-676748.1582, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-472823.9150, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2383338.5920, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-798684.9504, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1585647.0997, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-697727.1357, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-683751.5290, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-838146.9570, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-570206.8471, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1300652.2739, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1352443.8815, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1204361.5567, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-604232.8904, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-368636.3018, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-669581.2685, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2066909.8572, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-716238.2492, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2444936.5818, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-435138.7332, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1217116.6591, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1220282.5594, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-499575.0213, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-796866.9700, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-807353.3530, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-839468.5525, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-423257.3494, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-982443.6743, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-586841.0936, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1452842.1584, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2158280.5613, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1208379.5711, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-485656.1385, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1429377.7398, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-860405.4761, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-640917.1735, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2084109.3282, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-687255.3878, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-758720.4755, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1207703.2361, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-468016.1790, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-728454.8349, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1419349.5637, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2080611.2651, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-568842.0146, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1011451.4280, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-590271.7220, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-888417.3984, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-850047.4731, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-385071.1835, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-546978.1071, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-849575.7097, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1183289.9465, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1323324.0137, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2376495.6923, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-826844.1074, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-645042.2246, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-553123.9930, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-603489.7455, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-450214.7829, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-793304.7841, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-726493.7122, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1509127.4516, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-725133.5848, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2776478.3828, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-698519.1381, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-721390.6382, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-520851.6028, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-932994.7412, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-449295.4573, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3364457.9155, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-704117.4115, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-745836.8144, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1158369.7243, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1022355.7470, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-615334.6614, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-426097.1780, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-699216.7720, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-735136.3036, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2853448.3917, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-628267.0981, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-854516.3684, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-419375.0611, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-600202.0013, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-909690.7597, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2118941.5256, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-559874.5574, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1786211.6291, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-887757.3827, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-486019.7076, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1288154.7083, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2132738.3486, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1382659.4043, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-803245.5843, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-608906.4954, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-635135.1361, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-800950.6558, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-712415.1594, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-705587.1594, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-566181.2298, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-668031.1438, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-580511.6763, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-620275.2209, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1041035.5955, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3240019.4428, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-781562.6848, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1100726.3085, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-718703.1811, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-687460.9469, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2096433.6201, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-643231.1744, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1498396.1090, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-611750.3915, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1376151.2998, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-677166.6146, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-993916.2571, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-591131.0413, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-861310.8344, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-623411.5857, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-607845.0894, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2406207.7293, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-399058.2221, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-315150.3003, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-556173.4767, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-941538.4198, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-813248.0073, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2937936.1660, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1396298.6640, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-776941.8587, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-646410.5013, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-568241.6274, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-646264.3010, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-586041.6229, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1987323.5184, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-603167.9385, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1773071.9138, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1327202.2396, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1265268.6862, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-461909.8759, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-633245.8472, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-605004.3693, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2173119.9038, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-871357.0741, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-573432.6230, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1554617.1531, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-629833.5570, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-905502.7544, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1321291.0592, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-600574.3893, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-737163.1181, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-539981.2171, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1928165.5815, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1474757.2579, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-771339.0488, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2526206.4187, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-405768.6480, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-803940.8897, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-729595.4781, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-763687.1216, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1516951.3669, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-618480.8108, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1317858.0211, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2203480.2225, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-640881.0198, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1038384.5759, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-665123.9504, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-647200.5078, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-687412.4131, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-937004.9332, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1384215.8266, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-959116.8754, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-391007.5072, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-532948.6801, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-820683.2655, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1383440.9063, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2082189.0315, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-585047.8871, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1559836.1736, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2002996.9951, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-871068.7191, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-674844.9200, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1260519.0445, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-786886.9007, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-562830.3700, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-418211.1864, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1527824.8565, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-657945.9156, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-624495.8766, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2162894.5717, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-719395.3654, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-640612.8974, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-730669.0114, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1074873.4970, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2182841.4025, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1708246.2172, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-420473.3769, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-858667.9777, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-601333.4097, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-783799.1817, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-847113.0581, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-736069.5784, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-604897.9670, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-822789.8181, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1960607.7245, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-367267.1733, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-824424.8280, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1146502.4914, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-705220.9396, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1705320.6309, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1625959.1751, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2871548.7861, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-743629.8121, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-781820.9058, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-611229.8040, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-545815.2603, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-500804.9786, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-453508.1350, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-671363.7187, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2725419.5813, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1238259.0148, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1123170.9474, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-591350.0497, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-659879.8373, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-734743.7638, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-393366.6995, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1106152.1142, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-843164.5108, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1431843.6009, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-622116.2884, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-693829.4313, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-731027.7333, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1998015.8214, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-712079.1313, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-574579.5137, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-533852.9989, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2119300.6264, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-451647.5839, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1247348.9144, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-876083.2039, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1300253.2865, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1033253.3836, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2303827.7654, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-573193.4152, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-509275.8670, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-539497.9278, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1356111.2105, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1289589.6210, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1151686.8349, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-413959.9685, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1949862.0796, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-435269.7787, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-526502.4724, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2526489.7931, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-784462.5204, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-658249.5997, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-485394.1046, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-770743.1769, grad_fn=<NegBackward>)\n",
      "VVVV_step\n",
      "loss :  tensor(-8139157.1362, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8139834.9652, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8140516.3177, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8141200.0846, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8141885.2860, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8142571.0918, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8143256.8160, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8143941.8965, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8144625.8707, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8145308.3562, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8145989.0363, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8146667.6496, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8147343.9803, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8148017.8506, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8148689.1126, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8149357.6404, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8150023.3248, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8150686.0696, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8151345.7932, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8152002.4292, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8152655.9286, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8153306.2582, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8153953.3981, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8154597.3384, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8155238.0748, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8155875.6062, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8156509.9327, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8157141.0548, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8157768.9742, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8158393.6934, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8159015.2165, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8159633.5495, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8160248.7002, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8160860.6793, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8161469.4999, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8162075.1779, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8162677.7324, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8163277.1852, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8163873.5604, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8164466.8844, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8165057.1847, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8165644.4901, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8166228.8299, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8166810.2338, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8167388.7312, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8167964.3518, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8168537.1251, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8169107.0806, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8169674.2476, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8170238.6553, grad_fn=<NegBackward>)\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.07913\n",
      " MSE with beta :  0.69458\n",
      "ELBO :  8170238.6553\n",
      "MMMM_step\n",
      "loss :  tensor(-811387.3885, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1010706.0359, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-689196.4580, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-813671.1688, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2765587.0342, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-713727.2047, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-507575.3248, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-857741.7883, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-494237.3101, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1589254.6586, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1053140.7391, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-776583.2667, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-529960.3351, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-649719.2190, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1160198.0958, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1916548.4220, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-693785.6156, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2791143.1626, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-418973.2323, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-724879.4681, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-964737.3519, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1364462.3390, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-733159.9390, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-479266.7652, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-913823.9095, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-619203.9141, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-674051.3332, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1245578.7080, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-752364.2193, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-306952.5564, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1586093.2555, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2071794.4229, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-952204.0333, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-625127.0904, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2369571.7918, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1069290.1086, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-421504.9220, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-417157.8958, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-599928.7180, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1714589.6593, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-605548.4103, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3498364.1596, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-622869.7500, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-450730.7679, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-911118.6239, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-650209.7664, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-761228.0748, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-669580.1743, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-424167.1800, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1719489.2280, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-442225.8100, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-872453.7049, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-578957.3925, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-928467.4426, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-542731.6656, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2660875.8289, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2118694.0471, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-316355.2833, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-629741.4712, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-477936.2557, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-843133.3459, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1466660.1415, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1409035.9025, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-907938.5005, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-640855.3593, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-617723.8063, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1370153.8112, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2689003.0339, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-566223.4972, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-825329.2994, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-401413.3547, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1058157.3212, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2143165.6616, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-992939.1093, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-650450.5281, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-395509.5797, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1304245.0837, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-871581.8643, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-678001.6691, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1133664.1477, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-703439.8266, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-681520.9215, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1472693.6671, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-382345.0019, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-518287.8653, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-830326.9600, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1138095.3679, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2442494.4511, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-485524.7484, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1962587.4861, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-591737.2490, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-438601.6214, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2274793.9821, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-797547.4141, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1028802.4298, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-589948.9782, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-493784.6134, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-693446.7943, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-690474.9728, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-637090.9127, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1154459.8157, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2708291.9163, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1070365.4377, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-721371.6360, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-754129.9569, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-701395.5730, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2242856.0383, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1837970.0347, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-705495.1905, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-467714.4230, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-614499.7756, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-846303.4598, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-472745.4743, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1324946.4844, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-933451.8210, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-532925.9787, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-368715.6529, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2203534.8115, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-623882.9406, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1709857.6135, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-730263.0662, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-811337.7431, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-671066.9017, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-718956.8612, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1128080.4264, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-689980.3618, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-724385.6872, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2695933.2279, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-650956.1168, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-596462.7505, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1415755.2476, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-694208.3792, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-712007.2216, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-638120.6839, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2112859.0875, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1349096.7048, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1411743.4854, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-469190.6558, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2160767.4082, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-922827.5116, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1299952.1241, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-613770.4841, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-613886.2135, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-676251.6109, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-746514.9438, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2103177.7739, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-624802.5403, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-918523.5936, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1119219.9764, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-682365.9861, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-560015.2042, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1415446.4148, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1142377.7271, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-952141.3920, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1037531.4200, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-691682.4252, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-790061.3976, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-714307.7324, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-679626.3497, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2162071.9446, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-777538.5569, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-627275.6595, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1493784.8655, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-506832.7974, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-321973.1375, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2915455.0489, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-658814.7103, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-869090.6231, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1363717.3416, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-571400.1353, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-392029.7834, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2499768.8695, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-990988.2483, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-518890.7502, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-756526.4981, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1076922.0298, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-437084.9025, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-659172.7711, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1112890.3493, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-414270.5261, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-995844.5685, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2780648.0415, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1309668.5964, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-459253.2908, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-943720.9536, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1265767.9944, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-972329.5120, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-389564.7656, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-678925.7035, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1065253.1621, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-774505.7543, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2080194.2274, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1957573.8798, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1624303.5845, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-992144.0219, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-410020.1926, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-627431.9579, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1253249.3278, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-761505.8778, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-544183.8814, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-559072.3108, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-721629.2623, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1392986.0593, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-737303.4219, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-698087.5570, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2501558.4989, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-815918.5171, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-743398.7239, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2639914.0337, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-767369.7826, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-709120.2124, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-370897.6611, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1433339.6029, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-561389.8340, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-731222.5810, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-957601.6933, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1536137.2861, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-634152.4111, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-714252.2792, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-769962.0422, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1077065.5575, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-678424.8579, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2174443.3910, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-585902.4337, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-458285.1256, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-778784.5870, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2168845.1750, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1914310.2116, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-524806.7839, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-485651.7995, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-812728.8819, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1026393.7789, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-457871.5136, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-905972.0413, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-701881.9289, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-691521.3970, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-603939.7548, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2164708.1555, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1612894.9779, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1030487.0333, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1035555.9928, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1844714.7507, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-690897.5321, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-806189.2621, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-785679.1382, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-636256.3704, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-940143.8236, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1430648.5800, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-388931.1667, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-822434.2118, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1113194.7442, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-792064.2660, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2033634.4385, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2043250.9216, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-462893.5145, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-514091.4790, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1063747.4424, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-622808.8039, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-703857.1384, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1278807.5839, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-500165.8634, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2728062.3128, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-654866.2487, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-618022.3561, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1668885.2658, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-861425.0281, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-433282.4406, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2264330.7143, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-584769.4277, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-603832.8384, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-608672.3459, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1145531.0236, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-616734.8876, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-631963.4080, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-651692.6512, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1444850.9236, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1206043.7147, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2264565.0189, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-421447.2279, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-933101.1508, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-905427.3343, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-850684.1689, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-732458.5553, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-519655.1278, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1102758.2858, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2930142.6749, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-555497.0032, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-573725.0537, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1372297.4688, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-529334.7274, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-792426.0797, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-639988.9223, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-623352.2730, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2329121.8708, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-631543.1865, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1252420.6250, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1034583.5044, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2029118.9553, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1239569.0465, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-434091.0935, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-790067.6242, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-506626.9983, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1376441.5650, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-760499.3409, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-932765.4317, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1330252.5225, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-582473.6516, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-629969.2612, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-487231.2265, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2453733.7530, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-753944.0556, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-999090.3339, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-838703.4518, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-873168.2889, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-916194.3621, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1248635.5385, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-572535.8062, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-729918.6750, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2683200.5202, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-308404.4266, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1324137.7305, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1927042.1793, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-907344.4164, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-626980.4270, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-688466.8801, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-658144.3708, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1498735.1737, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-539959.2807, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2089516.6412, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-462987.7706, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-872619.2498, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1105181.7670, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-925738.8641, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-715598.0821, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1485290.1601, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-513810.8760, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-809438.1970, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-446031.4428, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1034957.9817, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2838876.2340, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-761519.6662, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-640834.1435, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1105073.7837, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-532722.1724, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-669415.7454, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2446745.8530, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1069205.8643, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-631493.0408, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-793049.3908, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-606562.8567, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1314252.7656, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-639743.1180, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-753214.9552, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-781006.1669, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-965518.2492, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2131520.2051, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-963033.0198, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-434858.1123, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-680537.2932, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1460168.1055, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-870539.7206, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-862846.7598, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-481834.3472, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-576636.4455, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2912843.2744, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-573412.0929, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1379497.0099, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-512797.8689, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1466109.4582, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2608202.6738, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-890658.9826, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-542483.0593, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-605557.3669, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-847852.1282, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-631139.9653, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-577253.7037, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-344221.4772, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2216575.3495, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-543964.1092, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-669963.6289, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1021290.7794, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1424500.7458, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1140047.1789, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-810613.2491, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-811098.9733, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2680031.9331, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-455493.3065, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-714544.8933, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-882652.2653, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-724211.8004, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1552230.0552, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-350478.2491, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-696670.0222, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1239040.3151, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1417898.2689, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-812726.5204, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-745498.9069, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-499559.6468, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1976376.4187, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-782521.5684, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-991128.0219, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2050546.3895, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1402703.0987, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-625584.2504, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-404235.4038, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-878050.4698, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-987854.8605, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-830304.3327, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1987024.2219, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1238373.9621, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1531745.0300, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-522795.4264, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-580590.6957, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-821110.5590, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-764678.8031, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-723770.2603, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1137778.0181, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-701908.1015, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1114535.7348, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2074968.6140, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1113123.1006, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-589020.1458, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-768511.9339, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-670683.6034, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-603116.5680, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2277039.3826, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-503529.1446, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1239083.9213, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-458875.4784, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1739762.2099, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-297086.9094, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1052299.0757, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-460466.4564, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-742622.2059, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1051805.5286, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2266762.3318, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1431392.0645, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-834395.1499, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-498753.8959, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-883664.8138, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-552265.8616, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-808290.2144, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2147623.4213, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1718478.2053, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-471308.9321, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-431115.9519, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-769933.6680, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1272081.9633, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-834152.8391, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-477073.3791, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1071521.8651, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-611174.7851, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-611598.4897, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2779989.6950, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-778882.9144, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1004751.2192, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-732812.8139, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2231847.4388, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-907900.5176, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-517432.0712, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1312214.0378, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-787709.8756, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-854908.8827, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-825847.3412, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-948091.8616, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-628583.5393, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-358601.1455, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1585881.5895, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-472136.6783, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1245565.1937, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-956180.4798, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1974774.5963, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-607927.2331, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-869879.9105, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1887525.1389, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-637719.9921, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1385305.4900, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-777029.0133, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-792677.1898, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1212991.3642, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1260563.8685, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-688305.1667, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-945592.1210, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-741094.5816, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-836102.0043, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-507547.3731, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2632402.1794, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-558565.3460, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1546697.3187, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-496015.1680, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-597492.8121, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-537429.0479, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-658419.9432, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-562493.4412, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2726685.9507, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1043589.4514, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2201842.3711, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-905435.9105, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-427418.2122, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-506274.5596, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-863119.5903, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1913026.2634, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-628957.5999, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-724123.3214, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-970353.8608, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2035047.8790, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1007756.4731, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1327374.8097, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-848731.8697, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-818756.7952, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-559583.6885, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-601691.6304, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1107322.8785, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2005179.3927, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1079283.6809, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-819614.6298, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-795812.5071, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-791256.1111, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-849669.2724, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-722063.2213, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-636052.9313, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1665678.5151, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-376575.0997, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1321275.1404, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2191241.9714, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-533173.0392, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-929422.6851, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-517427.3090, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-523159.9112, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1298148.2777, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2852433.7488, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-479725.9675, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-769027.9002, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-777760.6274, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-560631.8012, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-909250.3213, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1037706.0779, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1152932.9381, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-541148.3546, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-520711.3216, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-804364.1885, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-892765.3286, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1226951.3913, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1993882.5928, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-697287.9758, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1872760.1310, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-769409.6745, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-870144.3856, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2174415.6865, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-601991.1963, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-355210.5008, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-829179.2546, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-591803.4682, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1171232.5817, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-574319.2354, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-977776.0418, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2724777.9437, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-771632.8358, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-629219.8242, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-730697.9237, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1328309.8119, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-461321.0706, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-623756.5681, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-581928.5634, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1924889.7888, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-979560.6616, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1325465.7629, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-945836.1092, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2274896.3295, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-531089.8501, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-514860.5607, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1478232.0338, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-838210.2367, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-613679.8612, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-911634.9787, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1008374.7495, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1028561.3798, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-329478.7055, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-397567.4943, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-711031.3889, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-781288.6241, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1006202.7580, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-899327.6603, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3013752.6708, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1941424.0985, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-553080.9239, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-872904.9944, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-460777.9697, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-824338.5747, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-520257.8743, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1093058.9448, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1903810.2624, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2976210.2861, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-730041.8530, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-458618.8720, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-814848.9065, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-654927.6032, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-640032.5039, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1257311.2570, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-637027.9060, grad_fn=<NegBackward>)\n",
      "VVVV_step\n",
      "loss :  tensor(-8171816.1698, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8172385.9168, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8172956.2248, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8173526.4922, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8174096.1698, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8174664.7871, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8175231.9578, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8175797.3722, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8176360.7834, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8176921.9953, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8177480.8539, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8178037.2424, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8178591.0769, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8179142.3019, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8179690.8842, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8180236.8067, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8180780.0629, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8181320.6515, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8181858.5739, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8182393.8333, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8182926.4350, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8183456.3872, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8183983.7015, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8184508.3932, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8185030.4805, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8185549.9844, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8186066.9275, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8186581.3337, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8187093.2277, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8187602.6342, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8188109.5779, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8188614.0830, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8189116.1729, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8189615.8707, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8190113.1990, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8190608.1806, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8191100.8383, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8191591.1949, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8192079.2735, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8192565.0968, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8193048.6874, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8193530.0678, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8194009.2605, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8194486.2880, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8194961.1730, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8195433.9380, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8195904.6051, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8196373.1961, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8196839.7318, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8197304.2326, grad_fn=<NegBackward>)\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.07101\n",
      " MSE with beta :  0.66656\n",
      "ELBO :  8197304.23263\n",
      "MMMM_step\n",
      "loss :  tensor(-2550612.0072, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-685099.7878, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-882483.8737, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-892947.8305, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-703179.2887, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1065083.4475, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-254921.0443, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1163064.6924, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1130217.2404, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-534211.9997, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-523791.7226, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-802515.5887, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1070601.7305, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-915910.5956, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2475636.0949, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-742293.9216, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1274740.3228, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1180431.8867, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-970585.7543, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2356960.1126, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-588852.2799, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-460426.6574, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-507385.8446, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-857137.9901, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-667051.3377, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-694740.8098, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-729106.4662, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1220602.8081, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1406715.1811, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-764745.4208, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-489864.3438, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2224229.1893, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1078278.1781, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-572699.5228, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1434805.4830, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-534551.9842, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2212425.9452, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1134056.0326, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-621044.2585, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-609664.7511, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1029175.9591, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-642909.1803, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-547461.6463, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-925118.3648, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1335903.9267, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-683355.9094, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2075916.4539, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-957680.4276, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-514782.5570, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1047206.1538, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-468873.6964, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-817796.2303, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-879118.9799, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2579030.2452, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-635116.2841, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1255438.8703, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1241310.4466, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-723507.0427, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-955602.3210, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-784312.0368, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1034687.6683, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1943113.2446, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-844408.5081, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-670770.1371, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2650386.6430, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-499181.6787, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-918749.3931, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1211024.0968, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-747248.2431, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-778543.8289, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-674817.4099, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-716321.3010, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-468689.1918, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1140802.0162, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-852144.9896, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-978728.9847, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1152533.3830, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-842597.9507, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-420213.6001, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2340287.6006, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-452251.4806, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-417493.8945, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-995537.2532, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1440080.8382, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-583855.9120, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-824874.3494, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2573616.2973, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-908115.0194, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-540045.2451, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-874193.9631, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-977829.4062, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-350688.8728, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-754722.5689, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-489794.4979, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1840986.4566, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2369968.0151, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-629330.3314, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1415753.0707, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-494773.1360, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1257979.9759, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-677848.5409, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-486451.3591, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-967199.0735, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2268038.9710, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-670827.7182, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1012307.7681, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-303674.3865, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-737123.8071, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-866669.8570, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2106310.8210, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1120488.8850, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1379016.0987, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-428769.4687, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-639632.0655, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1017570.5169, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-537355.3386, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-911667.3742, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-858809.0034, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2236473.2599, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1567719.4342, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1846462.3175, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-748910.0110, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-455094.2595, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2250180.3204, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-816824.7560, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-629406.9994, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-544134.1657, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-904603.3109, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-861572.1218, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-671434.2921, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2111059.1533, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1308381.5085, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1788424.5436, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-474690.6883, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-585473.6156, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-396679.3616, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-501960.6489, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-691089.8890, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1067690.1051, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1087052.3930, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2051853.2170, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-641804.5774, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-803861.3016, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1350755.8744, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-599840.9518, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-585788.5198, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-596621.3660, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2938368.2392, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1175637.3142, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-404386.7188, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-737791.1165, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1159083.0247, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-406848.4797, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-903413.6537, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-767617.8786, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2739533.9138, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-738904.1462, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1507239.2941, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-453693.3617, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-679960.2486, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1268665.3286, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-345435.0762, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-911452.4879, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-658875.3344, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-772224.8962, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-553462.7504, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1437492.0883, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2248628.6445, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-425652.2246, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-634090.9670, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1980949.0277, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2176765.8110, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-651820.2984, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-652497.4765, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1085728.7067, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-590215.6652, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-561697.8015, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-921426.9225, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-582598.3297, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1508317.2885, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2781820.6905, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-566540.8316, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-539640.4418, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-735543.2320, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-715921.7271, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1340277.5205, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-759578.1567, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-638690.9308, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1925839.2526, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-654098.9906, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-823921.6747, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1339601.8493, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-648829.1044, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2134602.0598, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-624568.8872, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-881872.5800, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1466766.6604, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-775723.1527, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-691221.3366, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-974714.6655, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1313228.3581, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2784735.0271, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-692246.8970, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-756521.6731, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-580328.7840, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-546622.6575, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-932247.0953, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-591745.8237, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-726492.9042, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1746087.8687, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-988991.7192, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2128114.9247, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-599856.2098, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-573231.2870, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-744549.4596, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-690692.7215, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-965178.4238, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-835191.4089, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-571026.6900, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-726881.4421, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1513569.2120, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2397151.2190, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-470922.7309, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-717203.2374, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-617528.0614, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1007798.4056, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1625819.1772, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-934340.9425, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-339491.7092, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-440432.4650, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-944119.2909, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2288016.3494, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-845743.6368, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-461620.0517, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1383760.4532, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-718583.7664, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1993701.8921, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-728590.5718, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-976871.6672, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1088410.1810, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1150182.7495, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-643191.6220, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2177483.9082, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-765708.7521, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1562362.4936, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-764813.0890, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-466560.2959, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-666603.7026, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-536288.0458, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-526457.8283, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1685411.8375, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-680609.5158, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1157768.6216, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-580737.8574, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2370004.9972, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-658961.0407, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-728666.9315, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-783660.3116, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1432157.0221, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-922209.8524, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-835674.1449, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-607440.3834, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2558666.9559, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-328616.1766, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1931034.3791, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-620020.6843, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2088598.7486, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-607347.5130, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-704756.2239, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-908777.1192, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-594605.8635, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-742059.6948, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-963091.8671, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-843035.1034, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-542286.3575, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1182517.2272, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-685915.7234, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-317920.3134, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1476433.3417, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2184908.8566, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1430385.8234, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-377578.6081, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-900741.2337, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1153748.8669, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-835454.9730, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-712488.7518, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-444401.7950, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2342153.4910, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1073429.7185, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-609430.6997, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1385419.0532, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2656370.8043, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-714685.5857, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-471591.8635, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-747002.1350, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-537766.0714, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1548810.2219, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2164212.6452, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-542561.7320, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1143936.0981, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-603864.9103, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1120081.2612, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-481403.8164, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-593359.6530, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-621338.8890, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-445130.7621, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-711957.1661, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-858289.0537, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-717562.0384, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1915675.7477, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2094340.1749, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-830784.9536, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-617414.5580, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-629976.9937, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-925295.3959, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-785749.0053, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1355375.0593, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2099459.3336, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1202764.4946, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-582519.3985, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-595258.5741, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-878480.4709, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2094426.2441, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-419101.9092, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-528635.1352, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-499604.2400, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-855984.0147, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2324790.8302, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1986729.7367, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-671065.8709, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-906141.9114, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-486359.1251, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-533437.1029, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2168184.7446, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-658346.3347, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-787269.8453, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3029428.1821, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1390979.8474, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-707805.4327, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-645009.3655, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-595383.9470, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-747397.3084, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-664072.2408, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-417639.9950, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-773798.8522, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2798447.8663, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-621360.8382, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-464021.2350, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1049452.5842, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-851161.4626, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-848419.8851, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-791030.8945, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-616075.0510, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-495857.9598, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-696572.0916, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-627680.4863, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-821191.2896, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2055756.5991, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1934567.2515, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-948261.8863, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-809996.2612, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1273195.3839, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-669660.9717, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2556693.4150, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-516482.6245, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-729467.2815, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-532112.1490, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1109288.4115, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-485288.8557, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-438699.8481, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-689053.0100, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2798587.1722, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-778760.0251, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-679163.4138, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1354472.9755, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-973168.2934, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2043902.5129, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1108534.7472, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-681563.5594, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-846273.8202, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-627666.9571, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1236060.7530, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1075104.0692, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-578761.7177, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-697990.1988, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1424360.7208, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-857763.6874, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-395529.3136, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1394542.6341, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-576074.2687, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-865952.0471, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1985774.5588, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-659454.4938, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-869058.5785, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1556763.0312, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-436653.8450, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1715542.2234, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-432951.5858, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-444823.2777, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2081988.7112, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-899784.2598, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1249928.0961, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1002929.2147, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1393786.3385, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1911312.1482, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-583460.9989, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-620384.5857, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-536046.0793, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1897239.7491, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1505476.1312, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-656661.2699, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-745520.2611, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-941595.7075, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1368337.3970, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-390186.9954, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-693402.2884, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2392034.0089, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-637929.5898, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1093096.7631, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1544920.4324, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-395369.2376, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-800604.8937, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-706207.3220, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-627995.0039, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2939147.9410, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-801047.7634, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-661178.0828, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-625496.3745, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1031104.9643, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-723920.3823, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1102748.4353, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-312300.0312, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1230055.3950, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-605899.4350, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-929923.4120, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1349627.3495, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-852498.4948, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2148093.3423, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-446843.3910, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-634406.9340, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-474810.4790, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-681775.9488, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2165536.2633, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-373792.0488, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-667187.2800, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-899853.7192, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-893685.4451, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2039915.4669, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-549638.3626, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1191419.5435, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-694560.5037, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-665231.9331, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1009020.6190, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-890199.3987, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2591894.9440, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-605713.2305, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-509015.3337, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1068848.2559, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-761539.1940, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1191603.8257, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-835629.6851, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-428205.0226, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2109600.9701, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1293086.7804, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-959128.2920, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-440017.1178, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-487067.2682, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-503264.2711, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2757917.4301, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-653566.3560, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1496337.4807, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-900366.0450, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2325790.8663, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-693877.6889, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-832906.3535, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-640774.1424, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-612895.6747, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1638043.0036, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-899625.7226, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-552813.5635, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-626072.7409, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-557831.1136, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-512897.4681, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2024313.0297, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2124687.5237, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-957562.6354, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-652147.8008, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-741772.2406, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-513479.5262, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2300114.7879, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1027100.7090, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-765563.3421, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1905639.5335, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-635136.1635, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-356939.2379, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-693655.6382, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1032561.8237, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2446539.2644, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-606629.5133, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-579770.7928, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-951253.4233, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-739235.6201, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1131062.6726, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-710700.9213, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-638628.3363, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-586894.0165, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1100323.9277, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-715119.1162, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-737104.5939, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1127500.7772, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1948564.8691, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1344119.9532, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1186914.5661, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-687974.6232, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1414270.9443, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2267690.2984, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-607142.7882, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-648094.2285, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-550231.1110, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-834864.1073, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-793911.7309, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-759570.0608, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-418594.1526, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3316204.0983, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-722278.9532, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-605594.6715, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-950712.5469, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-631420.5593, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-396891.6362, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1842060.6412, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1180589.1834, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-541541.0288, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-875257.5532, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-926646.8516, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1186530.9801, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1247572.1340, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-422101.3596, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-590223.1284, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1046413.6283, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1318317.0556, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-733543.1387, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1030044.2670, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2272977.9859, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-781848.3664, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-659672.0495, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-675970.0368, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1075051.9510, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-841103.5840, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-956888.7938, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-826376.4505, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1036571.6995, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2127013.1930, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-772938.2542, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-674812.5113, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-730255.7212, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1420636.1411, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1825293.0369, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-588704.1689, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1395019.0679, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-789919.5111, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1842356.0242, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-758038.2138, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-724439.6902, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-544991.9621, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-744133.1572, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-619432.4421, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-860132.4697, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2104034.6210, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-421058.2939, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1274319.6232, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-852984.5478, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-653483.7317, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2211093.5455, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-699457.6443, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-633285.1390, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1452163.3331, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2201799.3667, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-653855.4040, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1275407.6400, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1412011.7034, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-975642.7435, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-649720.0036, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-567015.3869, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-460382.7464, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-416058.9240, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2344464.0445, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1293712.7028, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-876252.4663, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-731383.2338, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-848633.0932, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-401935.9838, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1285720.8718, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-710017.4969, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1468499.2459, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-354408.7390, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-508028.1567, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-855095.4385, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2976714.8769, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-455552.0506, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-867207.0885, grad_fn=<NegBackward>)\n",
      "VVVV_step\n",
      "loss :  tensor(-8198512.2527, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8198995.1751, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8199481.6442, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8199970.8808, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8200462.1689, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8200954.8697, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8201448.4231, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8201942.3418, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8202436.2010, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8202929.6287, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8203422.2988, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8203913.9256, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8204404.2610, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8204893.0918, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8205380.2356, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8205865.5375, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8206348.8656, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8206830.1072, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8207309.1655, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8207785.9574, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8208260.4121, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8208732.4697, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8209202.0804, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8209669.2035, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8210133.8067, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8210595.8655, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8211055.3625, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8211512.2873, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8211966.6356, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8212418.4088, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8212867.6135, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8213314.2603, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8213758.3629, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8214199.9376, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8214639.0023, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8215075.5764, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8215509.6806, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8215941.3368, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8216370.5682, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8216797.3991, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8217221.8548, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8217643.9609, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8218063.7436, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8218481.2289, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8218896.4428, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8219309.4113, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8219720.1603, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8220128.7154, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8220535.1025, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8220939.3472, grad_fn=<NegBackward>)\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.06254\n",
      " MSE with beta :  0.64117\n",
      "ELBO :  8220939.34718\n",
      "MMMM_step\n",
      "loss :  tensor(-2217219.3464, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-784649.7531, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-588895.9518, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1316075.8414, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-915501.1524, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1032189.7660, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-644455.5662, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-721600.9449, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-391311.1615, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-396410.2456, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-871243.7055, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2294696.5642, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1342032.6491, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1025651.7051, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1394390.8530, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-504829.0140, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1276727.0120, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1911873.7859, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-702578.6971, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-766031.4588, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-800168.1535, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-687708.2889, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-639009.3076, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1436135.3625, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-980615.3110, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-559202.2719, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-592053.1043, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1676489.0270, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-561286.4110, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-681740.9081, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-733304.0154, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2435761.5357, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-618253.3795, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-785176.5169, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-489610.8832, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1741092.4097, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-939307.3346, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-757734.5213, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2150193.0929, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-739272.5001, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-434069.2955, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2126969.7967, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-651325.5997, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1256548.1391, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-554901.2251, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1363419.6053, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1248842.3738, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-584578.9610, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-834178.8790, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1265097.3272, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-698552.2438, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1038288.2801, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1896737.0099, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1173266.6006, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-623345.8578, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-691471.8117, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-522500.7242, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-728123.6511, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-621721.0463, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-603602.3200, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-660603.4537, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-616489.9415, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3642391.6665, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-824812.3206, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-638492.9169, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-665064.7928, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-693144.1092, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1564454.3971, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2259568.4363, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-270510.3341, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-526517.7100, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1603706.8994, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-423864.5119, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-366197.9179, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-653979.5447, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2454578.6272, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-612600.7026, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1528553.4890, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1622816.7545, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-558442.0915, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-654180.3357, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-836218.5155, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-993486.4685, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1526507.3016, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2270901.1338, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-621489.7123, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-695413.8294, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-623086.3033, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2233766.8643, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-682659.7545, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-669551.3703, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-581654.6675, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-742190.4115, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-612599.1169, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-832863.2165, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1865043.7787, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-329625.9720, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-376322.3520, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1741393.4157, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-840898.1745, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2236898.9529, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-890382.6032, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1296118.7561, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-508731.3874, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-585545.8447, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-396073.7672, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-664855.7764, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-663391.0533, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-946948.8257, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1433457.4709, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1314814.0646, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2215359.4566, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1374043.7776, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-531889.5380, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-662514.9271, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1182330.5803, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2031772.5138, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1248158.5688, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-675080.3953, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-514871.6484, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1172046.3551, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-506252.1362, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-768529.0614, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-540860.4669, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2286399.7847, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-735540.4258, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1388450.5025, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-821772.1125, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1868066.1498, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-746519.5425, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-544088.9857, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-398938.7584, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-656720.1911, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-632539.4378, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2585186.1989, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-788175.5509, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-948606.9120, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-690270.4178, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2709893.8092, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-551490.3256, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-854623.6243, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1216638.7627, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-683137.1349, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-566504.9747, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2637106.2400, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1052876.2427, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-635331.8284, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-879877.1560, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-651696.1010, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-710612.1770, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-410980.2664, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1242689.8907, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-795014.3307, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-828458.3916, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-765597.9832, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-704799.2209, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1220857.6430, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2254986.2215, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-548543.9916, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1102744.9944, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2199947.7476, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-955897.9560, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1022652.7666, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1222987.1807, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-699535.7047, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-872230.1922, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-508663.7209, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-739093.6646, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-709435.2634, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2294544.9008, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-642150.5625, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1172711.2093, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-594805.1857, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-865082.7392, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-568419.4900, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1373256.5405, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-687779.3399, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1787197.8634, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-436451.0167, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-582293.3376, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-556918.3421, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-976346.9002, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2208806.4429, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-985216.2331, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1465741.5630, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-972708.4031, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-854855.5600, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1988796.0146, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-542744.4863, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1149868.8666, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-700144.1667, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-544481.5520, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1121869.4329, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1983306.4911, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-699773.6809, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-893986.0651, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-650986.2927, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1111855.7103, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1274207.3862, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-484176.7633, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-518369.3013, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-508846.8466, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2278066.5310, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-479747.4579, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1022415.8608, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-829643.8980, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1307535.5488, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1275466.2404, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-734283.0591, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1986167.5823, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2004691.5323, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-705598.1263, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-583026.6323, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-910096.0600, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-636331.2417, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-659177.3303, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-532067.9739, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2314652.3681, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-903295.0437, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-781456.1083, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1561862.5040, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-656955.1815, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-791913.3646, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-676841.4983, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1290824.2575, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1046612.4550, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1119283.3477, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-464353.8576, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-588070.1335, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-566100.9129, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2233002.3394, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-912758.9579, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-603629.8851, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2488218.8810, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-831062.2829, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-539029.0541, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1342940.7514, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-501367.8569, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1046940.8038, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-867714.2418, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-907401.2060, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1129630.4307, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-627300.2612, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-861066.6309, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-774811.8170, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-866840.9253, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2341944.3279, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-712037.8698, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-932610.0545, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2029590.1388, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1717351.0093, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-706810.6203, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-461278.2692, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-809326.0305, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-560022.7222, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1004298.1201, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1760945.2914, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-398686.9294, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-761195.9770, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-655732.0107, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-679347.1388, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-493860.8635, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-546264.5617, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2924799.9607, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1407109.1653, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2168204.4403, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-553340.5111, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-627116.9592, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-538573.7712, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-672853.4979, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-560660.6433, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1693577.5607, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-630370.3883, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-447998.7153, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-961380.8781, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-611734.1365, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1988448.0720, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1667238.9356, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1319994.1377, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-593499.9733, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-851807.2103, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1819263.4468, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-579245.3555, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-386304.4733, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2157769.9096, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-648647.9637, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-914163.6315, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-863018.7682, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1297047.4621, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-997883.6851, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1478035.6554, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-452711.3751, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2170205.0217, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-511867.1689, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-783927.4606, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-529281.7889, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-715432.0542, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1014194.5519, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-488280.6653, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-639870.1965, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-695060.1060, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2974531.9807, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-725915.4648, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-966995.2477, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-978059.2755, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-537304.1262, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2479183.4985, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1453747.8496, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-684691.2923, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-850938.5474, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-611166.0703, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-625866.0596, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-508896.3722, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2122515.6026, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2106206.6602, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-813003.4793, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-523021.5268, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-355064.2370, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1034498.6725, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-757448.4303, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1242379.7656, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2357156.1805, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-503021.4624, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-796949.0664, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-641044.8616, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-822932.3440, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1320582.5018, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-537182.9947, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-459964.2913, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1383801.9698, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-946089.4579, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-589648.0893, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1273824.3842, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2003497.7850, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-908850.8498, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-655651.7864, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1020191.4170, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1397213.7255, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-863124.0584, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-429621.2125, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2108355.6432, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-460765.1370, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-738909.7960, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1202424.0556, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-547827.2297, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-787589.0953, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-544575.4204, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-908313.2007, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-654342.4689, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1292965.7429, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-741335.9712, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2743140.2234, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-615716.5361, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-817113.5326, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2780349.2817, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-518533.5373, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-831122.4783, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1397297.2476, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-915812.9946, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-345514.1328, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-736078.2347, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-451281.9769, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-902350.8321, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2384384.2433, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1678300.2549, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-525611.7877, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1194164.2489, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-349095.8220, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2217785.0388, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1591375.9705, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1164866.1097, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-756136.3215, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-650476.6997, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-519233.7610, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-601628.7369, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-718646.0923, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1108407.0661, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2511280.6982, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-429958.9886, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-601344.2451, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1092678.7598, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1402681.7388, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-491315.7657, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-583368.3329, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1181109.5127, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-446928.1362, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-644173.6161, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-536138.5689, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2227632.4574, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1346522.6197, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1008663.7437, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-829785.6862, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-806246.7504, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2927320.7140, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-680261.1447, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-553635.7623, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1059224.2603, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1086615.7010, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-649553.5587, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-458472.8100, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-539130.4140, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-689525.9322, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-922057.9854, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-524960.5407, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1162081.7406, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2159346.7206, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1420384.1115, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-802059.6650, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-780645.0178, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2110187.2267, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1099187.3546, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-361940.6154, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-928294.6229, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1537113.3922, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-839098.8041, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-564284.0967, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1052999.6064, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-801890.0533, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-581353.6759, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1987359.9724, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1043716.1387, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-868485.1439, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-558932.9653, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1325477.8831, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-327661.4433, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-539912.9818, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1383564.8303, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2166640.3604, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-690253.7714, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1458364.7245, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-681792.4232, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-973100.1552, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-601704.5072, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-624316.7318, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-536139.9999, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1451069.6159, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1441211.8566, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2190460.9074, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-787289.5174, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-588330.1235, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1052441.0373, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-841242.8057, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-661345.0165, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1675072.1400, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-709612.5713, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-597329.4017, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2059925.0912, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-624533.8149, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2627503.0394, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-477387.7546, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-657598.9383, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1089563.9743, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-469675.2063, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1037111.6018, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1113539.6337, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-748594.3738, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-719642.4967, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-608459.5501, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2282336.8536, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-688444.2732, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-390276.4807, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1131575.7025, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-769559.4758, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1630476.6465, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2212087.2059, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-518183.9301, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-640934.0343, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-366123.3006, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1248928.4265, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1539934.3060, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-931573.9171, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-762987.8253, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1345051.6410, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-458660.8224, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2934258.5164, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-850462.0207, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-501282.9262, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-762293.9864, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-668715.0558, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-700745.2804, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1244740.9594, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1285632.2661, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-530632.2819, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2477523.6819, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-261382.2944, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-585313.3676, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-766146.4972, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1069954.4784, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-785632.8233, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-625059.2094, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1333495.2480, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1421715.6375, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-871821.8205, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-325571.6626, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2342368.8312, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-515477.8014, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2013794.4168, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-887854.5387, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1206405.1083, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-683393.2285, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-684274.3502, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-914247.0216, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-770612.9815, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1059853.2793, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1895479.5501, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-731531.9039, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1140976.4745, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1301082.8785, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-680302.4338, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1365148.9933, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-732828.0966, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-374082.9683, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2681775.9353, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-724154.9979, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1509712.9613, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-618862.2274, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-606555.5267, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-981784.9312, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-447345.1041, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-651072.5577, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1036780.4042, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-440517.3373, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-836408.7484, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1153462.6618, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-746754.9591, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-296695.9812, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2263313.6930, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1446740.6753, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1305140.4098, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-693680.7853, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-964499.6486, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-681987.5358, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1068225.3215, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-719504.6986, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2196576.8246, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-591382.9419, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-652575.3200, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1280776.0754, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1942034.0459, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1530570.3278, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-409278.1658, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-707700.9593, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-802468.9303, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-895159.6886, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1289238.0817, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-519676.3356, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-607785.6935, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2062920.2435, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-676027.9652, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-457609.6486, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-640048.8661, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1967868.6535, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1411712.7804, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2025996.1245, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-846975.1662, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-559784.9443, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1114147.9725, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-843714.2383, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-676243.4949, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-742422.9960, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-688553.1295, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-407008.2077, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2188309.7453, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-357028.8758, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2134285.4439, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-869655.6065, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-609447.6825, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-966836.4194, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-843934.3464, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-823061.9887, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2142375.6255, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-549945.7863, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-505425.4996, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1304056.6662, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1365939.4032, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-686787.9455, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1102151.4500, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-946778.1143, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-845556.4399, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-657699.1149, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-720269.3273, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-740437.9306, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2287357.2337, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-920681.7479, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1005137.7219, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-953330.5351, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-830745.9905, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-409081.6095, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-632304.8757, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-670432.6039, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3181492.2234, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-538853.7499, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1103262.3695, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1063808.1449, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-747451.4501, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-878409.2797, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-844255.9948, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2120606.4434, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-614285.7027, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-849423.1489, grad_fn=<NegBackward>)\n",
      "VVVV_step\n",
      "loss :  tensor(-8221864.3495, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8222266.0169, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8222668.2493, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8223070.5960, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8223472.6367, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8223873.9995, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8224274.3667, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8224673.4739, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8225071.1039, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8225467.0802, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8225861.2617, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8226253.5384, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8226643.8291, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8227032.0780, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8227418.2532, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8227802.3426, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8228184.3512, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8228564.2965, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8228942.2047, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8229318.1075, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8229692.0393, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8230064.0354, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8230434.1309, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8230802.3592, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8231168.7516, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8231533.3365, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8231896.1390, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8232257.1814, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8232616.4831, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8232974.0614, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8233329.9323, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8233684.1111, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8234036.6125, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8234387.4514, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8234736.6423, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8235084.1999, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8235430.1386, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8235774.4728, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8236117.2171, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8236458.3864, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8236797.9961, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8237136.0623, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8237472.6014, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8237807.6305, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8238141.1665, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8238473.2266, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8238803.8276, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8239132.9861, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8239460.7181, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8239787.0394, grad_fn=<NegBackward>)\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.05452\n",
      " MSE with beta :  0.6176\n",
      "ELBO :  8239787.0394\n",
      "MMMM_step\n",
      "loss :  tensor(-474989.8382, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-430500.5172, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-806722.3061, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-951649.3194, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-932324.4095, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3033821.7731, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-920921.7798, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-688821.0351, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1041505.8469, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-485043.3398, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2273282.3462, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-748632.0550, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-964736.3733, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-657829.4627, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-586149.5702, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1481924.6050, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-697327.3358, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-875214.1834, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2024473.0942, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-493264.7381, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-535860.5309, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-655832.0960, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1665935.3716, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1292091.5045, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2325706.7863, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1361043.2978, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-673903.2995, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-399220.4989, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-849860.7761, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-568084.6607, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1078116.7296, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-983892.3526, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-447540.7050, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-757306.3112, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-628104.4803, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-821324.5909, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2833676.2597, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-815497.7985, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1260296.0866, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-676281.2056, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-492013.3968, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-768452.0044, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1537932.8684, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-587105.8195, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1309575.9944, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-587918.0768, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1070677.8752, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1886331.5128, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-362391.4180, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-684938.2260, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1150579.3365, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-740300.1523, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-592547.1732, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2676152.9452, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-551229.3605, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1481865.3939, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-716701.8787, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1148880.2676, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-681909.0309, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-804981.8253, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-843732.3178, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2006748.5230, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1051281.2895, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-985856.6812, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-950533.5635, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-502527.0275, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1185650.1732, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-816270.9632, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-860233.7891, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-584767.0503, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1263342.7541, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2076280.7757, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-598714.4308, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-771341.5080, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-759701.8149, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1324406.1660, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-395560.1594, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-699079.7059, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2959319.9129, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-731785.4881, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-427413.0851, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-649448.8591, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3038904.0261, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1366091.3996, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-594634.3211, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-834340.5302, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-597227.7209, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-730811.3253, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1947490.8012, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1063054.7254, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-631608.1965, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1015590.8107, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-569485.4703, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1765150.9521, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-664994.0955, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-582604.2077, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-965527.4651, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-506932.8578, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-762912.1981, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2037195.1661, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-484297.3871, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1301267.6915, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-720091.2359, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1461466.5790, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1343600.6574, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1947314.7903, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-790422.6266, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1254077.8087, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-849387.2218, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-980607.6077, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-575949.5954, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-497829.6342, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-792729.5976, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-956009.2292, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-337703.0784, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-765361.9108, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2027631.5659, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1716432.0016, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1057237.3693, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-586950.7474, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1201954.2788, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-537068.2026, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1766254.9115, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-556471.1698, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-851778.9371, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-533380.1686, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2081415.7033, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-712079.3950, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1047099.7736, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1165551.4940, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-672211.5349, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2259680.8430, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-588067.8373, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-539954.7310, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-697844.5365, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1269785.0788, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-497620.1624, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-660459.3783, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1290625.9860, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-600584.3114, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2527362.2872, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-707243.6307, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1313975.9553, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-642119.0501, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-272416.2364, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-797074.1237, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-538546.1138, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-990003.4535, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1295722.3650, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2209099.4457, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-635903.4092, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1501226.4099, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1444703.5859, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-428037.3717, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2193182.4915, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-699802.3475, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1252896.0623, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-496856.2396, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1010431.3303, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-714046.7039, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-353865.9427, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-637340.9326, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-552188.9364, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2263420.6748, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1246695.8839, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-631752.9323, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-688125.9206, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1866345.2906, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-535466.9367, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-825040.2252, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2156465.1889, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-899819.4093, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-515496.9581, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-880869.7742, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1882196.5037, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-544809.8535, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2221313.7689, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-596062.7545, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-696875.3945, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-862499.4412, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-915128.0825, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1535285.0015, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-853704.4111, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-559501.0813, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2227742.6459, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1290357.3488, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-588955.5921, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1305311.8973, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-741736.8743, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-853672.1156, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-485503.1037, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-746240.5566, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-407563.7310, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1203910.6891, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-830202.2168, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2922068.8616, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-266639.3377, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-999707.3887, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-733850.0796, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-876148.9384, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-535481.6382, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1162103.8760, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-591748.9033, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-397176.1207, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-602237.9656, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2312633.7506, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1383959.2850, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1253841.7981, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-599233.0430, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-665609.5882, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-925071.6151, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1152841.4282, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-829598.9043, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-589167.3653, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-594968.8746, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2883906.1281, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-765930.7393, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-851621.2069, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-890493.9778, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1363916.8050, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1344153.0053, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-456105.6091, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2141861.1394, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-426272.2987, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-696200.4173, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1527773.6255, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-542914.8562, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1474695.2260, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-840408.8571, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-470022.3440, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-582370.0907, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2106065.6396, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2637498.1859, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-677356.5269, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-809395.5256, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-345371.7833, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1077251.6230, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1111038.8613, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-942247.1118, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-639659.2615, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-532064.6551, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-851301.3475, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-961894.4935, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1041171.3157, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1774550.1304, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-447676.1379, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1945824.4000, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-685649.1226, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-726845.1216, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-822127.3255, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-749907.7117, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2117743.4303, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1204900.8577, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-895802.1013, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-734168.6073, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-988729.2446, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1157340.6825, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1714763.5572, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1008540.2476, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-847232.6273, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-473771.1069, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1948991.9271, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-482815.8611, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-606388.9442, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-553912.3167, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2771558.9559, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-437568.8100, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-521582.1529, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-443148.5106, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-679538.6212, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2010057.8416, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-822486.8731, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-786629.1093, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-661560.6656, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2315210.5412, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-501645.6694, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1245641.7282, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-441295.8336, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-455741.9105, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1832729.8162, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-790420.3107, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-551870.7180, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1364062.6556, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-406277.8250, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1062073.5241, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2442146.0726, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1038457.1252, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-584817.4722, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-725813.0259, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1433829.7418, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-591797.6285, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-576081.9429, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2229354.3619, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-855293.5959, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-718984.9080, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1107931.9875, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2304577.8900, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-350484.9112, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-684812.2062, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-421221.9102, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-832612.9960, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-810607.7832, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1034388.2547, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1800992.6642, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-839960.6919, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1095031.6144, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2445834.7921, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-516434.7647, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1572272.8345, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-787704.9418, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-408030.4405, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-574778.2360, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-724531.2479, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-595005.9396, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2693696.1160, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-712127.2251, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-953480.4873, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1237153.5261, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-586731.6648, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-736656.9845, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-488027.6940, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-816088.7638, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-618989.0069, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1203738.3987, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1255684.8009, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-911755.7249, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-562346.2923, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2382305.2818, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2786181.1367, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-645096.3433, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-732618.7044, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-498520.5537, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-719849.3949, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1035459.9203, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1092459.2730, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-729370.9979, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1251270.1726, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2161935.4668, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-642666.8528, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-744866.1962, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1053292.3444, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-730394.6440, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-609953.6862, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1045243.8038, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-655873.5169, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-641267.7122, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-796077.0975, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2179778.7349, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-865502.5955, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-414900.8612, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1218449.2427, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1467978.7652, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1275288.9388, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-838263.5170, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-557650.0468, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1434468.3980, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-679979.3823, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-864925.2014, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-598744.8121, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1990938.4602, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-657620.0156, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-402033.3560, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-640044.7121, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-989946.9307, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-746836.7338, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2186537.4839, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1161396.9645, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1454514.2804, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-493536.9461, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-746552.8427, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1218743.4621, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-882611.7574, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2233564.4199, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-922394.1928, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-484692.2703, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1257674.9764, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-758591.3956, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1226076.7934, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-669832.2173, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2098665.3276, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1456341.3233, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-599017.4644, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-718971.0346, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-712305.5537, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-561667.5218, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1676398.1600, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-837636.4116, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2329332.1824, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-818077.6258, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-993203.8329, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-480035.5363, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-543723.3185, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-438388.5183, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1037218.9684, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-606465.4348, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1388392.7351, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-646281.3034, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2319658.5571, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1069097.1312, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-733628.4440, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-582552.1443, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-672282.4739, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-392255.5866, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-955497.4392, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2319350.1088, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1411629.1195, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-537807.7433, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1368559.5757, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-674992.9434, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1547653.0764, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-513418.8176, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1178062.8846, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-767955.7787, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-695749.4584, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-485557.5553, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2376468.8277, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-991052.4494, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-676092.8490, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-428244.2285, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1428123.1084, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-757441.8224, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2679692.6572, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-552143.4621, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-727747.3072, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-561905.6881, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-937577.8803, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1027106.8307, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-973451.2511, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1202435.5779, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-728888.0328, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-633269.1760, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2175560.8081, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-569947.7212, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-898751.5612, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1508908.7814, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-742626.1782, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-775389.3501, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-621234.6770, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1005176.5402, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2117892.6022, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-935827.6540, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1153149.1645, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2003078.9261, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-610641.0567, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-510884.4808, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1433961.0596, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-834734.5949, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-758006.8398, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-831216.5837, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-563575.8974, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1112618.4956, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1448907.2773, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2386254.4802, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-654119.2294, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-626652.0471, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-616666.8352, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1369270.3973, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-697102.9677, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2766894.3588, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-636661.0528, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-754926.1111, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-615887.0375, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-702106.9224, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-697125.7529, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-907482.9252, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1249384.4039, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-704915.4424, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-529907.1297, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-878455.7943, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2164657.0886, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-833981.3518, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-971503.7259, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1089917.7869, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-946416.7350, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1256746.9044, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-500093.8779, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1114911.4291, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-789738.4429, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1973413.4383, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-569067.3924, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-553800.8719, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-652096.0710, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-728881.6282, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-708169.2053, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-676767.1449, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1503971.8363, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1173802.4179, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2242697.4124, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-658244.5303, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-689488.4157, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1300769.2622, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1426374.1308, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1841351.3115, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1215463.3989, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-685181.3855, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-423503.2602, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-570862.3262, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1636609.5197, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1080302.4232, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-553341.6109, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-648060.2002, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-804777.7837, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2272646.5576, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-673904.8739, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-824861.6984, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1351406.1763, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-830411.8836, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-697878.0899, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-636024.5524, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-766824.5621, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-949262.9115, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2183573.5060, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-738559.3462, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-611142.7908, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-867502.6141, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2078371.1503, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-975914.6968, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-550308.1527, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1134537.2969, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1283955.8404, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2210101.5782, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-898254.3011, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-646286.5025, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1019967.0516, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-642150.2451, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-601616.8986, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-856646.7992, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1365350.2975, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-836682.5093, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-459481.6114, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2310599.1345, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-866698.7737, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1254997.1098, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1182933.2295, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-659273.7281, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-669536.4364, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1109431.2403, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-405651.9791, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1476205.0846, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-733472.1108, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-981188.3786, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-636639.7067, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-719476.2195, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2177846.3534, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-942729.0012, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2151837.7241, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-593085.1347, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-582600.4673, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-607305.5004, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-710029.3332, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1293617.1945, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1358454.0168, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-425797.7925, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2034275.7177, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-718085.2644, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1583561.2512, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-753781.6455, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-898897.8212, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1213791.1833, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-611249.3996, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-792969.3280, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-590789.0947, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-629884.9796, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2572330.1560, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-477194.2528, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-634486.7957, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1033717.0959, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1508651.7382, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-579776.9653, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-823183.3247, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1447590.2966, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-523347.0357, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-665968.9174, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2230075.4928, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-576271.3977, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1393992.1600, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-552277.2856, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-950127.9331, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1189641.9582, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1340752.1514, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2551204.7302, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-765177.1696, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-512523.1322, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-378528.5231, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-775134.0580, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-768962.6519, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1161897.9345, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-644421.8055, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-676900.8002, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1091319.3476, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-614494.2914, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2506837.9245, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2530386.3455, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-967758.9103, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-377625.5798, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-896664.2462, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-446693.5940, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1018675.9602, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1276462.9478, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-725743.0052, grad_fn=<NegBackward>)\n",
      "VVVV_step\n",
      "loss :  tensor(-8241019.6495, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8241353.3841, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8241687.9205, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8242022.9284, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8242358.1010, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8242693.1644, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8243027.8804, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8243362.0444, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8243695.4813, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8244028.0412, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8244359.5956, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8244690.0339, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8245019.2620, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8245347.2004, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8245673.7835, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8245998.9588, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8246322.6857, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8246644.9338, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8246965.6812, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8247284.9120, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8247602.6155, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8247918.7846, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8248233.4159, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8248546.5090, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8248858.0665, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8249168.0931, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8249476.5953, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8249783.5806, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8250089.0574, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8250393.0349, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8250695.5229, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8250996.5318, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8251296.0731, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8251594.1593, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8251890.8037, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8252186.0206, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8252479.8249, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8252772.2315, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8253063.2556, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8253352.9119, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8253641.2151, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8253928.1794, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8254213.8191, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8254498.1482, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8254781.1806, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8255062.9303, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8255343.4109, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8255622.6359, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8255900.6187, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8256177.3720, grad_fn=<NegBackward>)\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.04735\n",
      " MSE with beta :  0.59453\n",
      "ELBO :  8256177.37199\n",
      "MMMM_step\n",
      "loss :  tensor(-809095.2334, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-678763.2113, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-753757.6317, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1046375.8827, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-345954.8728, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-566169.0894, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-663733.9208, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3392014.9742, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-889213.1149, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-923570.6387, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-350510.2795, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-883010.0275, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-640284.5273, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-710575.1977, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1720868.6416, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2137823.2129, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-425000.6570, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-490806.7996, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1517471.7480, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2664543.2507, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-745932.7020, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-757782.6190, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1145647.6135, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-508725.5789, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-846636.5295, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-469753.6856, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1154275.8406, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1051293.2577, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-680068.6541, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-975675.4876, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1928692.4687, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1149710.1589, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-401965.4425, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-591526.9426, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-978167.5216, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1276796.8728, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2391301.8715, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-803767.6409, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-530042.8669, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1281905.2931, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1618063.5078, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-904747.5805, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-713102.9522, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1078741.4488, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-654724.1988, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-555363.5367, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-735772.1010, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1994863.8003, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1037235.2616, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1562036.8153, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-715414.3928, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2254412.0926, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-762581.5943, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-617687.4965, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-556878.7167, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-749959.5058, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1896573.1297, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-642006.0758, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-742436.7026, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-750764.6106, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-589651.7418, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-688999.9486, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2018099.4187, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-927750.8043, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-474000.2445, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2308761.6757, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-745861.4312, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-730645.5773, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-701241.6727, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-438929.4647, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2044129.5243, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-812048.0342, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2704197.1136, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-856748.1074, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-591744.8300, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-827635.3283, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-809781.5634, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-487112.0415, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1239749.0108, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-739095.9803, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1470239.5697, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-837042.5015, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-783400.9554, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-646541.8984, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1341468.5328, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-636335.2011, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-596119.9046, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1945184.2924, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1449329.8846, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2484972.7197, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-575751.4924, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-459264.9035, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-743362.3435, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-413171.5073, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1449661.7073, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-680115.4757, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-813913.8462, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-817791.6755, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1894142.0210, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-348418.0375, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1777927.5072, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1441315.1584, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-781546.3754, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-380044.3770, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1621810.1327, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-578120.8551, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-934135.6679, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2360835.1084, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-640854.7750, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-690138.8012, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-740665.7915, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-688863.8865, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-660990.6103, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2220944.4232, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-670860.4224, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-691472.1323, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1033849.3282, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-414105.7651, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1136665.9622, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1427232.8527, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-449278.8564, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3025563.3570, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-759782.4807, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-753406.0153, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-477783.9871, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1555642.8484, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-835120.7064, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-399719.4538, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-613273.7775, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-808855.7632, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-691814.9675, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-670810.3137, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1116536.5443, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2264622.9546, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1395285.7267, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-694036.6636, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1437846.8741, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-863844.9425, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-636179.0443, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-489336.0932, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-599239.4195, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-642277.5386, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-754396.9458, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2832813.4947, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-387761.9111, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-650054.8157, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-795745.0766, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1663384.6176, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1218484.6974, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-756123.0192, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-488712.9167, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2295718.9342, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-802066.8530, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-470933.3570, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2215099.8088, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-640661.1669, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1601498.5791, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-510990.4666, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-565878.1745, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1449009.0676, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-606131.4671, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-744043.5658, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-455041.0982, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1159030.1960, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-847977.5298, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2359484.4011, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1417777.9189, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-666672.7174, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1923683.6219, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-470999.1590, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-524109.1035, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-724171.0190, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1498989.2108, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-851935.5338, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-860783.6808, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1401728.2015, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-412438.8900, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-328811.6248, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2918734.0123, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-804119.7333, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1471690.1061, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-772260.3033, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-740927.9159, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-806759.0871, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-991554.2075, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-594705.8353, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-650031.2649, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-288335.0031, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2453057.0925, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1071316.6812, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-791932.2424, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1415391.7448, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-613673.7540, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-432770.9013, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2315674.2574, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-553297.1744, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1542854.3206, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-659254.7701, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1379200.1833, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-759313.9264, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-797074.2419, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2392218.4835, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-419268.8728, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2028519.4636, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-733141.3081, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-657139.1260, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-917491.8340, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-311277.7510, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-538015.2023, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-378481.6896, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1387992.6136, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-837946.1633, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-708626.1442, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-629210.8042, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1464970.4147, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2310585.3252, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-907294.7203, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-560399.1032, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2518786.0751, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-517734.4518, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-596434.5574, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-812966.6149, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-980306.7313, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1362320.8112, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-842398.2952, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-529798.4467, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1351851.6677, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1220841.8039, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2054655.0088, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-502641.6343, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-963865.8489, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-790569.8538, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-805030.5141, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1306114.6978, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-493726.1748, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1200349.8278, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-799967.7760, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2436961.7821, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-870721.6032, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-343238.2390, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1387655.2772, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-878944.9833, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-417708.4066, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-676103.5377, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1128693.9906, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-652726.1504, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-702974.0614, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2411219.1864, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-660072.2681, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2050670.6341, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1055747.1267, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1284049.3154, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1113957.5687, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-637161.7101, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-977723.5259, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-476853.1521, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-743405.3054, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2039457.5808, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-611727.2762, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-985681.6282, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1289633.1903, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1162684.7060, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-684390.0365, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-739131.8992, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-773718.2323, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1799110.1567, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1097227.2789, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-341856.7433, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2205850.5401, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-672977.4388, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-920325.5995, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-445079.2683, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-541499.9642, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2015039.6871, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-808308.6113, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1370193.3786, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-587172.5893, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1116934.4056, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-681137.0913, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1136018.8943, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-444145.1629, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1218053.9471, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-673359.9425, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-484302.1886, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2169051.7029, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1615169.3893, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-747497.1531, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-904658.4611, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-738154.2449, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-595183.4484, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-521277.8329, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1209654.5443, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1005081.0704, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2740995.2019, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-885335.6841, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-560364.6890, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1078375.2751, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-645559.7945, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-452599.7023, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1940680.9544, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1225431.7263, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1259379.3731, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-829636.6444, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-824311.7046, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-722081.8898, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-653323.9405, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2327100.3195, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1148329.1520, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1559455.8762, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-556124.1524, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-715647.5365, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-574086.6195, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-947188.8768, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-619151.6905, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-574384.6503, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-656086.3656, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-915053.7186, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2875092.3853, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-826600.3002, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-842649.8769, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-664475.8406, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1210542.1641, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-800252.3152, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-616107.9878, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-425171.3732, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2092275.2751, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1558267.9183, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-887881.0277, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1471965.9414, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-594598.3511, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-600528.2749, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1267660.0589, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-911369.6560, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-705263.0312, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1897594.2474, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-806959.3498, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-839221.2627, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-567665.8775, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-647166.2628, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-787642.2737, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-712445.9935, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-556189.3832, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3378248.8598, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-767377.7707, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-766864.0553, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-704194.0188, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1251261.0223, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-655941.5635, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2169700.5125, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-661261.2368, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-677996.9873, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1368448.8739, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-834418.9476, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-833228.7492, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-428792.1982, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2196480.1808, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-337965.0999, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1290638.8361, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-824904.9832, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1509324.8658, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1195565.3416, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1051837.9789, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-558173.7399, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-511302.4446, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2722612.9278, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-721334.7753, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-758106.0617, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-737317.1377, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-710194.7032, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-620566.3920, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-941868.9929, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-319763.8011, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1241050.5648, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-689312.4390, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-960451.5721, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2772261.7750, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-713224.1911, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-684610.1413, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1586385.7640, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-630285.7259, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2143949.1459, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-720042.5213, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-652976.5886, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1124801.3351, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-663251.3473, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2581409.6037, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-807157.1091, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-775939.4526, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1565845.4187, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-464586.3730, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-526656.8106, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-871143.8403, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1982479.9896, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-618709.7056, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1493453.2006, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-706777.7186, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-541195.6747, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1246449.8141, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-572250.1231, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1094668.1457, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-383807.8741, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2614529.7492, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-732688.4607, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1324314.6914, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-881365.9035, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-529749.0790, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-606232.3740, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1182947.1970, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-809461.4903, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-839525.0748, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1107349.4715, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-768834.3614, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-588845.0591, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-521465.5738, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-750219.2718, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2870541.4716, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-878957.1838, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1463898.3657, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1225461.5633, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-665462.6158, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1954217.9165, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-375225.5508, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1220281.8672, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-472536.1369, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-681467.6585, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-622424.9855, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-750645.9632, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2931407.1318, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-815860.0766, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-582534.6384, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1197240.9709, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-674676.9318, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1345860.9331, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1697294.7926, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1900598.3103, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-694411.4198, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-696326.5061, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-541317.1875, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-557103.5886, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-823372.1780, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-644682.6015, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2090056.2556, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1063996.1929, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-921784.0827, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-728574.5229, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-920783.0563, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1190542.5724, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-694764.6149, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1109792.7853, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-506690.7008, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1197285.5873, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-413397.8028, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-671493.5907, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-875632.9495, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2290480.3514, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1191359.2232, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1533882.5929, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-717952.2244, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-598341.0966, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2169394.8707, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-931153.0091, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-709200.7567, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-455023.6081, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1141170.5373, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-728723.8648, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1050552.6868, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-797005.1704, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-773358.8463, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-903529.5280, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-621196.0968, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-718237.5476, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2663649.6667, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-284514.3281, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-738567.5806, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-570557.9600, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1738064.5156, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-760464.8291, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-544822.2256, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3068444.5775, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-550356.1084, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-725190.8868, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-548258.9893, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1735066.0372, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2038173.9721, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-987247.2340, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-779674.9953, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1005973.1690, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-435807.9265, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-563891.2952, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-969972.7361, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1223852.3638, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1013694.7558, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-630765.1252, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1070562.2172, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-721835.7067, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2060380.2490, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2375840.2564, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1647179.4913, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-565425.6199, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-759610.6517, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-563952.4982, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-717684.1910, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-765259.0369, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-860868.7438, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-734813.9222, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-900259.4379, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-700476.4454, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2187354.6571, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-437215.5925, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1137310.2400, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1416694.9252, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-740396.4797, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-992126.7452, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-492560.2589, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-455767.6523, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1088698.6909, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2713345.5995, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1057338.4306, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-953685.7818, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-501508.5447, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-683573.9930, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1509045.8742, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-727249.8013, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1090022.7918, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-645318.7870, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-556286.9905, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1091190.0313, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1953035.2224, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-580152.8024, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1241221.2877, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1124860.5388, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2767875.9106, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-398311.1446, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-472383.5607, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-714785.8102, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-956628.4023, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-630639.0769, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1020543.4576, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1118436.8280, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-630082.8482, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1420689.2933, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-773130.5814, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-608373.0893, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2054555.0766, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-625811.7579, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-739333.5896, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2129229.1323, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-721433.3273, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1203285.4041, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-616558.4228, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-854446.4358, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1366054.9848, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-706971.9279, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-427184.2738, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-522129.2033, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1099022.5834, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1048061.7605, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-701906.5619, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3068051.5842, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-682240.3116, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-662433.8026, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3371741.1531, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-864715.6252, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-505075.1835, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-749328.5770, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-790465.4692, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-947240.5016, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-365372.6907, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-786226.6989, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2082940.7748, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-592066.2937, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1010193.4090, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1065100.8282, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1330622.4014, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-903239.1703, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-485314.1660, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-533286.1523, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2107619.6070, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1847146.5944, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-653745.7055, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-766796.8854, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-858816.1700, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1058509.9429, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-430152.4843, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-871361.6004, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-774472.4493, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-514733.2697, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-700584.5884, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-707176.1296, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2784962.7868, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1235055.4040, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-668035.3167, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-745695.5734, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-826162.0064, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1372919.8754, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1208297.5872, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-863236.5774, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-604389.5161, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-751255.2899, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1884245.3912, grad_fn=<NegBackward>)\n",
      "VVVV_step\n",
      "loss :  tensor(-8256994.9926, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8257283.3764, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8257572.9169, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8257863.2572, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8258154.0658, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8258445.0446, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8258735.9310, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8259026.4963, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8259316.5432, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8259605.9014, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8259894.4249, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8260181.9879, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8260468.4828, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8260753.8179, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8261037.9165, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8261320.7155, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8261602.1644, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8261882.2241, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8262160.8648, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8262438.0643, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8262713.8061, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8262988.0785, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8263260.8741, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8263532.1889, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8263802.0226, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8264070.3778, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8264337.2595, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8264602.6749, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8264866.6329, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8265129.1432, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8265390.2165, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8265649.8640, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8265908.0976, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8266164.9298, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8266420.3741, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8266674.4446, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8266927.1565, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8267178.5256, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8267428.5683, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8267677.3013, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8267924.7414, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8268170.9054, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8268415.8099, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8268659.4713, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8268901.9057, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8269143.1290, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8269383.1572, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8269622.0056, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8269859.6897, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8270096.2246, grad_fn=<NegBackward>)\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.0411\n",
      " MSE with beta :  0.57057\n",
      "ELBO :  8270096.22459\n",
      "MMMM_step\n",
      "loss :  tensor(-683276.3728, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-798249.5788, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1377641.0996, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2097887.7676, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1086718.3901, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-568832.8475, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1097710.3614, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-559224.2059, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2157627.8663, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1374687.3857, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-679535.0734, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-679578.4726, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-835000.1089, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-789746.1060, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1230035.1377, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-523470.9387, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1285893.9990, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2854902.9667, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-795312.1678, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-831133.3353, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1120079.7110, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-418782.0877, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-238855.7607, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-724310.8034, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-568124.5318, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1547279.6063, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-725307.1596, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-558330.3364, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2153048.7882, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1422721.1670, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-627541.3850, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-667508.3211, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1085265.3610, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-834531.2578, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-533011.3125, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-742334.6934, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2575889.2382, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-492245.7799, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-794347.7724, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1212496.0620, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-745164.6235, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-858865.8550, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-378674.9212, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-591793.4506, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1178489.2261, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1844924.7592, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1304368.6727, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1367224.1141, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-864844.9416, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-651067.9982, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1486735.4711, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1583340.0712, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-311077.4156, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-507386.6208, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2158256.4789, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-707445.8677, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-721089.2731, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1917070.7248, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1236277.3386, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-477856.8404, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-721282.8246, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-496129.8336, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-573760.3914, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2125898.9548, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-690154.3221, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1499300.4951, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-490885.6957, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2454084.2999, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-607875.0070, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-875066.4497, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-561989.7634, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1089172.8439, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1813615.0752, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2210378.1150, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-646521.7687, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-931353.5167, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-947255.4366, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-512317.3883, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-542833.4677, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-665917.9751, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-815196.4930, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-576260.1550, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2134334.9088, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-667235.8043, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-831181.5762, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1171890.5163, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-537057.8290, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1531054.9348, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-898886.0961, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1080180.0598, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1154800.6268, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1329972.9607, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-400505.3841, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2034398.5883, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-637555.1751, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-732720.3849, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-708961.9286, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-762962.0306, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2138141.6820, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1532029.2004, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1215493.5844, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-259892.2727, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-505334.6821, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1143516.5210, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2310919.7414, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-992627.8172, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-609410.6960, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1223689.1310, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-954633.7847, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-865428.0235, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-774513.8886, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-537858.0974, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1218196.3722, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-628418.3939, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-548962.8796, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-407859.1090, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-881551.4450, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2144192.3285, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1312387.7100, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1127721.4407, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1177107.8184, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-406455.4335, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1163870.1784, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-276895.8309, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2397507.2696, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-686095.3258, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-782489.0086, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1379478.7115, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-817217.6335, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1770350.3340, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-935867.0700, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1931917.8332, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-991507.2613, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-665005.6650, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-577041.6785, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-580812.3384, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-960190.1143, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-834899.0195, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2185536.6676, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-552638.6184, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-846013.2237, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1107809.6652, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-393940.6472, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1388352.6741, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-454339.1339, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-477034.8815, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-498975.8861, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2940655.2166, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-680989.4001, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-813021.3106, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-920813.3879, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1483610.1568, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1188369.4098, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-972616.4201, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-956435.1361, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-952188.6363, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2133661.6923, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-770985.5341, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-689724.2547, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-605929.5222, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-619136.4511, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-931007.0003, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-355895.6178, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1097034.6838, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-810152.4156, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2184283.6983, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-813744.4637, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1458246.5413, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-718874.8644, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-577136.7170, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1167470.1843, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-803114.0318, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2785503.7073, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-706242.8706, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-717761.4919, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-793860.6818, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1024909.7335, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-448601.5483, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-965518.8451, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-932247.3374, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-854915.3676, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2079844.9096, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1203531.2495, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-760651.0050, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2515558.7477, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1248071.3208, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-797426.7714, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-588385.5833, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-619413.1911, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-656057.1511, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1047662.8252, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-797502.0707, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-777113.2818, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2528259.7473, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1457553.2181, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-497171.9501, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1056396.9893, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-584123.1757, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-774193.0408, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-595041.4452, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1023854.1178, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2543875.4030, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-442475.5410, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-661008.3289, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-847212.4081, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1057889.3317, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1020027.4832, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-673536.9074, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1258001.5058, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1189425.6547, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-712758.4680, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-732955.7001, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-866394.0979, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2003475.1773, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-747381.9351, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-759698.0002, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-770157.5581, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-953725.6946, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2201723.0283, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1548495.9014, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-630646.5913, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-527993.0834, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1192267.8496, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-444814.4687, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-766604.2655, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-476987.8053, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-651568.6759, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-914764.1557, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-707376.6596, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2128750.0449, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1179986.3525, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1443768.8964, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-612413.1849, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-650424.1269, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2730408.9419, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1002296.1947, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-635617.3867, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1465819.0928, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-581449.2782, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-591345.2779, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-770338.3983, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2787764.5035, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-779482.0783, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-731083.3524, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-876565.6446, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-893246.2455, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-968896.3641, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-462434.6422, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-735336.9001, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-767549.1087, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-479403.7345, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-456604.9538, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2086565.5151, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1058760.7885, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1342140.8162, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1343783.1314, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-609117.3140, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1090059.0260, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-531597.5072, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-685460.9521, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1656069.1481, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-826262.4190, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2111494.7447, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-760222.4913, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-534588.6327, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1068114.3108, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1113566.6511, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2109281.5566, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-988335.4608, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-596993.6219, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1499148.9095, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-359882.3447, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-796985.9868, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-877029.4478, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2292037.8999, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-794368.7728, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-607297.5807, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1674763.2468, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-606951.2480, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-620724.9026, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1470971.4446, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-939112.7877, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-691959.6241, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-573120.5217, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-505203.3190, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2200507.6139, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-518981.5922, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1370574.2677, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-591994.5077, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2025454.3253, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1595835.8393, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1165969.0604, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-557588.9179, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-657340.4167, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-527820.1305, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1147988.1878, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-752234.7722, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-745105.0655, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1700465.4193, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-450292.7952, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-518947.1247, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1625324.6831, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-368731.5206, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2108800.8378, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-768380.9151, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-784449.7033, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-473973.5599, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-440494.2191, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1016548.5824, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1951153.8669, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1454519.1180, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1380283.7069, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2119753.1935, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-483265.8916, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1043540.2605, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-662403.0686, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1273776.6328, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-786211.8969, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1114811.4339, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-786132.3261, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1499111.7458, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-394056.3085, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-946943.3173, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1046337.5477, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-860288.5956, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-645988.7659, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-758175.5420, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2118675.4508, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1103929.9064, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1321675.1593, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2167267.4763, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1043018.7653, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-685325.9238, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-626272.8010, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-460510.5433, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-862000.2231, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-842086.2627, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-539642.3224, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-720935.0410, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-632498.0402, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1564434.5230, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-775304.1836, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2135851.9783, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1059397.2332, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1259001.3524, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-570681.6186, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-635823.5192, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-973816.4198, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2733281.0764, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-602282.0890, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-819381.0647, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-675287.1877, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1231404.1218, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-412005.3122, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-694522.1430, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-717648.1345, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1254138.9993, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-931266.4617, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2508041.4017, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-520864.0872, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-815837.9641, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-591941.4708, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-959005.1854, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-967391.0784, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-918436.8782, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-537696.8015, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2120958.6606, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1358635.5598, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3278985.9861, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-607446.0724, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-394687.5002, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-686447.9368, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-794662.6860, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1427204.9071, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-579958.8439, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-498784.4341, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1240806.2104, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2549851.9567, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-519338.0240, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-693632.9263, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-413608.9066, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-649243.8138, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1260883.4255, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-942449.4868, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1080874.9472, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-589536.5196, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2280055.3161, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1102463.9998, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-807568.1496, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1003155.7552, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-948640.3741, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-456542.3684, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2305141.8311, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-894648.9201, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-656054.0424, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-578503.5061, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1032463.4028, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1381931.2631, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-882113.8228, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-538989.3027, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-691648.1959, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1055459.5368, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1237588.3089, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-687829.3896, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1947824.1559, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1449279.4925, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-755931.2806, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-445113.0367, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-808135.7279, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-688500.5973, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-633020.3560, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1306227.3915, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-604727.4441, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1150894.2936, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-741641.9208, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2335163.9384, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1025505.3070, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-805521.4538, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-482068.8982, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-402975.9759, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1270488.5029, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2502600.5076, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-766212.8430, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1015258.8149, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2285236.9357, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-671188.0689, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1232529.4500, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-709159.1320, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-900410.5206, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-996954.4620, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-801053.8854, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-673045.9708, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-508025.2323, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2325339.3338, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-788898.7757, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-348375.0943, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-696469.3228, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1112704.7339, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1085667.5636, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1404764.7602, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-764737.2702, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-886743.7770, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-559669.3749, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-700700.3598, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-502562.3969, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1347597.4786, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1633914.9153, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1873605.2378, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-798313.0228, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-765846.5734, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-448550.8152, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-870192.9736, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1329685.2921, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2372613.2850, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-623256.1063, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1061512.8044, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-628864.8772, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-712071.4295, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1870754.6297, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-435172.2759, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-606601.4150, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1997771.6249, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-759235.2629, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1259627.9681, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1093419.5510, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1303198.7493, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-594207.3163, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-687547.8369, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-559184.0505, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2302640.8824, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1109106.3149, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-620920.2348, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-387508.6352, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-328233.6619, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-949894.1563, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-476770.2179, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1500060.6497, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-795818.3103, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3029530.6925, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-801002.2838, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-676808.1812, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-561195.0490, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-667118.1666, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1327154.0338, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-830221.8254, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1141171.2677, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-569191.3603, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2497313.1465, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1261309.3849, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-830800.0369, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2376234.6269, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-534163.1480, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1267966.9875, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-646349.2648, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-589917.9803, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-763294.3867, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2219889.9826, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-747079.4771, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-912127.8272, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-669794.8075, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1107060.0578, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-691408.4310, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-968196.3102, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-954378.3914, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-944768.7134, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-572537.6248, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-584730.0331, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-592111.7237, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1594342.4331, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2145330.9695, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-953681.7837, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-881521.4903, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-803946.0545, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1469911.2925, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-689230.6804, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-693926.5952, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-772518.2185, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2504008.3517, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-888974.0459, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-447289.6033, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-794689.3445, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1229255.0334, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2294770.6585, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-314957.7016, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-700681.8418, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-904663.0757, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1577898.8209, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-453401.8670, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-795494.6717, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2180385.2085, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1294015.3889, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-733655.3669, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-879845.8020, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-901402.1135, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-651852.0880, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-833024.7588, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1150296.3940, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-479888.3238, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-631488.6627, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-657499.1707, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1197637.3404, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2047908.2198, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-831780.1047, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1273889.4461, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-811117.3729, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-791026.5160, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-872763.4453, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1296863.9619, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-637199.3000, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-416674.7882, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-863753.3854, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2580598.9049, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-674010.0230, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1078087.6760, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1224963.9421, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-501988.8350, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-710356.5678, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2026823.1825, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1628662.8034, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-425499.9894, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-715175.2749, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1289828.7962, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2403602.2049, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-844101.1217, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-407431.6403, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-786748.4416, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-761163.7128, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1061530.2013, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-222146.1979, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-682922.6046, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3334125.0023, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-733033.0429, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-613771.3531, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-777842.9711, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-754769.2561, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1151540.4984, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-508149.8965, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-603904.1278, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-888887.3017, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-910689.6115, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1309429.2077, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-968107.6627, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2200851.4583, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-879693.8611, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1048290.8237, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1559964.0881, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1388929.2171, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-319463.7600, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1958702.9899, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-899370.1266, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-565053.1066, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-529460.2250, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-694932.8363, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-494853.6941, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1302343.1620, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-780699.9229, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2030991.2030, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-538603.4800, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1343131.1415, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1084381.2553, grad_fn=<NegBackward>)\n",
      "VVVV_step\n",
      "loss :  tensor(-8270665.3923, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8270915.1886, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8271166.2817, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8271418.3058, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8271670.9205, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8271923.8167, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8272176.7197, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8272429.3881, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8272681.6124, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8272933.2124, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8273184.0342, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8273433.9469, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8273682.8401, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8273930.6217, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8274177.2160, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8274422.5625, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8274666.6142, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8274909.3362, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8275150.7029, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8275390.6967, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8275629.3059, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8275866.5233, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8276102.3455, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8276336.7721, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8276569.8052, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8276801.4489, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8277031.7095, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8277260.5952, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8277488.1158, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8277714.2825, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8277939.1072, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8278162.6025, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8278384.7815, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8278605.6577, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8278825.2451, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8279043.5582, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8279260.6124, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8279476.4233, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8279691.0074, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8279904.3816, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8280116.5631, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8280327.5695, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8280537.4182, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8280746.1267, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8280953.7120, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8281160.1911, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8281365.5805, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8281569.8964, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8281773.1547, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8281975.3709, grad_fn=<NegBackward>)\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.0359\n",
      " MSE with beta :  0.54797\n",
      "ELBO :  8281975.37094\n",
      "MMMM_step\n",
      "loss :  tensor(-1281151.3144, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-467960.9855, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1462270.7524, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2142653.9983, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-425103.3367, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-770940.9760, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-806935.0839, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-924747.9437, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1442175.7360, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-933833.8519, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-876292.7219, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-610851.1601, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2419710.3430, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-591286.5082, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-775739.3596, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-631659.8754, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1312853.5052, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-710396.0705, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-457567.4799, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-648814.1923, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3195290.0852, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-610782.6765, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-736325.8698, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-609471.0514, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-449765.4453, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-727663.6572, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2443503.9028, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-898707.7066, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1186403.3939, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1038908.2931, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-665643.9891, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-871128.5375, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-717954.6888, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-674741.7115, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2372327.7342, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-513088.6253, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-528345.8310, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1099979.4421, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-787615.7824, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1587723.2052, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2939169.7500, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-582503.6486, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-518519.0359, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-847976.4794, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-603988.9224, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-604595.2663, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-437248.7898, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1747423.8087, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-614719.7863, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-444775.6759, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-782739.5019, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1267429.5871, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-483960.5130, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1413837.6202, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1996093.7106, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1278096.0562, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-886746.5635, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1049403.2621, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1456395.1182, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-761237.9208, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1924492.9097, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-629103.2046, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-751176.5778, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-822938.5869, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-738363.0492, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2760861.1045, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-720442.7889, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1331055.4303, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-831609.1036, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-854332.5896, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-496341.9051, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-549024.2634, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-547360.1298, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-746950.4770, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1618194.8403, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-785680.3431, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-516711.9205, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1406149.0749, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-828437.7538, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1831777.1457, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-838121.1697, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-602513.4316, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1781756.0263, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-919906.2650, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-557522.8882, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-915826.9874, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-600499.3499, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2065914.4043, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-891302.2148, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1038158.9513, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-967016.9264, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-747451.0065, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1965309.6480, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1181562.2986, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-533141.8834, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-957878.8711, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1404710.6436, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-886344.3359, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1141138.5161, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-807320.5191, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-835377.0286, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2058772.9454, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-662806.4217, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-485573.5429, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-506557.7464, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2417720.2336, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-446902.6844, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1613113.6423, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-642652.1110, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-855848.6846, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1165707.9519, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-633060.2452, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1341604.9709, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-595585.5660, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1653458.0866, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-715569.0208, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-580249.4573, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2316785.0324, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-524105.2643, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-553943.8831, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2124600.2020, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-897777.6507, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-961710.9351, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1646262.1159, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-545346.8460, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-866312.0157, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-669126.7952, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-570599.5534, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-522146.4328, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-652444.1717, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2162554.2571, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1308068.9325, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1299624.2178, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-747010.1952, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-525187.6409, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1064380.6533, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-419580.4341, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-567356.3760, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-638536.2024, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-785962.3912, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-940925.7125, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1395559.6426, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-795832.6326, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2737508.8394, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-616532.7870, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2288912.8480, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-746825.5808, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-637501.0736, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1247171.8107, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-629417.1507, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1575135.0898, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-539413.4399, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2275202.6809, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-356929.3063, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-529527.0485, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-790465.2135, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-719951.7974, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2041901.6346, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1015507.1883, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-551997.9920, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-695830.9969, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-566090.3506, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-792263.7222, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-927643.3935, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-682642.8957, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1964452.3411, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1969323.6044, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-683494.6376, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-450429.5811, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-517943.3853, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1315525.7348, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-395130.3791, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1403448.0827, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-854405.3875, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1193631.6951, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2151586.1605, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1013155.9349, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-563699.0098, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-866619.6299, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2738788.2348, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-473414.5188, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-387008.1840, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1431923.7414, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-806083.7570, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-369182.7617, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1120977.2708, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1487516.1940, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-667449.3957, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-475899.0944, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1291171.7368, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-688744.0339, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2180932.3173, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1550797.3750, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2090797.8145, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-412309.1172, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1019119.5463, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-712766.5199, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-757710.3643, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-434686.9577, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1302914.0050, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-794641.8173, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-693027.4295, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-798891.5517, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1508792.5339, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-676060.1959, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-590291.9426, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2181377.6662, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1038372.3936, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1015650.9423, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-516720.6903, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1116647.0288, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-512564.1098, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-936699.9200, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1166453.8483, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2376540.5879, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-640778.2394, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1741654.7877, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-622129.3501, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-769506.5410, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1008670.5444, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2205966.0671, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-429160.8488, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-783562.1508, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-721147.6992, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-467952.3471, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-445085.0663, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-389213.9415, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1990904.7562, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1124724.0351, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-599742.2062, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2138767.7752, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1124138.5368, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-767367.1613, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1107879.1507, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-965694.1639, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-556709.8487, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2302702.1289, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1186663.5356, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-604947.5769, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-789340.5569, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-609128.3529, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2137363.2066, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1084781.8134, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1387040.2332, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-783248.6097, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-744540.3745, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-668350.2146, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-867249.1995, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-808473.3616, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2307792.5644, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-531152.9313, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-555112.5740, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-633379.5526, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-679245.2574, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1261457.2778, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1504354.3239, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-782777.0736, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1609380.1653, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2297908.9673, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-496462.7090, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-576487.4580, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-602674.9920, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-449916.3502, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1465722.3776, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-504809.6314, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-490332.7751, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-768872.3527, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2093913.9221, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-776205.9738, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1211825.8099, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1092292.8444, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1342912.4026, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2914358.1996, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-829332.2967, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-497298.5037, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-890922.4815, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-730096.9100, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-976173.1320, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-872780.1036, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-570892.7782, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-672582.0517, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1000492.9570, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-543480.8271, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2196195.7831, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-807110.1734, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1479284.7635, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1104616.1792, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-477933.2293, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-678839.1775, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-672661.6828, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-678194.6916, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1176431.9087, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-824082.7438, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1200888.4141, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2207585.2477, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-843366.6464, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-682602.6303, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-764853.1189, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2060540.0317, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-699182.1829, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-686686.4491, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-712177.8600, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-562532.6250, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2113539.6947, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-363936.4027, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-485927.8387, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1257996.8972, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-427527.1654, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2485205.4625, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1698994.4228, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-672070.9214, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-890016.6545, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-623464.9197, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-997309.0747, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-690924.1073, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1078379.9094, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-804184.2310, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1232255.2373, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-771382.7616, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2084093.3710, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-572250.4697, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-742550.2991, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1322967.0795, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-461391.2660, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2295642.9212, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1317924.8611, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-835049.2244, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-734151.8162, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1254100.2642, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-741101.9429, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-831010.1727, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-505536.2963, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-508490.0738, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-835133.9071, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2759085.2096, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-847377.2982, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1350572.7973, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-576428.4490, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1297874.0544, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-872983.2006, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-800480.9950, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1976695.7384, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-820229.8006, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-586347.7090, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1300322.3474, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-492241.5743, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2166301.0354, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-624678.8228, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-907138.3227, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-329946.0288, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-694532.3736, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1766348.3694, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-715147.0547, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-844784.0653, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1808246.8436, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-956753.6593, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2138328.5993, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-703665.1328, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-577652.3787, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-536523.2387, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1237765.1582, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-599320.1231, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-802529.5939, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-578875.7652, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1961215.5801, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-426578.5515, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1546019.6760, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1128807.7196, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2273242.0739, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-741352.5356, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-418164.8302, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-465323.0718, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1284847.6236, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-541815.0197, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-755116.3339, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1801639.0000, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-612970.7510, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2164358.3280, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-705663.5616, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1232734.7360, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-605155.3712, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1266246.2966, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1037774.3266, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-656535.0963, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-497077.0699, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-584280.8097, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-712663.3818, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-961498.3675, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-556615.9508, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2628672.2792, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-565722.3751, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1773940.4584, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-622490.9975, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-648325.4428, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-955025.7858, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2107480.7056, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-932259.4871, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1216250.3144, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-711371.8562, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1088874.6325, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-821193.3601, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-533447.7911, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-930587.6995, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-866192.5500, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-477196.5825, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1407918.3729, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-936071.5701, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2309144.6825, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-635971.4240, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-683316.3209, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-782654.6662, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-827299.8576, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-632094.9805, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1042252.3851, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1543088.7817, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2133692.8744, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-766626.3724, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-519174.9570, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-904836.6066, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-574604.9930, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-544523.8942, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-655785.9857, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3434448.1834, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-882411.0119, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1417772.1045, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2257205.4611, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1117774.5963, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-387355.1183, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-572060.3613, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-901048.0941, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-773106.8528, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-854994.2335, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2279414.1574, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1117453.3425, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-866474.3360, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1246292.1486, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-429142.8864, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-771513.8070, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-525904.9093, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1046120.0636, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-615391.9733, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1003621.2225, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-533148.0776, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3336502.5612, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-882995.7112, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-635502.9969, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-557214.1499, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-716255.9528, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1148457.3480, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-639276.9783, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-544539.6861, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2316334.0030, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-736435.8073, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1537047.2621, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-838395.0314, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-521297.9432, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-472695.3848, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-773773.0800, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1033863.2093, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-753120.2785, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-897881.5052, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-744886.8105, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1263083.1231, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2342038.6387, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1000135.5225, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-991200.5253, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-671833.2670, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1440605.5239, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2086221.7812, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-652037.6864, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-591271.5841, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-848628.1457, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-877422.0949, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2957951.2566, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-609699.8190, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-688503.7594, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-331062.1023, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-565418.0413, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-794841.4675, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1456584.3462, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-373513.3472, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-696278.4098, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2061102.7035, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1444275.8095, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-630801.0632, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-930295.1100, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1678182.8831, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-467265.0635, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-808700.9045, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2357439.7605, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-522937.0383, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-512312.8486, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1110155.2864, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-507922.6391, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1450651.5748, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1011613.3907, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-906654.0281, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-985385.5565, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1271133.0815, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-498707.9773, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-507478.8054, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1094831.8303, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2153236.0068, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-864826.1782, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-573451.6739, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-482126.7038, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-732007.9235, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1522478.8897, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-982534.3289, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2334077.5931, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-615205.2206, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1039612.8177, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1398696.0161, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-583373.2561, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1351577.5000, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1940904.2648, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-760800.8749, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-563145.1681, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1189688.8122, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-493405.2799, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-769247.5071, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-452017.1344, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-706201.5265, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2069847.2285, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-724438.9659, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2159450.4406, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-652933.9478, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-747255.9443, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1098270.3925, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-970005.4032, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-647657.1631, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1849867.2444, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-806329.6705, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-557299.3701, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1588211.0393, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-763289.8718, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2123491.0721, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-890121.0107, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1085573.5026, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-417660.4694, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-811999.2240, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1125955.0026, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-769324.5766, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1058044.5116, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1824214.9347, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1398654.0075, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-734528.4159, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-604561.7521, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-537940.1769, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-889910.3377, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1346885.4788, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-944847.1100, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-656394.0155, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-546285.9202, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-723898.6204, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-867431.3417, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1125416.0102, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1138484.1627, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2102772.3816, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1121277.1895, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-573622.4043, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-588637.3327, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-483306.8677, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1565257.9223, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-467009.5544, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2193789.7052, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-792213.7293, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1617998.7771, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-663602.1684, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1221765.4454, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-716733.2520, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-545242.3990, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2100241.2568, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1327387.6634, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-991073.8922, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-716071.0616, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1375523.2288, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-838313.6535, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2426994.3714, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1120674.7033, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-380897.7187, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-817393.5557, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-531097.2940, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-791029.2115, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2016864.6251, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-718719.1730, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-797973.1540, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1169519.7706, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-813213.3795, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1314714.3535, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-622637.5977, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-828363.7439, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-822286.0922, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-697624.8936, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-894775.6539, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1579483.9938, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2282521.1167, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-392574.6723, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-963519.4383, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-648636.2967, grad_fn=<NegBackward>)\n",
      "VVVV_step\n",
      "loss :  tensor(-8282344.6354, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8282547.8133, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8282751.0729, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8282954.2419, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8283157.1522, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8283359.6488, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8283561.5949, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8283762.8740, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8283963.3897, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8284163.0647, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8284361.8392, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8284559.6683, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8284756.5201, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8284952.3743, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8285147.2200, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8285341.0552, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8285533.8845, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8285725.7178, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8285916.5684, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8286106.4516, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8286295.3837, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8286483.3805, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8286670.4568, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8286856.6259, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8287041.8995, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8287226.2881, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8287409.8012, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8287592.4477, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8287774.2362, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8287955.1753, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8288135.2733, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8288314.5389, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8288492.9804, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8288670.6065, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8288847.4258, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8289023.4469, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8289198.6785, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8289373.1296, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8289546.8094, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8289719.7272, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8289891.8927, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8290063.3153, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8290234.0048, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8290403.9706, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8290573.2219, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8290741.7677, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8290909.6168, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8291076.7774, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8291243.2575, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8291409.0649, grad_fn=<NegBackward>)\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.03174\n",
      " MSE with beta :  0.52499\n",
      "ELBO :  8291409.06488\n",
      "MMMM_step\n",
      "loss :  tensor(-780987.5088, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-701183.5239, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-946408.5668, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1252943.9180, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2364117.7047, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-551326.8326, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1063478.4077, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-630621.1770, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-558860.3295, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-765072.1384, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-689675.7250, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2417423.0349, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1156684.3124, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-940225.9863, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1237662.2515, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-526006.2644, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-778867.3061, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1486017.2294, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-715827.9799, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1365773.6725, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-612656.2459, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1975951.5572, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-837240.4654, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-519109.1778, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1355292.8803, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-937983.9716, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2069279.2658, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-600288.5840, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-944314.8836, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1130265.5832, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-624827.9936, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-628803.8068, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2243826.9354, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-578189.2518, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-893029.9130, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1720815.4782, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-541316.9338, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-741235.1936, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-443729.4712, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1129524.7770, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-505548.2321, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-683325.5526, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-577390.6623, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1281539.0805, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2063076.2897, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-579695.9007, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1409318.1931, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1190701.0631, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2443453.3005, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-684771.1658, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-751726.2358, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-927996.6367, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-727623.3487, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-389248.0538, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-523551.5428, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1843014.4333, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-361294.7549, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-849570.0356, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-849175.2435, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-911088.6436, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-773610.8570, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2261446.2385, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-480161.1846, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1804997.6997, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2773496.2777, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1208622.9601, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-597145.9688, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-431766.1498, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1263135.6977, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-711282.2378, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-787417.3019, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-518699.0644, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-708644.0970, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-554083.1774, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-608228.6620, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-731825.2217, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2185999.0927, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-990130.4918, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1605390.2236, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-906982.7196, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1032225.7446, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1083171.4435, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-848588.2443, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-324357.3459, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-905852.9558, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1144364.3758, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2512261.1095, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-440294.5981, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2505993.6368, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1123498.6724, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1207073.9428, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-707370.6059, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-759142.5212, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-826904.3646, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-423739.2445, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-737983.3503, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-658587.4643, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1296909.0961, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2047420.5815, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-988946.6554, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-427638.9662, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-634598.7741, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1384230.2818, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-852801.7785, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-854528.6399, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1491824.4142, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-567568.5479, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-562851.6197, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-594709.5965, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1233144.2119, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-960723.2163, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2026455.0521, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1677159.3368, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-588229.1927, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-787691.3489, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-741690.0281, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-878508.8872, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-755958.5928, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-638756.1628, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2223308.0502, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-680213.2648, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-751957.3834, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-506876.1704, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1628796.3974, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-753904.9046, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-911910.6033, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2640500.1725, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-417344.8056, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-609755.2635, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1395612.9716, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-976091.3451, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2713579.5802, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-675588.9682, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-799003.4194, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-605120.7563, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-516698.4074, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-788994.9905, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2101541.5362, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1065944.8722, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-741108.2257, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1107701.8516, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1432552.2630, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-640831.5213, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-412984.1830, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2472190.2785, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-479294.2908, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-984176.1061, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1097054.0273, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-523203.4873, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-615338.7648, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-827891.6335, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1292158.4599, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-909189.8637, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1145834.9610, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1690150.3712, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-463801.9759, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-505512.3175, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-614568.3215, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-850100.5402, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2112163.8147, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2147170.4861, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-958644.1737, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-947241.9475, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-468702.9285, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1495835.8609, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1114085.8833, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-583944.5251, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-575861.4686, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-745633.7770, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-457308.9153, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1361023.8919, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-966326.9351, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1193663.3273, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1071402.5922, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-436894.3948, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2059273.7312, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-842306.4167, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-523051.3064, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1459750.8250, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-929976.5792, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-971176.7928, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2368518.1994, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-428951.8589, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-767522.7211, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1298468.4470, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-393129.2105, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1245457.9838, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-731592.6421, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1067347.4275, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2314001.6250, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-511661.8778, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-729484.0372, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-453165.5876, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-770108.1539, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-614167.4959, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-602624.9727, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1512478.6594, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2877485.6000, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-704330.3290, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-757333.0767, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-707994.6496, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1107568.2323, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-657193.6022, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-652489.3682, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-729165.1386, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1313388.3037, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-372726.2568, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2751082.3142, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1718702.7399, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-788943.7184, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-727423.2512, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2429859.4123, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1126784.6208, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-312435.9195, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-404426.1850, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-783195.6983, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1152937.5171, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-494965.3357, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1361570.5873, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2223427.0873, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-776806.5166, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-573103.0803, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1138384.8946, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-570284.6506, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2330305.2035, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-689488.6799, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1546865.5585, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-507301.0455, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-521001.0911, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-557981.0975, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1357713.6982, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-780893.0394, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1899358.6234, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1086627.6809, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-570144.1351, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1409505.7892, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-653546.1729, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-564600.6574, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-892887.8876, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1214965.2888, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1580233.0257, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1104199.7976, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-634671.8776, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-939326.9549, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-834017.4116, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-460085.3425, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-542719.5894, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2196090.7434, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1077714.2166, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-481485.3586, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-496032.1726, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-920291.5075, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1856411.9069, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-875989.6398, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2033770.6411, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-549560.0670, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1224749.9686, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-623827.8850, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2023008.6918, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1132350.7680, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-809756.3096, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-751445.4077, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1033994.2494, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-692497.1715, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1094863.0860, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-829816.3128, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-661268.8879, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-703617.4564, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-616326.3966, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-338829.2920, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1329751.0836, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2716734.5590, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-507598.7484, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1662475.8184, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-735808.9162, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2254062.2630, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1057987.8569, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-762943.9889, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-769604.0702, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-541112.0009, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1177860.1022, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-780849.6826, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-960512.5378, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-585688.5621, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-719993.5454, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-721423.6042, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2954683.6111, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-390637.2208, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-758052.1594, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3297211.6701, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-958115.7899, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-511480.5963, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-728356.0060, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-508418.0438, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-801285.5610, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-728174.4174, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-855209.4492, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-957169.9148, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-731835.7914, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-551004.8490, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1700787.9220, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-675338.2271, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2232840.8087, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-587350.6731, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2039446.1109, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1915978.5325, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-761788.7563, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-977119.7162, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-419097.2398, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-539870.5077, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-805945.1569, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-831945.9418, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1145646.0983, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-652616.3505, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-650467.4836, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-690356.8688, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-688533.5195, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1343246.2011, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2356165.6038, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-763339.4652, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-705436.6358, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1916046.0300, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-663907.2912, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-752029.4963, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2070259.5258, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-884434.1176, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-771671.4742, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-526991.5740, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-806467.3232, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-780164.2377, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-734259.5139, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1344206.1556, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-478778.6281, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-688709.9714, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-764928.4087, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2693595.4572, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2202393.1416, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-982210.1188, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-840585.6024, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-686208.3516, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-670199.4782, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1771739.4632, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-493580.5857, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-643863.1936, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-620428.8113, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-871767.3124, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-980000.6257, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-598358.6022, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1998007.6404, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-578073.4816, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1350985.7118, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1293613.2020, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2462938.6158, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1317354.0536, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1002130.2187, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-477902.3810, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-511477.1759, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-897999.5130, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-825962.7803, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-795536.3148, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1252615.7984, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1922865.2981, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-868848.1833, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1482162.4955, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-793367.9418, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-557389.4564, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-538585.4817, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-875568.5949, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-929922.6280, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1835522.4480, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-784744.6476, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-716439.3015, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-695755.2607, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-554782.6210, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-515127.8587, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2259105.8714, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-473813.8361, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1318349.6819, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-388267.2690, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-874177.1100, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-514732.2221, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-998216.6818, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2086317.2059, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1637165.8483, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1315862.5461, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-846620.7175, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-808228.1915, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-728919.9788, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-922431.7337, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-555785.6241, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-696886.8780, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2415303.5150, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-411627.0533, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1008993.9378, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-974248.7363, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-839119.7810, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-963819.9956, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1454837.2307, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-430419.2234, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2206514.4885, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-636950.1347, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1030813.0926, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2427040.8399, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-845974.3174, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-850734.3273, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-848215.4811, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1068970.5916, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-581972.1960, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1001636.5097, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-770186.9426, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-636382.5715, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1201256.0479, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-523498.9208, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2471654.9720, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-843981.3971, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-842182.8123, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-657954.8193, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-431773.3944, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2239381.8477, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-937505.3006, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-573687.1288, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-732634.4477, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-684033.5439, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2033989.0737, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1184258.2864, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2058139.3189, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-725394.2638, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-556828.1337, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-736076.6965, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1145832.1979, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-632881.3276, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1250984.5571, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-596776.8162, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1393677.4728, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-496184.3969, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-647651.0846, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-965082.7813, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-877715.0678, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-435238.2418, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2878845.1383, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2039210.2237, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1146541.9719, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-518448.1583, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1314840.5754, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1440373.9907, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-524710.6174, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-582813.3649, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-724605.7815, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-702197.5553, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-776295.4961, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1065980.4316, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1129909.5187, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2434859.7910, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-729940.4341, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-483076.5244, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-969366.1514, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1225213.6210, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-990979.3141, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2176523.4434, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-658171.8648, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-609465.4652, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-696003.2447, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-954269.7951, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-980992.9482, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1317067.6472, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-292258.2919, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-443516.5940, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1686306.7318, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2242757.9235, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-650161.4332, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-887698.7745, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-771665.8831, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1471467.6423, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1758885.0695, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-731173.6100, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1213193.1790, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-690783.1116, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-885927.4468, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-744240.4275, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-796197.7462, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2418029.3056, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-939330.8909, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-636560.8752, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-936605.0738, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-939488.9975, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-648655.3014, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1064793.4483, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-707981.0594, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2143167.3698, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-618305.8137, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-847231.3033, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-932192.5801, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-969969.0257, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-751229.7949, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-914369.3665, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1115161.5718, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-413785.1265, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1379685.5424, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2251242.2229, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-804527.1713, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-509821.1758, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-779105.7199, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-874544.0438, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1278152.4904, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1036222.8651, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-732669.2764, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-723162.8426, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-678655.7988, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1929133.7867, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1274016.7190, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1326960.6208, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-590471.0180, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-747406.2555, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-604283.0602, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2547440.4163, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-621835.2352, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-806501.5525, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-763656.4914, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-753104.8479, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1447173.7197, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2169040.6638, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-483036.6354, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-542917.2241, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-742419.4484, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1141455.5040, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1505215.5639, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-908330.8230, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-798514.1796, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2384951.0039, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-611320.2314, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-904822.2471, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-731374.5690, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1040630.3953, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-820028.2450, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-619621.5039, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1179035.7733, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2095086.7157, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-552722.1586, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-851294.4979, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1579990.6422, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-989127.3589, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-413530.4229, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1226998.4898, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-582114.7007, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-928023.8279, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-831999.9971, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-643820.2120, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-840143.1137, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-399078.5656, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-426169.4373, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2844201.8462, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1378031.4173, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-632494.5868, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-696361.5137, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-858659.5595, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-515445.4083, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1603517.0051, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-900682.7256, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1063263.3398, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2021129.8071, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-760458.1548, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1181356.0232, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-655045.0226, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-485849.3740, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2135372.0982, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-885550.7377, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-923641.4372, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1264371.9479, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2077162.2831, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-816668.0273, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2013936.3854, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-587736.9489, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-476507.5523, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-710960.8959, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-663094.3030, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-945276.5157, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-693837.4013, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2519262.1049, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1396666.5931, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-391608.1957, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-763242.4908, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-513695.9625, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1263510.8086, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-749221.4343, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-815880.1351, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-681709.6960, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-557772.8062, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-712400.6205, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2353726.3188, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1594335.2936, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1050449.2380, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-524967.0983, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1164979.1411, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-629738.6061, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1141663.4045, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-781753.6429, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-634948.9501, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1234952.5151, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2039509.6035, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-664090.7706, grad_fn=<NegBackward>)\n",
      "VVVV_step\n",
      "loss :  tensor(-8291958.1519, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8292128.1490, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8292298.8551, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8292470.0663, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8292641.5887, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8292813.2443, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8292984.8741, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8293156.3391, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8293327.5192, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8293498.3125, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8293668.6330, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8293838.4086, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8294007.5800, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8294176.0986, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8294343.9262, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8294511.0332, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8294677.3975, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8294843.0031, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8295007.8396, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8295171.9004, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8295335.1822, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8295497.6842, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8295659.4069, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8295820.3517, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8295980.5206, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8296139.9162, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8296298.5416, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8296456.4007, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8296613.4980, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8296769.8390, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8296925.4300, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8297080.2779, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8297234.3905, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8297387.7757, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8297540.4419, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8297692.3974, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8297843.6508, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8297994.2106, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8298144.0850, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8298293.2825, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8298441.8113, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8298589.6795, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8298736.8952, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8298883.4664, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8299029.4007, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8299174.7059, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8299319.3892, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8299463.4577, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8299606.9184, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-8299749.7778, grad_fn=<NegBackward>)\n",
      "-------UPDATE------- 25\n",
      " MSE with Sigma :  0.02862\n",
      " MSE with beta :  0.50165\n",
      "ELBO :  8299749.77784\n",
      "MMMM_step\n",
      "loss :  tensor(-713326.5561, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-857883.9114, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-726025.1955, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-489227.8212, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-792269.8655, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-977227.8153, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1012345.5486, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2730960.4955, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-854948.2236, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-863467.6782, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-448356.6074, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-970016.3596, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1531092.8280, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-492996.9945, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-717088.8358, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2421575.3208, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-885350.4388, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-895282.8259, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1029934.0201, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-672373.5579, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-703278.7600, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-367250.4116, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1450789.7235, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2294857.2984, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-370244.3920, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2208604.9154, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1304782.2418, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-798418.9828, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1385868.6201, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-658820.7032, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-794722.2121, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-777564.9330, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1216194.1148, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-960300.5672, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2409122.9146, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-700394.5167, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-830360.9601, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-653675.1350, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-850167.9196, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-679683.1148, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3506406.0470, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-471361.3896, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-896135.4963, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-728255.5627, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-673643.2840, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-796373.5581, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-844320.2518, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-382850.4646, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-856909.6623, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2176757.9471, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1800233.8193, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-638403.0220, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-582312.5782, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1051051.8358, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-669844.5335, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-523897.7902, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-747290.3080, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1984864.6177, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1297933.5982, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-621619.1324, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1372566.6363, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-823928.0717, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-860387.5735, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-591292.7232, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-478329.2252, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-590209.5192, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1262178.5521, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-833861.8313, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1288409.8679, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-432476.5456, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2776982.8688, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-637023.3737, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-557981.9730, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2158353.7336, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1368884.0520, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1004084.7485, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-477195.4133, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-781774.8044, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1325114.2654, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-626315.9302, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1081961.1958, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2058013.2829, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-711561.9674, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-687022.3855, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1069956.7291, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-702761.3371, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-909388.7415, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1079219.6900, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-740836.6214, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-872843.9761, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-639450.1009, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-789721.9796, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3108325.1754, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-404472.4007, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-631434.8305, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1112589.2323, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-546697.7636, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1091965.8254, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-781533.9877, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-575061.0517, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2223459.9223, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1225758.1071, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1098583.6619, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-756802.0607, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-555297.7163, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-751076.3374, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-587953.7034, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-558607.6204, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-879992.0489, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1615998.6098, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1230630.5606, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2120169.6289, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1184007.7246, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-866413.1904, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1470327.2354, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-664385.0499, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-570874.1727, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2450172.4388, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-478964.5103, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-614816.0785, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-703264.2056, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-743600.8167, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-387073.9519, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1699387.4062, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-812759.0427, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2152583.2459, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-530954.5511, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1269902.5204, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1129321.6816, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-467009.3959, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1592157.8928, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1072443.2929, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-506582.1502, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-523796.5626, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2374522.9504, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-633660.7054, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-949553.8694, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-826852.0091, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-486938.2369, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1715416.9460, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-582127.5139, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-780662.3019, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-979217.9105, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1978965.4040, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2178049.6953, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-582102.3403, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1065128.0740, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-665009.6965, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-736665.5477, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-985639.9496, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1214870.6448, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-871962.0659, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-701463.0514, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-690634.4896, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-885560.7378, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-601878.3072, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1886636.1206, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-603600.7614, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1432777.6015, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1496875.7517, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-734222.6236, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-964228.8856, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2139602.8454, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-840353.5850, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1031863.7933, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-699051.7818, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1259271.3200, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-630787.7038, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1219068.7579, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-711434.5714, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2077325.0670, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1307581.4573, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-761321.4892, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-611725.3056, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-851061.1154, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-760392.0832, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-803231.2167, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-789016.8161, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-898702.8842, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-981284.5388, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2213465.6515, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-436664.0412, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-562748.0228, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1613703.4165, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2149613.0236, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-788277.1163, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-821417.2860, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-691972.1399, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1421784.3770, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1321406.7754, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-501838.9994, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-603495.5213, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1095210.7640, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1055151.4101, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1847905.9374, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-674027.4023, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1148714.7294, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1026624.9563, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-763955.7741, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-688157.9183, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-436978.3812, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-674641.4833, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1069183.7671, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-942966.0284, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1357198.9061, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-681050.8751, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-719392.6289, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2417925.4668, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1111373.2116, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1213031.3973, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-885507.0725, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-523150.7340, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-669713.3183, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1109402.2264, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-834131.6815, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1953138.1515, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-536755.0446, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-694680.1912, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2608485.4153, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-821625.6776, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-826503.4110, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1294753.7536, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1038072.6788, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-478871.7438, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-550773.8558, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-589313.5921, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-713774.4452, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1243598.3133, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-406897.3343, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-772974.0324, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2890260.1439, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1131449.2416, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1251433.3560, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-706854.4916, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1203663.7654, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-844756.8993, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-746896.7924, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-758641.0878, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-580261.6284, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2207234.9543, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-415088.9498, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1383838.0535, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-787794.0112, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2347794.9213, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-613721.7159, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-604862.9462, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1534988.6864, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-611557.5611, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1655327.4765, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1857553.7560, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-540588.8719, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1536316.2615, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-706723.9011, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-804710.6142, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-663882.9670, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-534330.4315, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-353236.7137, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-790002.6219, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1425207.1810, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-594292.6790, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-857666.3315, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2114740.8919, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-700835.3464, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1463601.8099, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-988231.1137, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-505293.2606, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-773222.7199, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-583308.8049, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-656598.7743, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3043616.3686, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-740843.5737, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1008741.1879, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1168327.7428, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-895630.5931, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-619004.0962, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-620605.1146, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-706201.4723, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-696115.7689, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-3081649.1828, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-512418.3458, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2375325.1040, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-762224.7122, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-750994.2261, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-506753.5870, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-756169.1850, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1154047.0043, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1579458.0118, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-415005.5119, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1116203.1773, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2905700.4751, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-751670.3979, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1009430.8495, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-582059.9194, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-457727.7446, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-824410.3754, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-652614.0839, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-648286.6524, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-504832.2459, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-520894.3420, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1307906.1826, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-658523.4280, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-702795.4258, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1418518.9541, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2537950.4442, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-641685.5564, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1130182.5880, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-816148.3897, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-895809.6186, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-925657.2069, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2363543.2001, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-969689.4805, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-557304.3900, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2081665.1583, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-624539.4541, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-639455.8142, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1388154.0872, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-956455.4392, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-940240.3521, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-432152.9807, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1236998.7745, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-720582.7135, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2320584.4871, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-552388.5502, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-421399.9819, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-935504.8428, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1248857.1467, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-576248.5245, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1524249.1357, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-745333.1939, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1984755.7334, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-520023.3614, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-761969.2145, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1198431.2998, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1292734.1150, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-925835.3985, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-870762.4328, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-853670.7212, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-602781.4888, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2180058.8769, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-817269.3792, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-563811.1584, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-545179.0178, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1926662.7298, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-810197.2996, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-955530.3272, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-620447.4599, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-548623.1787, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1838131.4611, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2125839.7552, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-464296.3892, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1003337.8210, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-742565.2989, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-951087.9087, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-475690.4660, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1538725.5786, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-371540.4673, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-364149.3612, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-707225.3563, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2326669.0345, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1563926.4046, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1072635.7036, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1125304.9597, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1956453.4305, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-860535.5489, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-817235.4243, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-893454.7418, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-655944.4673, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-918584.4274, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-701938.3462, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-788251.8214, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1000004.6383, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-426553.9594, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-593753.8509, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2997134.0125, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-738531.1972, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1052875.1161, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-828056.2357, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1234622.2611, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-743241.3271, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1001432.8620, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1195456.4188, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1987869.5168, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-806086.6867, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-502770.6662, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1336210.9420, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1356791.2014, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-726571.3913, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1097776.7151, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-612807.4670, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1812092.8443, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-482288.8455, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-875292.8445, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-753963.7523, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-651421.5276, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-874747.2932, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-786521.6398, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-602032.6756, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-689697.9835, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2545541.9432, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1394880.2816, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2918525.4228, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1045454.3450, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-567952.7744, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-403796.0984, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-862187.1511, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1241356.8267, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-649609.4331, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-609389.4030, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-434632.9340, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-845610.5653, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1588941.9595, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2336654.0678, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-362429.0598, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-482173.4143, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-909546.4865, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1338704.5202, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-817067.2434, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-648553.0496, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1120453.1569, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2538837.2277, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1377260.2393, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-720423.6595, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-657239.7940, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-418813.0550, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-425871.9445, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-733655.2231, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1971041.8333, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1010532.0138, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-647384.0801, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1373012.0249, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1465690.6516, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-672454.3362, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-575248.4244, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-950784.1614, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1298001.2886, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-789677.3276, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-647459.0252, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-698839.8285, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2449100.3467, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-890153.1228, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-638858.7523, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1042364.9514, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1070623.8873, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-475873.6237, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-608548.8669, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-781869.4765, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2939464.0577, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-742167.9634, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1984699.6000, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1689846.3694, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-418244.4330, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-613008.6675, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-521334.6237, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1202981.9360, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-929739.2550, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-939560.7250, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-774094.5321, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-891955.5170, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-709241.0465, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1926250.9519, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-697838.0391, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-771543.7548, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1795350.9831, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-733216.0202, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-736561.9211, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1014861.6943, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1113860.5462, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2159898.0518, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-650721.0532, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-812949.7751, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-606954.5754, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1204075.0526, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1410008.4297, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-594918.6606, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2390629.0899, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1170482.4169, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-601067.4057, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-582832.7156, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-655692.0622, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-893962.3120, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-633313.0472, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-692203.0558, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-931961.7289, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2382540.3654, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1050577.0482, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-845388.4265, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-538660.8779, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1224890.1218, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1414315.8463, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-461127.4949, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2196375.0152, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-337503.6504, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1118248.3350, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-740015.7204, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1350908.0959, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-680619.6167, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-778058.0007, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-782322.4300, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1146635.9521, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1564130.3068, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-306265.1725, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-459699.6787, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-666878.0424, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-2595664.1033, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-645751.7347, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-1786307.7493, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-738254.7315, grad_fn=<NegBackward>)\n",
      "loss :  tensor(-421377.3100, grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7a01e113e81e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_batch\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mPLNmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSigma_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVEM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeginning_VE_step_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.002\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeginning_M_step_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#%time model_batch.VEM(data, number_VEM_step = 3,batch_size = 25, beginning_VE_step_lr=0.002, beginning_M_step_lr = 0.05, requires_init = False, )#N_epoch_VE = 100, N_epoch_M = 100)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-852f94979be5>\u001b[0m in \u001b[0;36mVEM\u001b[0;34m(self, data, number_VEM_step, batch_size, beginning_VE_step_lr, beginning_M_step_lr, requires_init, N_epoch_VE, N_epoch_M)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_VEM_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MMMM_step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mN_epoch_M\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'VVVV_step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVE_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mN_epoch_VE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-852f94979be5>\u001b[0m in \u001b[0;36mM_step\u001b[0;34m(self, lr, tolerance, N_epoch, verbose, batch_size)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;31m# gradient ascent to optimize beta, the model parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         self.torch_gradient_ascent(self.M_step_optimizer, self.M_step_scheduler, [self.beta], ['beta'], \n\u001b[0m\u001b[1;32m    339\u001b[0m                                    lr = lr, tolerance = tolerance, N_epoch= N_epoch, verbose= verbose, batch_size = batch_size )\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-852f94979be5>\u001b[0m in \u001b[0;36mtorch_gradient_ascent\u001b[0;34m(self, optimizer, scheduler, params, params_names, lr, tolerance, N_epoch, verbose, batch_size)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;31m#print('beginning of epoch')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mY_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovariates_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_b\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovariates_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0;31m#print('epoch loss : ', epoch_loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-852f94979be5>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, optimizer, Y_, covariates_, O_, M_, S_, Sigma_, beta_)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_ELBO_bis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovariates_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSigma_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NAAAAAAAAN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_batch  = PLNmodel(Sigma_init, beta_init, M_init, S_init)\n",
    "model_batch.VEM(data,200,25, beginning_VE_step_lr=0.002, beginning_M_step_lr = 0.05)\n",
    "#%time model_batch.VEM(data, number_VEM_step = 3,batch_size = 25, beginning_VE_step_lr=0.002, beginning_M_step_lr = 0.05, requires_init = False, )#N_epoch_VE = 100, N_epoch_M = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "japanese-inside",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.40378\n",
      " MSE with beta :  0.34964\n",
      "ELBO :  1064.91898\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.06781\n",
      " MSE with beta :  0.33127\n",
      "ELBO :  1127.2489\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.14153\n",
      " MSE with beta :  0.34737\n",
      "ELBO :  1130.27347\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.19771\n",
      " MSE with beta :  0.36532\n",
      "ELBO :  1131.80225\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.2331\n",
      " MSE with beta :  0.37899\n",
      "ELBO :  1132.70339\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.25107\n",
      " MSE with beta :  0.38754\n",
      "ELBO :  1133.30331\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.25649\n",
      " MSE with beta :  0.39242\n",
      "ELBO :  1133.74135\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.25405\n",
      " MSE with beta :  0.39552\n",
      "ELBO :  1134.08017\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.24754\n",
      " MSE with beta :  0.39837\n",
      "ELBO :  1134.34902\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.23963\n",
      " MSE with beta :  0.40188\n",
      "ELBO :  1134.56262\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.232\n",
      " MSE with beta :  0.40648\n",
      "ELBO :  1134.72977\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.22548\n",
      " MSE with beta :  0.41226\n",
      "ELBO :  1134.85692\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.22025\n",
      " MSE with beta :  0.41946\n",
      "ELBO :  1134.94816\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.21515\n",
      " MSE with beta :  0.4311\n",
      "ELBO :  1134.98798\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.21158\n",
      " MSE with beta :  0.44199\n",
      "ELBO :  1134.98864\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.21029\n",
      " MSE with beta :  0.44939\n",
      "ELBO :  1135.00172\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.21182\n",
      " MSE with beta :  0.4492\n",
      "ELBO :  1135.05279\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.21123\n",
      " MSE with beta :  0.4547\n",
      "ELBO :  1135.07039\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.21069\n",
      " MSE with beta :  0.45777\n",
      "ELBO :  1135.06827\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.21156\n",
      " MSE with beta :  0.45973\n",
      "ELBO :  1135.12689\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.21103\n",
      " MSE with beta :  0.46288\n",
      "ELBO :  1135.14636\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.21235\n",
      " MSE with beta :  0.46525\n",
      "ELBO :  1135.15468\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.21291\n",
      " MSE with beta :  0.46756\n",
      "ELBO :  1135.16134\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.21322\n",
      " MSE with beta :  0.46981\n",
      "ELBO :  1135.13526\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.21458\n",
      " MSE with beta :  0.47178\n",
      "ELBO :  1135.1759\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.21576\n",
      " MSE with beta :  0.4736\n",
      "ELBO :  1135.14927\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.21596\n",
      " MSE with beta :  0.47469\n",
      "ELBO :  1135.15544\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.2168\n",
      " MSE with beta :  0.4763\n",
      "ELBO :  1135.18002\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.21749\n",
      " MSE with beta :  0.47763\n",
      "ELBO :  1135.16609\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.218\n",
      " MSE with beta :  0.47829\n",
      "ELBO :  1135.16078\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.2178\n",
      " MSE with beta :  0.47885\n",
      "ELBO :  1135.1831\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.2179\n",
      " MSE with beta :  0.47898\n",
      "ELBO :  1135.15709\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.21882\n",
      " MSE with beta :  0.47978\n",
      "ELBO :  1135.16172\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.21819\n",
      " MSE with beta :  0.47954\n",
      "ELBO :  1135.16595\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.21862\n",
      " MSE with beta :  0.48008\n",
      "ELBO :  1135.18537\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.21905\n",
      " MSE with beta :  0.48051\n",
      "ELBO :  1135.16446\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.21887\n",
      " MSE with beta :  0.48034\n",
      "ELBO :  1135.17958\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.21858\n",
      " MSE with beta :  0.47999\n",
      "ELBO :  1135.17128\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.21864\n",
      " MSE with beta :  0.48042\n",
      "ELBO :  1135.18267\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.21918\n",
      " MSE with beta :  0.48047\n",
      "ELBO :  1135.16928\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.2192\n",
      " MSE with beta :  0.48072\n",
      "ELBO :  1135.17076\n",
      "-------UPDATE------- None\n",
      " MSE with Sigma :  0.21833\n",
      " MSE with beta :  0.48016\n",
      "ELBO :  1135.16929\n",
      "CPU times: user 52.4 s, sys: 124 ms, total: 52.5 s\n",
      "Wall time: 52.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.005, 0.09000000000000001)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PLNmodel(Sigma_init, beta_init, M_init, S_init)\n",
    "%time model.VEM(data, number_VEM_step = 1500,batch_size = None, N_epoch_VE = 100, N_epoch_M = 100, beginning_VE_step_lr=0.005, beginning_M_step_lr = 0.1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dietary-parade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction des données \n",
    "Y_tricho = torch.from_numpy(read_csv('trichoptera.csv', sep=',').to_numpy())\n",
    "O_tricho = torch.outer(Y_tricho.sum(1), torch.ones(Y_tricho.shape[1]))/1000\n",
    "\n",
    "n_tricho,p_tricho = Y_tricho.shape \n",
    "d_tricho = 4\n",
    "covariates_tricho = torch.ones((n_tricho,d_tricho)) # attention prendre que des 1 n'est pas une bonne solution\n",
    "\n",
    "data_tricho = [Y_tricho,O_tricho, covariates_tricho]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "unusual-third",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 20 # nb of cavariates\n",
    "n = 200; p = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "municipal-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(p,p) \n",
    "Sigma_init =  (noise+ noise.T)\n",
    "beta_init = torch.rand((d, p))\n",
    "\n",
    "M_init = torch.ones((n,p))/100# some random values to initialize we divide to avoid nan values \n",
    "S_init = torch.ones((n,p))/8 # some random values to initializ. we divise to avoid nan values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "furnished-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "true_Sigma = torch.from_numpy(toeplitz(0.5**np.arange(p)))\n",
    "true_beta = torch.randn(d, p)\n",
    "\n",
    "\n",
    "covariates = torch.rand((n,d))\n",
    "O = 1 + torch.zeros((n,p))\n",
    "\n",
    "sample_model = sample_PLN()\n",
    "Y_sampled = torch.from_numpy(sample_model.sample(true_Sigma,true_beta, O, covariates)) \n",
    "\n",
    "data = [Y_sampled, O, covariates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "nuclear-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(modele, batch_size, time): \n",
    "    n,p = modele.Y.shape\n",
    "    d = modele.beta.shape[0]\n",
    "    ELBO = np.round(modele.current_ELBO,5)\n",
    "    name = 'batch size = {},n = {}, p = {}, d = {},  ELBO ={}, time = {}.png'.format(batch_size, n,p,d, ELBO, time )\n",
    "    abscisse = np.arange(len(modele.MSE_Sigma_list))\n",
    "    fig,ax = plt.subplots(4,1,figsize = (12,12))\n",
    "    ax\n",
    "    plt.subplots_adjust(hspace = 0.4)\n",
    "    plt.suptitle(name)\n",
    "    ax[0].plot(abscisse, modele.MSE_Sigma_list)\n",
    "    Sigma_min = np.round(min(modele.MSE_Sigma_list),5)\n",
    "    Sigma_argmin = np.argmin(modele.MSE_Sigma_list)\n",
    "    ax[0].set_title('MSE of Sigma. last MSE :{} . best_MSE {}, argmin = {}'.format(np.round(modele.MSE_Sigma_list[-1],5), Sigma_min, Sigma_argmin))\n",
    "    \n",
    "    ax[1].plot(abscisse, modele.MSE_beta_list)\n",
    "    beta_min = np.round(min(modele.MSE_beta_list),5)\n",
    "    beta_argmin = np.argmin(modele.MSE_beta_list)\n",
    "    ax[1].set_title('MSE of beta. last MSE :{} . best_MSE {}, argmin = {}'.format(np.round(modele.MSE_beta_list[-1],5), beta_min, beta_argmin))\n",
    "    \n",
    "    ax[2].plot(abscisse, modele.ELBO_list)\n",
    "    ax[2].set_xscale('log')\n",
    "    ax[2].set_title('ELBO')\n",
    "    \n",
    "    ax[3].plot(abscisse, modele.MSE_Sigma_list)\n",
    "    ax[3].set_title('MSE of Sigma (x axis in log scale)')\n",
    "    ax[3].set_xscale('log')\n",
    "    plt.savefig(name)\n",
    "    \n",
    "\n",
    "    \n",
    "def save_models(modele,modele_batch, batch_size): \n",
    "    n,p = modele.Y.shape\n",
    "    d = modele.beta.shape[0]\n",
    "    ELBO = np.round(modele.current_ELBO,5)\n",
    "    name = 'batch size = {},n = {}, p = {}, d = {}, With batch : last ELBO : {}, time : {}, Without batch : last ELBO : {}, time : {}.jpg'.format(batch_size,\n",
    "                                         n,p,d,  np.round(modele_batch.current_ELBO,1), np.round(modele_batch.running_time,0),  np.round(modele.current_ELBO,1),np.round(modele.running_time,0))\n",
    "    abscisse = np.arange(len(modele.MSE_Sigma_list))\n",
    "    fig,ax = plt.subplots(4,1,figsize = (15,12))\n",
    "    ax\n",
    "    plt.subplots_adjust(hspace = 0.4)\n",
    "    plt.suptitle(name)\n",
    "    ax[0].plot(abscisse, modele_batch.MSE_Sigma_list, label = 'MSE with batch')\n",
    "    ax[0].plot(abscisse, modele.MSE_Sigma_list, label = 'MSE without batch')\n",
    "    ax[0].legend()\n",
    "    ax[0].set_title('MSE of Sigma. last MSE with batch :{} . last_MSE without batch : {}'.format(np.round(modele_batch.MSE_Sigma_list[-1],5), np.round(modele.MSE_Sigma_list[-1],5)))\n",
    "    \n",
    "    ax[1].plot(abscisse, modele_batch.MSE_beta_list, label = 'MSE with batch')\n",
    "    ax[1].plot(abscisse, modele.MSE_beta_list, label = 'MSE without batch')\n",
    "    ax[1].legend()\n",
    "    ax[1].set_title('MSE of beta. last MSE with batch :{} . last_MSE without batch : {}'.format(np.round(modele_batch.MSE_beta_list[-1],5), np.round(modele.MSE_beta_list[-1],5)))\n",
    "    \n",
    "    ax[2].plot(abscisse, modele_batch.ELBO_list, label = 'ELBO with batch')\n",
    "    ax[2].plot(abscisse, modele.ELBO_list, label = 'ELBO without batch')\n",
    "    ax[2].legend()\n",
    "    ax[2].set_xscale('log')\n",
    "    ax[2].set_title('ELBO')\n",
    "    \n",
    "    \n",
    "    ax[3].plot(abscisse, np.array(modele.ELBO_list)-np.array(modele_batch.ELBO_list), label =  'ELBO without - ELBO with')\n",
    "    ax[3].legend()\n",
    "    ax[3].set_title('ELBO without batches - ELBO with batches')\n",
    "    ax[3].axhline(y=0, c = 'red')\n",
    "    ax[3].set_ybound( lower=-20, upper=20)\n",
    "    plt.savefig(name)\n",
    "    \n",
    "\n",
    "def print_model(modele): \n",
    "    abscisse = np.arange(len(modele.MSE_Sigma_list))\n",
    "    fig,ax = plt.subplots(4,1,figsize = (12,12))\n",
    "    ax\n",
    "    plt.subplots_adjust(hspace = 0.4)\n",
    "    ax[0].plot(abscisse, modele.MSE_Sigma_list)\n",
    "    Sigma_min = np.round(min(modele.MSE_Sigma_list),5)\n",
    "    Sigma_argmin = np.argmin(modele.MSE_Sigma_list)\n",
    "    ax[0].set_title('MSE of Sigma. last MSE :{} . best_MSE {}, argmin = {}'.format(np.round(modele.MSE_Sigma_list[-1],5), Sigma_min, Sigma_argmin))\n",
    "    \n",
    "    ax[1].plot(abscisse, modele.MSE_beta_list)\n",
    "    beta_min = np.round(min(modele.MSE_beta_list),5)\n",
    "    beta_argmin = np.argmin(modele.MSE_beta_list)\n",
    "    ax[1].set_title('MSE of beta. last MSE :{} . best_MSE {}, argmin = {}'.format(np.round(modele.MSE_beta_list[-1],5), beta_min, beta_argmin))\n",
    "    \n",
    "    ax[2].plot(abscisse, modele.ELBO_list)\n",
    "    ax[2].set_xscale('log')\n",
    "    ax[2].set_title('ELBO')\n",
    "    \n",
    "    ax[3].plot(abscisse, modele.MSE_Sigma_list)\n",
    "    ax[3].set_title('MSE of Sigma (x axis in log scale)')\n",
    "    ax[3].set_xscale('log')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-lobby",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "addressed-verification",
   "metadata": {},
   "source": [
    "sizes : \n",
    "\n",
    "$ Y : (n,p)$ \n",
    "\n",
    "$O : (n,p)$ \n",
    "\n",
    "$\\Sigma :  (p,p)$ \n",
    "\n",
    "covariates ($x$) : $(n,d)$\n",
    "\n",
    "$\\beta : (d,p)$\n",
    "\n",
    "$M : (n,p)$\n",
    "\n",
    "$S : (n,p)$ . Should be seen as $(n,p,p)$ but since all the $n$  matrix $(p,p)$ are diagonal, we only need $p$ points to encode it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-bargain",
   "metadata": {},
   "source": [
    "\n",
    "d = 2 # nb of cavariates\n",
    "n = 200; p = 50\n",
    "\n",
    "\n",
    "Does not work very well : \n",
    "\n",
    "$MSE_{Sigma} = 1.15$ : probably stock in a local minima. \n",
    "$MSE_{beta} = 0.95$\n",
    "lr = 0.1 for both \n",
    "***\n",
    "\n",
    "d = 5 # nb of cavariates\n",
    "n = 200; p = 50\n",
    "\n",
    "lr = 0.01 for VE step\n",
    "LR = 0.1 for M_step\n",
    "added an init for beta : \n",
    "\n",
    "MSE with Sigma :  0.10714\n",
    "MSE with beta :  0.12845\n",
    "\n",
    "result after 250 VEM step. \n",
    "\n",
    "took about 25 minutes\n",
    "\n",
    "***\n",
    "Same as above but without inittialization for beta : \n",
    "\n",
    " MSE with Sigma :  0.08429\n",
    " MSE with beta :  0.12089\n",
    " \n",
    " we can go to 0.06 and 0.11 if we go 50 step more \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-bishop",
   "metadata": {},
   "source": [
    "## The Poisson lognormal (PLN) model\n",
    "\n",
    "\n",
    "- Consider $n$ sites $(i=1 \\ldots n)$\n",
    "\n",
    "- Measure $x_{i}=\\left(x_{i h}\\right)_{1 \\leq h \\leq d}$ :\n",
    "$x_{i h}=$ given environmental descriptor (covariate) for site $i$\n",
    "(altitude, temperature, latitude, ...)\n",
    "\n",
    "- Consider $p$ species $(j=1 \\ldots p)$ Measure $Y=\\left(Y_{i j}\\right)_{1 \\leq i \\leq n, 1 \\leq j \\leq p}$ :\n",
    "\n",
    "- Measure $Y = Y_{i j}=$ number of observed individuals from species $j$ in site $i$ (abundance). \n",
    "\n",
    "- Associate a random vector $Z_{i}$ with each site Assume that the unknown $\\left(Z_{i}\\right)_{1 \\leq i \\leq n}$ are iid (no spatial structure):\n",
    "$$\n",
    "Z_{i} \\sim \\mathcal{N}_{p}(0, \\Sigma)\n",
    "$$\n",
    "- Assume that the observed abundances $\\left(Y_{i j}\\right)_{1 \\leq i \\leq n, 1 \\leq j \\leq p}$ are independent conditionally on the $Z=\\left(Z_{i}\\right)_{i}$\n",
    "\n",
    "\n",
    "$$\n",
    "\\left(Y_{i j} \\mid Z_{i j}\\right) \\sim \\mathcal{P}\\left(\\exp \\left(o_{i j}+x_{i}^{\\top} \\beta_{j}+Z_{i j}\\right)\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "The parameter of the model is $\\theta = (\\beta, \\Sigma)$. \n",
    "\n",
    "Since the model depends on latent variables, we want to apply the EM algortihm. However, EM requires to compute the following : \n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{\\theta}\\left[p_{\\theta}\\left(Z_{i} \\mid Y\\right)\\right]=\\mathbb{E}_{\\theta}\\left[p_{\\theta}\\left(Z_{i} \\mid Y_{i}\\right)\\right] \\propto \\int_{\\mathbb{R}^{p}} p_{\\Sigma}\\left(Z_{i}\\right) \\prod_{j} p_{\\theta}\\left(Y_{i j} \\mid Z_{i j}\\right) \\mathrm{d} Z_{i}\n",
    "$$\n",
    "\n",
    "Which is intractable in practice. \n",
    "\n",
    "We have two alternatives here. The first one is an approximation of this integral via MCMC methods. The second one is the variationnal approach. We adopt here the second approach. \n",
    "\n",
    "The goal of variationnal approach is to approximate $p_{\\theta}(Z \\mid Y)$ with some law $q^{\\star}(Z)$ from which we can compute the expectation with respect to $\\theta$. \n",
    "\n",
    "\n",
    "We find such a law by maximizing the Evidence Lower BOund (ELBO), that is : \n",
    "$$ \n",
    "q^{\\star} = \\underset{q \\in \\mathcal{Q}}{\\operatorname{argmax}} J_{\\theta,q}(Y) \n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "\\begin{align} J_{\\theta, q}(Y)& =\\log p_{\\theta}(Y)-K L\\left[q(Z) \\| p_{\\theta}(Z \\mid Y)\\right]                                    \\\\ \n",
    "                              & = \\mathbb{E}_{q}\\left[\\log p_{\\theta}(Y, Z)\\right] \\underbrace{-\\mathbb{E}_{q}[\\log q(Z)]}_{\\text {entropy } \\mathcal{H}(q)}    \\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "Where $\\mathcal{Q}$ is a set of distributions. \n",
    "The Variational EM (VEM) consists in alternate between two steps : \n",
    "- VE step: update $q$\n",
    "$$\n",
    "q^{h+1}=\\underset{q \\in \\mathcal{Q}}{\\arg \\max } J_{\\theta^{h}, q}(Y)=\\underset{q \\in \\mathcal{Q}}{\\arg \\min } K L\\left[q(Z) \\| p_{\\theta^{h}}(Z \\mid Y)\\right]\n",
    "$$\n",
    "- M step: update $\\theta$\n",
    "$$\n",
    "\\theta^{h+1}=\\underset{\\theta}{\\arg \\max } J_{\\theta, q^{h+1}}(Y)=\\underset{\\theta}{\\arg \\max } \\mathbb{E}_{q^{h+1}}\\left[\\log p_{\\theta}(Y, Z)\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-product",
   "metadata": {},
   "source": [
    "# VEM for PLN \n",
    "\n",
    "We consider \n",
    "$$\n",
    "\\mathcal{Q}_{\\text {Gauss }}=\\{q: q=\\mathcal{N}(m, S)\\}\n",
    "$$\n",
    "\n",
    "The parameters $M = (m_i)_{1\\leq i \\leq n} \\in \\mathbb{R}^{n\\times p}$  and $ S = (S_i)_{1\\leq i \\leq n} \\in \\mathbb{R}^{n\\times p} $ are called variational parameters whereas $\\theta = (\\beta,\\Sigma)$ is called model parameter.  \n",
    "\n",
    "The ELBO can be computed as : \n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "J_{\\theta, q}(Y)=& \\sum_{i} \\mathbb{E}_{q_{i}}\\left[\\log p_{\\theta}\\left(Z_{i}\\right)\\right]+\\sum_{i} \\mathbb{E}_{q_{i}}\\left[\\log p_{\\theta}\\left(Y_{i} \\mid Z_{i}\\right)\\right]+\\sum_{i} \\mathcal{H}\\left[\\mathcal{N}\\left(m_{i}, S_{i}\\right)\\right] \\\\\n",
    "=&-\\frac{n}{2} \\log |\\Sigma|-\\frac{1}{2} \\sum_{i} \\mathbb{E}_{\\mathcal{N}\\left(\\cdot m_{i}, S_{i}\\right)}\\left[Z_{i}^{\\top} \\Sigma^{-1} Z_{i}\\right] \\\\\n",
    "&+\\sum_{i, j} \\mathbb{E}_{\\mathcal{N}\\left(\\cdot ; m_{i}, S_{i}\\right)}\\left[-\\exp \\left(o_{i j}+x_{i}^{\\top} \\beta_{j}+Z_{i j}\\right)+Y_{i j}\\left(o_{i j}+x_{i}^{\\top} \\beta_{j}+Z_{i j}\\right)\\right] \\\\\n",
    "&+\\frac{1}{2} \\sum_{i} \\log \\left|S_{i}\\right|+\\mathrm{cst}\n",
    "\\end{aligned}\n",
    "$$\n",
    "We can evaluate some moments of $Z$ : \n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}_{\\mathcal{N}\\left(\\cdot ; m_{i}, s_{i}\\right)}\\left(Z_{i}\\right) &=m_{i}, & \\mathbb{E}_{\\mathcal{N}\\left(\\cdot ; m_{i}, S_{i}\\right)}\\left(Z_{i}^{\\top} \\Sigma^{-1} Z_{i}\\right)=m_{i}^{\\top} \\Sigma^{-1} m_{i}+\\operatorname{tr}\\left(\\Sigma^{-1} S_{i}\\right) \\\\\n",
    "\\mathbb{E}_{\\mathcal{N}\\left(\\cdot ; m_{i}, S_{i}\\right)}\\left(e^{Z_{i j}}\\right) &=\\exp \\left(m_{i j}+\\left[S_{i}\\right]_{j j}^{2} / 2\\right) &\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We then get : \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "J_{\\theta, q}(y) &=-\\frac{n}{2} \\log |\\Sigma|-\\frac{1}{2} \\sum_{i} m_{i}^{\\top} \\Sigma^{-1} m_{i}+tr\\left(\\Sigma^{-1} S_{i}\\right) \\\\\n",
    "&+\\sum_{i, j}-\\exp \\left(o_{i j}+x_{i}^{T} \\beta_{j}+m_{i j}+\\left[S_{i}\\right]_{j j}^{2} / 2\\right)+Y_{i j}\\left(o_{i j}+x_{i}^{T} \\beta_{j}+m_{i j}\\right) \\\\\n",
    "&+\\frac{1}{2} \\sum_{i} \\log \\left|S_{i}\\right|+c s t .\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "% the problem is convex if the S_i are diagonals. %\n",
    "\n",
    "We have a closed form for the $\\Sigma$ step, that is : \n",
    "\n",
    "$$\n",
    "\\widehat{\\Sigma}=\\frac{1}{n} \\sum_{i}\\left(m_{i} m_{i}^{\\top}+S_{i}\\right)\n",
    "$$\n",
    "\n",
    "For $\\beta$, we have the following : \n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\nabla _{\\beta}=-X^{\\top} \\exp \\left(0+M+\\frac{S \\odot S}{2}+X \\beta\\right)+\\frac{1}{2} X^{\\top} Y\n",
    "$$\n",
    "\n",
    "However, we don't have any closed form for the VE step. \n",
    "\n",
    "We consider now $S$ as $(n,p)$ matrix. Indeed, the $S_i$ are supposed diagonal matrices so we only need $p$ points to encode each of them. Considering $S$ this way is simpler for calculus. Here are the gradients with respect to the variational parameters. \n",
    "\n",
    "$$\n",
    "\\nabla_{M} J=-M \\Sigma^{-1}-\\exp \\left(O+x \\beta+M+\\frac{S \\odot S}{2}\\right)+Y\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\nabla_{S} J=-\\frac{1}{2}\\mathbb{1}_{n}\\mathbb{1}_{p}^{T} D_{\\Sigma^{-1}}-S\\odot  \\exp \\left(0+X \\beta+M+\\frac{S \\odot  S}{2}\\right)+\\frac{1}{2} \\frac{1}{S}\n",
    "$$\n",
    "\n",
    "\n",
    "We denote $D_{\\Sigma^{-1}}$ the diagonal matrix composed of the diagonal of $\\Sigma^{-1}$. The exponential is applied component-wise, as well as the division $\\frac 1 S$. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-hybrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def VE_step(self, lr = None, tolerance = 2, N_epoch = 200, verbose = True  ): \n",
    "        '''\n",
    "        VE_step : optimize the variational parameter. \n",
    "        We don't have a closed form for the parameters M and S so we have to do a gradient \n",
    "        ascent to do optimize them. \n",
    "        \n",
    "        args : \n",
    "             'lr' : learning if we want to set the learning rate of the optimizer\n",
    "        '''\n",
    "        \n",
    "        self.torch_gradient_ascent(self.VE_step_optimizer, self.VE_step_scheduler, lr = lr,\n",
    "                                    tolerance= tolerance, N_epoch= N_epoch, verbose= verbose)\n",
    "    def M_step(self,  lr = None, tolerance = 2, N_epoch = 50, verbose = True, batch_size = None):\n",
    "        \n",
    "        '''\n",
    "        Optimize the model parameters. \n",
    "        We have a closed form for Sigma so we actually don't need to do a gradient ascent for Sigma, just apply the formula. \n",
    "        We do a gradient ascent for beta. \n",
    "        '''\n",
    "        # closed form for Sigma, we don't need to optimize\n",
    "        with torch.no_grad(): \n",
    "            self.Sigma = 1/self.n*(torch.sum(torch.stack([torch.outer(self.M[i,:],self.M[i,:]) + torch.diag(self.S[i,:])  for i in range(self.n)]), axis = 0))\n",
    "        \n",
    "            \n",
    "            #self.beta = torch.mm(torch.inverse(torch.mm(self.covariates.T,self.covariates)),torch.mm(self.covariates.T,self.M))\n",
    "            #print('grad : ', self.grad_beta())\n",
    "        #print('grad :', self.beta.grad)\n",
    "\n",
    "        # gradient ascent to optimize beta, the model parameter\n",
    "        self.torch_gradient_ascent(self.M_step_optimizer, self.M_step_scheduler, \n",
    "                                   lr = lr, tolerance = tolerance, N_epoch= N_epoch, verbose= verbose, batch_size = batch_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def compute_ELBO(self): \n",
    "        ''' \n",
    "        computes the ELBO. We simply apply the formula given above. \n",
    "        '''\n",
    "        \n",
    "        inv_Sigma = torch.inverse(self.Sigma)\n",
    "        tmp = -self.n/2*torch.log(torch.det(self.Sigma))\n",
    "        \n",
    "        # formula with the quadratic function and the trace \n",
    "        tmp -=1/2*( torch.sum(torch.mm(torch.mm(self.M,inv_Sigma),self.M.T).diagonal()))   # we can simplify here, takes too much time \n",
    "                                                                                           # we should remove the diagonal and do a more efficient multiplication\n",
    "                                            \n",
    "        Gram_matrix = torch.mm(self.covariates,self.beta) # matrix with term (i,j): <x_i,beta_j>\n",
    "        \n",
    "        Exp_moment = torch.exp(self.M + torch.pow(self.S,2)/2)\n",
    "        \n",
    "        tmp += torch.sum(-torch.exp(self.O + Gram_matrix + self.M + torch.pow(self.S,2)/2) + torch.multiply(self.Y, self.O + Gram_matrix + self.M))\n",
    "        \n",
    "        for i in range(self.n): \n",
    "            tmp += 1/2* torch.log(self.S[i,:].prod())\n",
    "            tmp -= 1/2 * torch.trace(torch.multiply(inv_Sigma,self.S[i,:]))\n",
    "            \n",
    "        return tmp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
