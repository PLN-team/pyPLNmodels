{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage and main fitting functions\n",
    "\n",
    "The package comes with an artificial dataset to present the functionality.\n",
    "\n",
    "```\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick mathematical description of the package. \n",
    "\n",
    "The package tries to infer the parameters of two models: \n",
    "\n",
    "- Poisson Log Normal model (PLN)\n",
    "- Poisson Log Normal-Principal Composent Analysis model (PLN-PCA)\n",
    "\n",
    "\n",
    "\n",
    "We consider the follwoing model:  \n",
    "\n",
    "- Consider $n$ samples $(i=1 \\ldots n)$\n",
    "\n",
    "- Measure $x_{i}=\\left(x_{i h}\\right)_{1 \\leq h \\leq d}$ :\n",
    "$x_{i h}=$ (covariate) for sample $i$\n",
    "(altitude, temperature, categorical covariate, ...)\n",
    "\n",
    "- Consider $p$ features (genes) $(j=1 \\ldots p)$ Measure $Y=\\left(Y_{i j}\\right)_{1 \\leq i \\leq n, 1 \\leq j \\leq p}$ :\n",
    "\n",
    "- Measure $Y = Y_{i j}=$ number of times the feature $j$ is observed in sample $i$. \n",
    "\n",
    "- Associate a random vector $Z_{i}$ with each sample.\n",
    "- Assume that the unknown $\\left(W_{i}\\right)_{1 \\leq i \\leq n}$ are independant and living in a space of dimension $q\\leq p$  such that:\n",
    "\n",
    "$$\n",
    "\\begin{aligned} \n",
    "W_{i} & \\sim \\mathcal{N}_p\\left(0, I_{q}\\right)  \\\\\n",
    "Z_{i} &=\\beta^{\\top}\\mathbf{x}_{i} +\\mathbf{C}W_i  \\in \\mathbb R^p \\\\\n",
    "Y_{i j} \\mid Z_{i j} & \\sim \\mathcal{P}\\left(\\exp \\left(o_{ij} + Z_{i j}\\right)\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "and $C\\in \\mathbb R^{p\\times q}$, $\\beta \\in \\mathbb R^{d\\times p}$. \n",
    "\n",
    "Where $O = (o_{ij})_{1\\leq i\\leq n, 1\\leq j\\leq p}$ are known offsets. \n",
    "\n",
    "We can see that \n",
    "\n",
    "$$Z_{i} \\sim \\mathcal N_p (\\beta^{\\top}\\mathbf{x}_{i}, \\Sigma) $$\n",
    "\n",
    "The unknown parameter is $\\theta = (\\Sigma,\\beta)$. The latent variable of the model can be seen as $Z$ or $W$. \n",
    "\n",
    "\n",
    "- When $p=q$, we call this model Poisson-Log Normal (PLN) model. In this case, $Z_i$ is a non-degenerate gaussian with mean  $\\beta^{\\top}\\mathbf{x}_{i} \\in \\mathbb R^p$ and covariance matrix $\\Sigma$.  \n",
    "- When $p<q$, we call this model  Poisson-Log Normal-Principal Component Analysis (PLN-PCA). Indeed, we are doing a PCA in the latent layer, estimating $\\Sigma$ with a ranq $q$ matrix: $CC^{\\top}$.\n",
    "\n",
    "The goal of this package is to retrieve $\\theta$ from the observed data $(Y, O, X)$. To do so, we will try to maximize the log likelihood of the model:\n",
    "$$p_{\\theta}(Y_i)  = \\int_{\\mathbb R^q} p_{\\theta}(Y_i,W)dW \\overset{\\text{ (if } p=q\\text{)}}{=} \\int_{\\mathbb R^p} p_{\\theta}(Y_i,Z)dZ$$\n",
    "\n",
    "However, almost any integrals involving the law of the complete data is unreachable, so that we can't perform neither gradient ascent algorithms nor EM algorithm.   \n",
    "We adopt two different approaches to circumvent this problem: \n",
    "- Variational approximation of the latent layer (Variational EM)\n",
    "- Importance sampling based algorithm, using a gradient ascent method.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Variational approach\n",
    "\n",
    "We want here to use the EM algorithm, but the E step is unreachable, since the law $Z|Y_i$ (resp $W|Y_i$) is unknown and can't be integrated out. We thus choose to approximate the law of $Z|Y_i$ (resp $W|Y_i$) with a law $\\phi_i(Z)$ (resp $\\phi_i(W)$), where $\\phi_i$ is taken among a family of law. We thus change the objective function: \n",
    "\n",
    "$$\\begin{align} J_Y(\\theta,\\phi) & = \\frac 1 n \\sum _{i = 1}^n J_{Y_i}(\\theta, \\phi_i) \\\\ \n",
    "J_{Y_i}(\\theta, \\phi_i)& =\\log p_{\\theta}(Y_i)-K L\\left[\\phi_i(Z_i) \\|p_{\\theta}(Z_i \\mid Y_i)\\right]\\\\ \n",
    "& = \\mathbb{E}_{\\phi_i}\\left[\\log p_{\\theta}(Y_i, Z_i)\\right] \\underbrace{-\\mathbb{E}_{\\phi_i}[\\log \\phi_i(Z_i)]}_{\\text {entropy } \\mathcal{H}(\\phi_i)} \\\\\n",
    "\\end{align}$$\n",
    "\n",
    "\n",
    "We choose $\\phi_i$ in a family distribution : \n",
    "\n",
    "$$\n",
    "\\phi_i \\in \\mathcal{Q}_{\\text {diag}}=\\{\n",
    " \\mathcal{N}\\left(M_{i}, \\operatorname{diag} (S_{i}\\odot S_i ))\n",
    ", M_i \\in \\mathbb{M} ^q, S_i \\in \\mathbb{R} ^q\\right\\}\n",
    "$$\n",
    "\n",
    "We choose such a Gaussian approximation since $W$ is gaussian, so that $W|Y_i$ may be well approximated. However, taking a diagonal matrix as covariance breaks the dependecy induced by $Y_i$. \n",
    "\n",
    "We can prove that $J_{Y_i}(\\theta, \\phi_i) \\leq p_{\\theta} (Y_i) \\; \\forall \\phi_i$. The quantity $J_{Y}(\\theta, \\phi)$ is called the ELBO (Evidence Lower BOund).  \n",
    "\n",
    "##### Variational EM \n",
    "\n",
    "Given an intialisation $(\\theta^0, q^0)$, the variational EM aims at maximizing the ELBO alternating between two steps: \n",
    "\n",
    "-  VE step: update  $q$\n",
    "$$\n",
    "q^{t+1}=\\underset{q \\in \\mathcal{Q}_{gauss}}{\\arg \\max } J_Y(\\theta^{t}, q)\n",
    "$$\n",
    "- M step : update $\\theta$\n",
    "$$\n",
    "\\theta^{t+1}=\\underset{\\theta}{\\arg \\max } J_Y(\\theta, q^{t+1})\n",
    "$$\n",
    "Each step is an optimisation problem that needs to be solved using analytical forms or gradient ascent. Note that $q$ is completely determined by $M = (M_i)_{1 \\leq i \\leq n } \\in \\mathbb R ^{n\\times q}$ and $S = (S_i)_{1 \\leq i \\leq n } \\in \\mathbb R ^{n\\times q}$, so that $J$ is a function of $(M, S, \\beta, \\Sigma)$. $M$ and $S$ are the variational parameters, $\\beta$ and $\\Sigma$ are the model parameters.  \n",
    "\n",
    "\n",
    "##### Case $p = q$\n",
    "The case $p=q$ is not doing any reduction dimension, but is very fast to compute. \n",
    "When $ p =q $, computations show that the M-step is straightforward as we can update $\\Sigma$ and $\\beta$ with an analytical form : \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\Sigma^{(t+1)} & = \\frac{1}{n} \\sum_{i}\\left(\\left((M^{(t)}-X\\beta)_{i} (M^{(t)}-X\\beta)_{i}\\right)^{\\top}+S^{(t)}_{i}\\right)\\\\\n",
    "\\beta^{(t+1)} &= (X^{\\top}X)^{-1}X^{\\top}M^{(t)} \\\\ \n",
    "\\end{aligned}\n",
    "$$\n",
    "This results in a fast algorithm, since we only need to go a gradient ascent on the variational parameters $M$ and $S$. Practice shows that we only need to do one gradient step of $M$ and $S$, update $\\beta$ and $\\Sigma$ with their closed form, then re-perform a gradient step on $M$ and $S$ and so on.\n",
    "\n",
    "\n",
    "##### Case $p <q$\n",
    "\n",
    "When $p<q$, we do not have any analytical form, and we are forced to perform gradient ascent on all the parameters. Practice shows that we can perform a gradient ascent on all the parameters at a time (doing each VE step and M step perfectly is quite inefficient). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importance sampling based algorithm \n",
    "\n",
    "In this section, we try to estimate the gradients with respect to $\\theta = (C, \\beta) $. \n",
    "\n",
    "\n",
    "We can use importance sampling to estimate the likelihood: \n",
    "\n",
    " $$p_{\\theta}(Y_i) = \\int \\tilde p_{\\theta}^{(u)}(W) \\mathrm dW \\approx \\frac 1 {n_s} \\sum_{k=1}^{n_s} \\frac {\\tilde p_{\\theta}^{(u)}(V_k)}{g(V_k)}, ~ ~ ~(V_{k})_{1 \\leq k \\leq n_s} \\overset{iid}{\\sim} g$$\n",
    " \n",
    "where $g$ is the importance law, $n_s$ is the sampling effort and  \n",
    "\n",
    "\n",
    "$$\\begin{array}{ll}\n",
    "\\tilde p_{\\theta}^{(u)}\\ :& \\mathbb R^{q}  \\to  \\mathbb R^+  \\\\\n",
    " & W \\mapsto p_{\\theta}(Y_i| W) p(W) \\\\\n",
    "\\end{array}$$\n",
    "\n",
    "To learn more about the (crucial) choice of $g$, please see REF.\n",
    "\n",
    "One can do the following approximation:\n",
    "\n",
    "\n",
    "  $$\\begin{equation}\\label{one integral}\n",
    "  \\nabla _{\\theta} \\operatorname{log} p_{\\theta}(Y_i) \\approx \\nabla_{\\theta} \\operatorname{log}\\left(\\frac 1 {n_s} \\sum_{k=1}^{n_s} \\frac {\\tilde p_{\\theta}^{(u)}(V_k)}{g(V_k)}\\right)\\end{equation}$$\n",
    "  \n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<!---\n",
    " ### ZIPLN \n",
    "\n",
    "[//]ZIPLN model is a modified PLN model that tries to explain the zero inflated datasets. Basically, we add a latent variable $\\xi$ parametrized by $B^0$ that will force some components of $Y$ to be zero. The model is the following : \n",
    "\n",
    "$$\n",
    "\\begin{aligned} \n",
    "W_{i} & \\sim \\mathcal{N}\\left(0, I_{q}\\right)  \\\\\n",
    "Z_{i} &=\\beta^{\\top}\\mathbf{x}_{i} +\\mathbf{C}W_i  \\in \\mathbb R^p \\\\\n",
    "\\xi _{ij} &   \\sim \\mathcal{B}\\left(\\operatorname{logit}^{-1}\\left(\\mathbf x_{i}^{\\top} B_{j}^{0}\\right)\\right) \\in \\mathbb R \\\\\n",
    "Y_{i j} \\mid Z_{i j} & \\sim (1-\\xi_{ij})\\mathcal{P}\\left(\\exp \\left(o_{ij} + Z_{i j}\\right)\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "$\n",
    "\\text { We are interested in inferring } \\theta=\\left(\\boldsymbol{\\Sigma}, \\boldsymbol{\\beta}, \\boldsymbol{B}^{0}\\right) \\in \\mathbb{S}_{p}^{++} \\times \\mathcal{M}_{p, d}(\\mathbb{R}) \\times \\mathcal{M}_{p, d}(\\mathbb{R}) \\text {,   where }\\Sigma = CC^{\\top}\n",
    "$\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9ab2fda4397b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/PLNpy/fastPLNmodels/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_M\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_Sigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPoisson_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_stirling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_log_P_WgivenY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrefined_MSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mVRA\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSAGARAD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAGRAD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVRGRAD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
